{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai\n",
    "from torch.export import export\n",
    "from executorch.exir import to_edge\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "from executorch.exir import EdgeCompileConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = getattr(monai.networks.nets, 'densenet121')\n",
    "model = densenet(spatial_dims=2,\n",
    "                    in_channels=3,\n",
    "                    out_channels=3,\n",
    "                    dropout_prob=float(0.2),\n",
    "                    pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_168726/579817510.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(weights_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# Load the weights from the file\n",
    "weights_path = '/home/kindersc/Documents/executorch_example/executorch/notebooks/best_metric_model.pth'\n",
    "state_dict = torch.load(weights_path, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet121(\n",
       "  (features): Sequential(\n",
       "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (denseblock1): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition1): _Transition(\n",
       "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock2): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition2): _Transition(\n",
       "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock3): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer17): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer18): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer19): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer20): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer21): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer22): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer23): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer24): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transition3): _Transition(\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "    (denseblock4): _DenseBlock(\n",
       "      (denselayer1): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer2): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer3): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer4): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer5): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer6): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer7): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer8): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer9): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer10): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer11): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer12): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer13): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer14): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer15): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (denselayer16): _DenseLayer(\n",
       "        (layers): Sequential(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (dropout): Dropout2d(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (class_layers): Sequential(\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (out): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Custom dataset returning an image of all 1s\n",
    "class OneImageDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.target = 0  # Dummy target (can be changed if needed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000  # Single item in the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.randn((3, 256, 256))\n",
    "        return image, self.target\n",
    "\n",
    "# Define a data loader with batch size 1\n",
    "data_loader = DataLoader(OneImageDataset(), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define calibration function\n",
    "def calibrate(model_in, data_loader):\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            model_in(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._export import capture_pre_autograd_graph\n",
    "from torch.ao.quantization.quantize_pt2e import convert_pt2e, prepare_pt2e\n",
    "from torch.ao.quantization.quantizer.xnnpack_quantizer import (\n",
    "    get_symmetric_quantization_config,\n",
    "    XNNPACKQuantizer,\n",
    ")\n",
    "from torch.export import export, ExportedProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0926 19:43:43.120000 168726 torch/_export/__init__.py:64] +============================+\n",
      "W0926 19:43:43.120000 168726 torch/_export/__init__.py:65] |     !!!   WARNING   !!!    |\n",
      "W0926 19:43:43.121000 168726 torch/_export/__init__.py:66] +============================+\n",
      "W0926 19:43:43.121000 168726 torch/_export/__init__.py:67] capture_pre_autograd_graph() is deprecated and doesn't provide any function guarantee moving forward.\n",
      "W0926 19:43:43.121000 168726 torch/_export/__init__.py:68] Please switch to use torch.export.export_for_training instead.\n"
     ]
    }
   ],
   "source": [
    "example_args = (torch.ones(1, 3, 256, 256),)\n",
    "pre_autograd_aten_dialect = capture_pre_autograd_graph(model, example_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Autograd ATen Dialect Graph\n",
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    arg0, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    arg0_1 = arg0\n",
      "    _param_constant0 = self.features_conv0_weight\n",
      "    conv2d = torch.ops.aten.conv2d.default(arg0_1, _param_constant0, None, [2, 2], [3, 3]);  arg0_1 = _param_constant0 = None\n",
      "    empty = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty = None\n",
      "    _param_constant1 = self.features_norm0_weight\n",
      "    _param_constant2 = self.features_norm0_bias\n",
      "    _tensor_constant0 = self.features_norm0_running_mean\n",
      "    _tensor_constant1 = self.features_norm0_running_var\n",
      "    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, _param_constant1, _param_constant2, _tensor_constant0, _tensor_constant1, 0.1, 1e-05);  conv2d = _param_constant1 = _param_constant2 = _tensor_constant0 = _tensor_constant1 = None\n",
      "    getitem = _native_batch_norm_legit_no_training[0]\n",
      "    getitem_1 = _native_batch_norm_legit_no_training[1];  getitem_1 = None\n",
      "    getitem_2 = _native_batch_norm_legit_no_training[2];  _native_batch_norm_legit_no_training = getitem_2 = None\n",
      "    relu_ = torch.ops.aten.relu_.default(getitem);  getitem = None\n",
      "    max_pool2d = torch.ops.aten.max_pool2d.default(relu_, [3, 3], [2, 2], [1, 1]);  relu_ = None\n",
      "    empty_1 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_1 = None\n",
      "    _param_constant3 = self.features_denseblock1_denselayer1_layers_norm1_weight\n",
      "    _param_constant4 = self.features_denseblock1_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant2 = self.features_denseblock1_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant3 = self.features_denseblock1_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(max_pool2d, _param_constant3, _param_constant4, _tensor_constant2, _tensor_constant3, 0.1, 1e-05);  _param_constant3 = _param_constant4 = _tensor_constant2 = _tensor_constant3 = None\n",
      "    getitem_3 = _native_batch_norm_legit_no_training_1[0]\n",
      "    getitem_4 = _native_batch_norm_legit_no_training_1[1];  getitem_4 = None\n",
      "    getitem_5 = _native_batch_norm_legit_no_training_1[2];  _native_batch_norm_legit_no_training_1 = getitem_5 = None\n",
      "    relu__1 = torch.ops.aten.relu_.default(getitem_3);  getitem_3 = None\n",
      "    _param_constant5 = self.features_denseblock1_denselayer1_layers_conv1_weight\n",
      "    conv2d_1 = torch.ops.aten.conv2d.default(relu__1, _param_constant5);  relu__1 = _param_constant5 = None\n",
      "    empty_2 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_2 = None\n",
      "    _param_constant6 = self.features_denseblock1_denselayer1_layers_norm2_weight\n",
      "    _param_constant7 = self.features_denseblock1_denselayer1_layers_norm2_bias\n",
      "    _tensor_constant4 = self.features_denseblock1_denselayer1_layers_norm2_running_mean\n",
      "    _tensor_constant5 = self.features_denseblock1_denselayer1_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, _param_constant6, _param_constant7, _tensor_constant4, _tensor_constant5, 0.1, 1e-05);  conv2d_1 = _param_constant6 = _param_constant7 = _tensor_constant4 = _tensor_constant5 = None\n",
      "    getitem_6 = _native_batch_norm_legit_no_training_2[0]\n",
      "    getitem_7 = _native_batch_norm_legit_no_training_2[1];  getitem_7 = None\n",
      "    getitem_8 = _native_batch_norm_legit_no_training_2[2];  _native_batch_norm_legit_no_training_2 = getitem_8 = None\n",
      "    relu__2 = torch.ops.aten.relu_.default(getitem_6);  getitem_6 = None\n",
      "    _param_constant8 = self.features_denseblock1_denselayer1_layers_conv2_weight\n",
      "    conv2d_2 = torch.ops.aten.conv2d.default(relu__2, _param_constant8, None, [1, 1], [1, 1]);  relu__2 = _param_constant8 = None\n",
      "    cat = torch.ops.aten.cat.default([max_pool2d, conv2d_2], 1);  max_pool2d = conv2d_2 = None\n",
      "    empty_3 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_3 = None\n",
      "    _param_constant9 = self.features_denseblock1_denselayer2_layers_norm1_weight\n",
      "    _param_constant10 = self.features_denseblock1_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant6 = self.features_denseblock1_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant7 = self.features_denseblock1_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat, _param_constant9, _param_constant10, _tensor_constant6, _tensor_constant7, 0.1, 1e-05);  _param_constant9 = _param_constant10 = _tensor_constant6 = _tensor_constant7 = None\n",
      "    getitem_9 = _native_batch_norm_legit_no_training_3[0]\n",
      "    getitem_10 = _native_batch_norm_legit_no_training_3[1];  getitem_10 = None\n",
      "    getitem_11 = _native_batch_norm_legit_no_training_3[2];  _native_batch_norm_legit_no_training_3 = getitem_11 = None\n",
      "    relu__3 = torch.ops.aten.relu_.default(getitem_9);  getitem_9 = None\n",
      "    _param_constant11 = self.features_denseblock1_denselayer2_layers_conv1_weight\n",
      "    conv2d_3 = torch.ops.aten.conv2d.default(relu__3, _param_constant11);  relu__3 = _param_constant11 = None\n",
      "    empty_4 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_4 = None\n",
      "    _param_constant12 = self.features_denseblock1_denselayer2_layers_norm2_weight\n",
      "    _param_constant13 = self.features_denseblock1_denselayer2_layers_norm2_bias\n",
      "    _tensor_constant8 = self.features_denseblock1_denselayer2_layers_norm2_running_mean\n",
      "    _tensor_constant9 = self.features_denseblock1_denselayer2_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, _param_constant12, _param_constant13, _tensor_constant8, _tensor_constant9, 0.1, 1e-05);  conv2d_3 = _param_constant12 = _param_constant13 = _tensor_constant8 = _tensor_constant9 = None\n",
      "    getitem_12 = _native_batch_norm_legit_no_training_4[0]\n",
      "    getitem_13 = _native_batch_norm_legit_no_training_4[1];  getitem_13 = None\n",
      "    getitem_14 = _native_batch_norm_legit_no_training_4[2];  _native_batch_norm_legit_no_training_4 = getitem_14 = None\n",
      "    relu__4 = torch.ops.aten.relu_.default(getitem_12);  getitem_12 = None\n",
      "    _param_constant14 = self.features_denseblock1_denselayer2_layers_conv2_weight\n",
      "    conv2d_4 = torch.ops.aten.conv2d.default(relu__4, _param_constant14, None, [1, 1], [1, 1]);  relu__4 = _param_constant14 = None\n",
      "    cat_1 = torch.ops.aten.cat.default([cat, conv2d_4], 1);  cat = conv2d_4 = None\n",
      "    empty_5 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_5 = None\n",
      "    _param_constant15 = self.features_denseblock1_denselayer3_layers_norm1_weight\n",
      "    _param_constant16 = self.features_denseblock1_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant10 = self.features_denseblock1_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant11 = self.features_denseblock1_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_1, _param_constant15, _param_constant16, _tensor_constant10, _tensor_constant11, 0.1, 1e-05);  _param_constant15 = _param_constant16 = _tensor_constant10 = _tensor_constant11 = None\n",
      "    getitem_15 = _native_batch_norm_legit_no_training_5[0]\n",
      "    getitem_16 = _native_batch_norm_legit_no_training_5[1];  getitem_16 = None\n",
      "    getitem_17 = _native_batch_norm_legit_no_training_5[2];  _native_batch_norm_legit_no_training_5 = getitem_17 = None\n",
      "    relu__5 = torch.ops.aten.relu_.default(getitem_15);  getitem_15 = None\n",
      "    _param_constant17 = self.features_denseblock1_denselayer3_layers_conv1_weight\n",
      "    conv2d_5 = torch.ops.aten.conv2d.default(relu__5, _param_constant17);  relu__5 = _param_constant17 = None\n",
      "    empty_6 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_6 = None\n",
      "    _param_constant18 = self.features_denseblock1_denselayer3_layers_norm2_weight\n",
      "    _param_constant19 = self.features_denseblock1_denselayer3_layers_norm2_bias\n",
      "    _tensor_constant12 = self.features_denseblock1_denselayer3_layers_norm2_running_mean\n",
      "    _tensor_constant13 = self.features_denseblock1_denselayer3_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, _param_constant18, _param_constant19, _tensor_constant12, _tensor_constant13, 0.1, 1e-05);  conv2d_5 = _param_constant18 = _param_constant19 = _tensor_constant12 = _tensor_constant13 = None\n",
      "    getitem_18 = _native_batch_norm_legit_no_training_6[0]\n",
      "    getitem_19 = _native_batch_norm_legit_no_training_6[1];  getitem_19 = None\n",
      "    getitem_20 = _native_batch_norm_legit_no_training_6[2];  _native_batch_norm_legit_no_training_6 = getitem_20 = None\n",
      "    relu__6 = torch.ops.aten.relu_.default(getitem_18);  getitem_18 = None\n",
      "    _param_constant20 = self.features_denseblock1_denselayer3_layers_conv2_weight\n",
      "    conv2d_6 = torch.ops.aten.conv2d.default(relu__6, _param_constant20, None, [1, 1], [1, 1]);  relu__6 = _param_constant20 = None\n",
      "    cat_2 = torch.ops.aten.cat.default([cat_1, conv2d_6], 1);  cat_1 = conv2d_6 = None\n",
      "    empty_7 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_7 = None\n",
      "    _param_constant21 = self.features_denseblock1_denselayer4_layers_norm1_weight\n",
      "    _param_constant22 = self.features_denseblock1_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant14 = self.features_denseblock1_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant15 = self.features_denseblock1_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_2, _param_constant21, _param_constant22, _tensor_constant14, _tensor_constant15, 0.1, 1e-05);  _param_constant21 = _param_constant22 = _tensor_constant14 = _tensor_constant15 = None\n",
      "    getitem_21 = _native_batch_norm_legit_no_training_7[0]\n",
      "    getitem_22 = _native_batch_norm_legit_no_training_7[1];  getitem_22 = None\n",
      "    getitem_23 = _native_batch_norm_legit_no_training_7[2];  _native_batch_norm_legit_no_training_7 = getitem_23 = None\n",
      "    relu__7 = torch.ops.aten.relu_.default(getitem_21);  getitem_21 = None\n",
      "    _param_constant23 = self.features_denseblock1_denselayer4_layers_conv1_weight\n",
      "    conv2d_7 = torch.ops.aten.conv2d.default(relu__7, _param_constant23);  relu__7 = _param_constant23 = None\n",
      "    empty_8 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_8 = None\n",
      "    _param_constant24 = self.features_denseblock1_denselayer4_layers_norm2_weight\n",
      "    _param_constant25 = self.features_denseblock1_denselayer4_layers_norm2_bias\n",
      "    _tensor_constant16 = self.features_denseblock1_denselayer4_layers_norm2_running_mean\n",
      "    _tensor_constant17 = self.features_denseblock1_denselayer4_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, _param_constant24, _param_constant25, _tensor_constant16, _tensor_constant17, 0.1, 1e-05);  conv2d_7 = _param_constant24 = _param_constant25 = _tensor_constant16 = _tensor_constant17 = None\n",
      "    getitem_24 = _native_batch_norm_legit_no_training_8[0]\n",
      "    getitem_25 = _native_batch_norm_legit_no_training_8[1];  getitem_25 = None\n",
      "    getitem_26 = _native_batch_norm_legit_no_training_8[2];  _native_batch_norm_legit_no_training_8 = getitem_26 = None\n",
      "    relu__8 = torch.ops.aten.relu_.default(getitem_24);  getitem_24 = None\n",
      "    _param_constant26 = self.features_denseblock1_denselayer4_layers_conv2_weight\n",
      "    conv2d_8 = torch.ops.aten.conv2d.default(relu__8, _param_constant26, None, [1, 1], [1, 1]);  relu__8 = _param_constant26 = None\n",
      "    cat_3 = torch.ops.aten.cat.default([cat_2, conv2d_8], 1);  cat_2 = conv2d_8 = None\n",
      "    empty_9 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_9 = None\n",
      "    _param_constant27 = self.features_denseblock1_denselayer5_layers_norm1_weight\n",
      "    _param_constant28 = self.features_denseblock1_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant18 = self.features_denseblock1_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant19 = self.features_denseblock1_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_3, _param_constant27, _param_constant28, _tensor_constant18, _tensor_constant19, 0.1, 1e-05);  _param_constant27 = _param_constant28 = _tensor_constant18 = _tensor_constant19 = None\n",
      "    getitem_27 = _native_batch_norm_legit_no_training_9[0]\n",
      "    getitem_28 = _native_batch_norm_legit_no_training_9[1];  getitem_28 = None\n",
      "    getitem_29 = _native_batch_norm_legit_no_training_9[2];  _native_batch_norm_legit_no_training_9 = getitem_29 = None\n",
      "    relu__9 = torch.ops.aten.relu_.default(getitem_27);  getitem_27 = None\n",
      "    _param_constant29 = self.features_denseblock1_denselayer5_layers_conv1_weight\n",
      "    conv2d_9 = torch.ops.aten.conv2d.default(relu__9, _param_constant29);  relu__9 = _param_constant29 = None\n",
      "    empty_10 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_10 = None\n",
      "    _param_constant30 = self.features_denseblock1_denselayer5_layers_norm2_weight\n",
      "    _param_constant31 = self.features_denseblock1_denselayer5_layers_norm2_bias\n",
      "    _tensor_constant20 = self.features_denseblock1_denselayer5_layers_norm2_running_mean\n",
      "    _tensor_constant21 = self.features_denseblock1_denselayer5_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, _param_constant30, _param_constant31, _tensor_constant20, _tensor_constant21, 0.1, 1e-05);  conv2d_9 = _param_constant30 = _param_constant31 = _tensor_constant20 = _tensor_constant21 = None\n",
      "    getitem_30 = _native_batch_norm_legit_no_training_10[0]\n",
      "    getitem_31 = _native_batch_norm_legit_no_training_10[1];  getitem_31 = None\n",
      "    getitem_32 = _native_batch_norm_legit_no_training_10[2];  _native_batch_norm_legit_no_training_10 = getitem_32 = None\n",
      "    relu__10 = torch.ops.aten.relu_.default(getitem_30);  getitem_30 = None\n",
      "    _param_constant32 = self.features_denseblock1_denselayer5_layers_conv2_weight\n",
      "    conv2d_10 = torch.ops.aten.conv2d.default(relu__10, _param_constant32, None, [1, 1], [1, 1]);  relu__10 = _param_constant32 = None\n",
      "    cat_4 = torch.ops.aten.cat.default([cat_3, conv2d_10], 1);  cat_3 = conv2d_10 = None\n",
      "    empty_11 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_11 = None\n",
      "    _param_constant33 = self.features_denseblock1_denselayer6_layers_norm1_weight\n",
      "    _param_constant34 = self.features_denseblock1_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant22 = self.features_denseblock1_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant23 = self.features_denseblock1_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_4, _param_constant33, _param_constant34, _tensor_constant22, _tensor_constant23, 0.1, 1e-05);  _param_constant33 = _param_constant34 = _tensor_constant22 = _tensor_constant23 = None\n",
      "    getitem_33 = _native_batch_norm_legit_no_training_11[0]\n",
      "    getitem_34 = _native_batch_norm_legit_no_training_11[1];  getitem_34 = None\n",
      "    getitem_35 = _native_batch_norm_legit_no_training_11[2];  _native_batch_norm_legit_no_training_11 = getitem_35 = None\n",
      "    relu__11 = torch.ops.aten.relu_.default(getitem_33);  getitem_33 = None\n",
      "    _param_constant35 = self.features_denseblock1_denselayer6_layers_conv1_weight\n",
      "    conv2d_11 = torch.ops.aten.conv2d.default(relu__11, _param_constant35);  relu__11 = _param_constant35 = None\n",
      "    empty_12 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_12 = None\n",
      "    _param_constant36 = self.features_denseblock1_denselayer6_layers_norm2_weight\n",
      "    _param_constant37 = self.features_denseblock1_denselayer6_layers_norm2_bias\n",
      "    _tensor_constant24 = self.features_denseblock1_denselayer6_layers_norm2_running_mean\n",
      "    _tensor_constant25 = self.features_denseblock1_denselayer6_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, _param_constant36, _param_constant37, _tensor_constant24, _tensor_constant25, 0.1, 1e-05);  conv2d_11 = _param_constant36 = _param_constant37 = _tensor_constant24 = _tensor_constant25 = None\n",
      "    getitem_36 = _native_batch_norm_legit_no_training_12[0]\n",
      "    getitem_37 = _native_batch_norm_legit_no_training_12[1];  getitem_37 = None\n",
      "    getitem_38 = _native_batch_norm_legit_no_training_12[2];  _native_batch_norm_legit_no_training_12 = getitem_38 = None\n",
      "    relu__12 = torch.ops.aten.relu_.default(getitem_36);  getitem_36 = None\n",
      "    _param_constant38 = self.features_denseblock1_denselayer6_layers_conv2_weight\n",
      "    conv2d_12 = torch.ops.aten.conv2d.default(relu__12, _param_constant38, None, [1, 1], [1, 1]);  relu__12 = _param_constant38 = None\n",
      "    cat_5 = torch.ops.aten.cat.default([cat_4, conv2d_12], 1);  cat_4 = conv2d_12 = None\n",
      "    empty_13 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_13 = None\n",
      "    _param_constant39 = self.features_transition1_norm_weight\n",
      "    _param_constant40 = self.features_transition1_norm_bias\n",
      "    _tensor_constant26 = self.features_transition1_norm_running_mean\n",
      "    _tensor_constant27 = self.features_transition1_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_5, _param_constant39, _param_constant40, _tensor_constant26, _tensor_constant27, 0.1, 1e-05);  cat_5 = _param_constant39 = _param_constant40 = _tensor_constant26 = _tensor_constant27 = None\n",
      "    getitem_39 = _native_batch_norm_legit_no_training_13[0]\n",
      "    getitem_40 = _native_batch_norm_legit_no_training_13[1];  getitem_40 = None\n",
      "    getitem_41 = _native_batch_norm_legit_no_training_13[2];  _native_batch_norm_legit_no_training_13 = getitem_41 = None\n",
      "    relu__13 = torch.ops.aten.relu_.default(getitem_39);  getitem_39 = None\n",
      "    _param_constant41 = self.features_transition1_conv_weight\n",
      "    conv2d_13 = torch.ops.aten.conv2d.default(relu__13, _param_constant41);  relu__13 = _param_constant41 = None\n",
      "    avg_pool2d = torch.ops.aten.avg_pool2d.default(conv2d_13, [2, 2], [2, 2]);  conv2d_13 = None\n",
      "    empty_14 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_14 = None\n",
      "    _param_constant42 = self.features_denseblock2_denselayer1_layers_norm1_weight\n",
      "    _param_constant43 = self.features_denseblock2_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant28 = self.features_denseblock2_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant29 = self.features_denseblock2_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d, _param_constant42, _param_constant43, _tensor_constant28, _tensor_constant29, 0.1, 1e-05);  _param_constant42 = _param_constant43 = _tensor_constant28 = _tensor_constant29 = None\n",
      "    getitem_42 = _native_batch_norm_legit_no_training_14[0]\n",
      "    getitem_43 = _native_batch_norm_legit_no_training_14[1];  getitem_43 = None\n",
      "    getitem_44 = _native_batch_norm_legit_no_training_14[2];  _native_batch_norm_legit_no_training_14 = getitem_44 = None\n",
      "    relu__14 = torch.ops.aten.relu_.default(getitem_42);  getitem_42 = None\n",
      "    _param_constant44 = self.features_denseblock2_denselayer1_layers_conv1_weight\n",
      "    conv2d_14 = torch.ops.aten.conv2d.default(relu__14, _param_constant44);  relu__14 = _param_constant44 = None\n",
      "    empty_15 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_15 = None\n",
      "    _param_constant45 = self.features_denseblock2_denselayer1_layers_norm2_weight\n",
      "    _param_constant46 = self.features_denseblock2_denselayer1_layers_norm2_bias\n",
      "    _tensor_constant30 = self.features_denseblock2_denselayer1_layers_norm2_running_mean\n",
      "    _tensor_constant31 = self.features_denseblock2_denselayer1_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, _param_constant45, _param_constant46, _tensor_constant30, _tensor_constant31, 0.1, 1e-05);  conv2d_14 = _param_constant45 = _param_constant46 = _tensor_constant30 = _tensor_constant31 = None\n",
      "    getitem_45 = _native_batch_norm_legit_no_training_15[0]\n",
      "    getitem_46 = _native_batch_norm_legit_no_training_15[1];  getitem_46 = None\n",
      "    getitem_47 = _native_batch_norm_legit_no_training_15[2];  _native_batch_norm_legit_no_training_15 = getitem_47 = None\n",
      "    relu__15 = torch.ops.aten.relu_.default(getitem_45);  getitem_45 = None\n",
      "    _param_constant47 = self.features_denseblock2_denselayer1_layers_conv2_weight\n",
      "    conv2d_15 = torch.ops.aten.conv2d.default(relu__15, _param_constant47, None, [1, 1], [1, 1]);  relu__15 = _param_constant47 = None\n",
      "    cat_6 = torch.ops.aten.cat.default([avg_pool2d, conv2d_15], 1);  avg_pool2d = conv2d_15 = None\n",
      "    empty_16 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_16 = None\n",
      "    _param_constant48 = self.features_denseblock2_denselayer2_layers_norm1_weight\n",
      "    _param_constant49 = self.features_denseblock2_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant32 = self.features_denseblock2_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant33 = self.features_denseblock2_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_6, _param_constant48, _param_constant49, _tensor_constant32, _tensor_constant33, 0.1, 1e-05);  _param_constant48 = _param_constant49 = _tensor_constant32 = _tensor_constant33 = None\n",
      "    getitem_48 = _native_batch_norm_legit_no_training_16[0]\n",
      "    getitem_49 = _native_batch_norm_legit_no_training_16[1];  getitem_49 = None\n",
      "    getitem_50 = _native_batch_norm_legit_no_training_16[2];  _native_batch_norm_legit_no_training_16 = getitem_50 = None\n",
      "    relu__16 = torch.ops.aten.relu_.default(getitem_48);  getitem_48 = None\n",
      "    _param_constant50 = self.features_denseblock2_denselayer2_layers_conv1_weight\n",
      "    conv2d_16 = torch.ops.aten.conv2d.default(relu__16, _param_constant50);  relu__16 = _param_constant50 = None\n",
      "    empty_17 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_17 = None\n",
      "    _param_constant51 = self.features_denseblock2_denselayer2_layers_norm2_weight\n",
      "    _param_constant52 = self.features_denseblock2_denselayer2_layers_norm2_bias\n",
      "    _tensor_constant34 = self.features_denseblock2_denselayer2_layers_norm2_running_mean\n",
      "    _tensor_constant35 = self.features_denseblock2_denselayer2_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, _param_constant51, _param_constant52, _tensor_constant34, _tensor_constant35, 0.1, 1e-05);  conv2d_16 = _param_constant51 = _param_constant52 = _tensor_constant34 = _tensor_constant35 = None\n",
      "    getitem_51 = _native_batch_norm_legit_no_training_17[0]\n",
      "    getitem_52 = _native_batch_norm_legit_no_training_17[1];  getitem_52 = None\n",
      "    getitem_53 = _native_batch_norm_legit_no_training_17[2];  _native_batch_norm_legit_no_training_17 = getitem_53 = None\n",
      "    relu__17 = torch.ops.aten.relu_.default(getitem_51);  getitem_51 = None\n",
      "    _param_constant53 = self.features_denseblock2_denselayer2_layers_conv2_weight\n",
      "    conv2d_17 = torch.ops.aten.conv2d.default(relu__17, _param_constant53, None, [1, 1], [1, 1]);  relu__17 = _param_constant53 = None\n",
      "    cat_7 = torch.ops.aten.cat.default([cat_6, conv2d_17], 1);  cat_6 = conv2d_17 = None\n",
      "    empty_18 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_18 = None\n",
      "    _param_constant54 = self.features_denseblock2_denselayer3_layers_norm1_weight\n",
      "    _param_constant55 = self.features_denseblock2_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant36 = self.features_denseblock2_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant37 = self.features_denseblock2_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_7, _param_constant54, _param_constant55, _tensor_constant36, _tensor_constant37, 0.1, 1e-05);  _param_constant54 = _param_constant55 = _tensor_constant36 = _tensor_constant37 = None\n",
      "    getitem_54 = _native_batch_norm_legit_no_training_18[0]\n",
      "    getitem_55 = _native_batch_norm_legit_no_training_18[1];  getitem_55 = None\n",
      "    getitem_56 = _native_batch_norm_legit_no_training_18[2];  _native_batch_norm_legit_no_training_18 = getitem_56 = None\n",
      "    relu__18 = torch.ops.aten.relu_.default(getitem_54);  getitem_54 = None\n",
      "    _param_constant56 = self.features_denseblock2_denselayer3_layers_conv1_weight\n",
      "    conv2d_18 = torch.ops.aten.conv2d.default(relu__18, _param_constant56);  relu__18 = _param_constant56 = None\n",
      "    empty_19 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_19 = None\n",
      "    _param_constant57 = self.features_denseblock2_denselayer3_layers_norm2_weight\n",
      "    _param_constant58 = self.features_denseblock2_denselayer3_layers_norm2_bias\n",
      "    _tensor_constant38 = self.features_denseblock2_denselayer3_layers_norm2_running_mean\n",
      "    _tensor_constant39 = self.features_denseblock2_denselayer3_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, _param_constant57, _param_constant58, _tensor_constant38, _tensor_constant39, 0.1, 1e-05);  conv2d_18 = _param_constant57 = _param_constant58 = _tensor_constant38 = _tensor_constant39 = None\n",
      "    getitem_57 = _native_batch_norm_legit_no_training_19[0]\n",
      "    getitem_58 = _native_batch_norm_legit_no_training_19[1];  getitem_58 = None\n",
      "    getitem_59 = _native_batch_norm_legit_no_training_19[2];  _native_batch_norm_legit_no_training_19 = getitem_59 = None\n",
      "    relu__19 = torch.ops.aten.relu_.default(getitem_57);  getitem_57 = None\n",
      "    _param_constant59 = self.features_denseblock2_denselayer3_layers_conv2_weight\n",
      "    conv2d_19 = torch.ops.aten.conv2d.default(relu__19, _param_constant59, None, [1, 1], [1, 1]);  relu__19 = _param_constant59 = None\n",
      "    cat_8 = torch.ops.aten.cat.default([cat_7, conv2d_19], 1);  cat_7 = conv2d_19 = None\n",
      "    empty_20 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_20 = None\n",
      "    _param_constant60 = self.features_denseblock2_denselayer4_layers_norm1_weight\n",
      "    _param_constant61 = self.features_denseblock2_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant40 = self.features_denseblock2_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant41 = self.features_denseblock2_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_8, _param_constant60, _param_constant61, _tensor_constant40, _tensor_constant41, 0.1, 1e-05);  _param_constant60 = _param_constant61 = _tensor_constant40 = _tensor_constant41 = None\n",
      "    getitem_60 = _native_batch_norm_legit_no_training_20[0]\n",
      "    getitem_61 = _native_batch_norm_legit_no_training_20[1];  getitem_61 = None\n",
      "    getitem_62 = _native_batch_norm_legit_no_training_20[2];  _native_batch_norm_legit_no_training_20 = getitem_62 = None\n",
      "    relu__20 = torch.ops.aten.relu_.default(getitem_60);  getitem_60 = None\n",
      "    _param_constant62 = self.features_denseblock2_denselayer4_layers_conv1_weight\n",
      "    conv2d_20 = torch.ops.aten.conv2d.default(relu__20, _param_constant62);  relu__20 = _param_constant62 = None\n",
      "    empty_21 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_21 = None\n",
      "    _param_constant63 = self.features_denseblock2_denselayer4_layers_norm2_weight\n",
      "    _param_constant64 = self.features_denseblock2_denselayer4_layers_norm2_bias\n",
      "    _tensor_constant42 = self.features_denseblock2_denselayer4_layers_norm2_running_mean\n",
      "    _tensor_constant43 = self.features_denseblock2_denselayer4_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, _param_constant63, _param_constant64, _tensor_constant42, _tensor_constant43, 0.1, 1e-05);  conv2d_20 = _param_constant63 = _param_constant64 = _tensor_constant42 = _tensor_constant43 = None\n",
      "    getitem_63 = _native_batch_norm_legit_no_training_21[0]\n",
      "    getitem_64 = _native_batch_norm_legit_no_training_21[1];  getitem_64 = None\n",
      "    getitem_65 = _native_batch_norm_legit_no_training_21[2];  _native_batch_norm_legit_no_training_21 = getitem_65 = None\n",
      "    relu__21 = torch.ops.aten.relu_.default(getitem_63);  getitem_63 = None\n",
      "    _param_constant65 = self.features_denseblock2_denselayer4_layers_conv2_weight\n",
      "    conv2d_21 = torch.ops.aten.conv2d.default(relu__21, _param_constant65, None, [1, 1], [1, 1]);  relu__21 = _param_constant65 = None\n",
      "    cat_9 = torch.ops.aten.cat.default([cat_8, conv2d_21], 1);  cat_8 = conv2d_21 = None\n",
      "    empty_22 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_22 = None\n",
      "    _param_constant66 = self.features_denseblock2_denselayer5_layers_norm1_weight\n",
      "    _param_constant67 = self.features_denseblock2_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant44 = self.features_denseblock2_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant45 = self.features_denseblock2_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_9, _param_constant66, _param_constant67, _tensor_constant44, _tensor_constant45, 0.1, 1e-05);  _param_constant66 = _param_constant67 = _tensor_constant44 = _tensor_constant45 = None\n",
      "    getitem_66 = _native_batch_norm_legit_no_training_22[0]\n",
      "    getitem_67 = _native_batch_norm_legit_no_training_22[1];  getitem_67 = None\n",
      "    getitem_68 = _native_batch_norm_legit_no_training_22[2];  _native_batch_norm_legit_no_training_22 = getitem_68 = None\n",
      "    relu__22 = torch.ops.aten.relu_.default(getitem_66);  getitem_66 = None\n",
      "    _param_constant68 = self.features_denseblock2_denselayer5_layers_conv1_weight\n",
      "    conv2d_22 = torch.ops.aten.conv2d.default(relu__22, _param_constant68);  relu__22 = _param_constant68 = None\n",
      "    empty_23 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_23 = None\n",
      "    _param_constant69 = self.features_denseblock2_denselayer5_layers_norm2_weight\n",
      "    _param_constant70 = self.features_denseblock2_denselayer5_layers_norm2_bias\n",
      "    _tensor_constant46 = self.features_denseblock2_denselayer5_layers_norm2_running_mean\n",
      "    _tensor_constant47 = self.features_denseblock2_denselayer5_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_22, _param_constant69, _param_constant70, _tensor_constant46, _tensor_constant47, 0.1, 1e-05);  conv2d_22 = _param_constant69 = _param_constant70 = _tensor_constant46 = _tensor_constant47 = None\n",
      "    getitem_69 = _native_batch_norm_legit_no_training_23[0]\n",
      "    getitem_70 = _native_batch_norm_legit_no_training_23[1];  getitem_70 = None\n",
      "    getitem_71 = _native_batch_norm_legit_no_training_23[2];  _native_batch_norm_legit_no_training_23 = getitem_71 = None\n",
      "    relu__23 = torch.ops.aten.relu_.default(getitem_69);  getitem_69 = None\n",
      "    _param_constant71 = self.features_denseblock2_denselayer5_layers_conv2_weight\n",
      "    conv2d_23 = torch.ops.aten.conv2d.default(relu__23, _param_constant71, None, [1, 1], [1, 1]);  relu__23 = _param_constant71 = None\n",
      "    cat_10 = torch.ops.aten.cat.default([cat_9, conv2d_23], 1);  cat_9 = conv2d_23 = None\n",
      "    empty_24 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_24 = None\n",
      "    _param_constant72 = self.features_denseblock2_denselayer6_layers_norm1_weight\n",
      "    _param_constant73 = self.features_denseblock2_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant48 = self.features_denseblock2_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant49 = self.features_denseblock2_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_10, _param_constant72, _param_constant73, _tensor_constant48, _tensor_constant49, 0.1, 1e-05);  _param_constant72 = _param_constant73 = _tensor_constant48 = _tensor_constant49 = None\n",
      "    getitem_72 = _native_batch_norm_legit_no_training_24[0]\n",
      "    getitem_73 = _native_batch_norm_legit_no_training_24[1];  getitem_73 = None\n",
      "    getitem_74 = _native_batch_norm_legit_no_training_24[2];  _native_batch_norm_legit_no_training_24 = getitem_74 = None\n",
      "    relu__24 = torch.ops.aten.relu_.default(getitem_72);  getitem_72 = None\n",
      "    _param_constant74 = self.features_denseblock2_denselayer6_layers_conv1_weight\n",
      "    conv2d_24 = torch.ops.aten.conv2d.default(relu__24, _param_constant74);  relu__24 = _param_constant74 = None\n",
      "    empty_25 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_25 = None\n",
      "    _param_constant75 = self.features_denseblock2_denselayer6_layers_norm2_weight\n",
      "    _param_constant76 = self.features_denseblock2_denselayer6_layers_norm2_bias\n",
      "    _tensor_constant50 = self.features_denseblock2_denselayer6_layers_norm2_running_mean\n",
      "    _tensor_constant51 = self.features_denseblock2_denselayer6_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_24, _param_constant75, _param_constant76, _tensor_constant50, _tensor_constant51, 0.1, 1e-05);  conv2d_24 = _param_constant75 = _param_constant76 = _tensor_constant50 = _tensor_constant51 = None\n",
      "    getitem_75 = _native_batch_norm_legit_no_training_25[0]\n",
      "    getitem_76 = _native_batch_norm_legit_no_training_25[1];  getitem_76 = None\n",
      "    getitem_77 = _native_batch_norm_legit_no_training_25[2];  _native_batch_norm_legit_no_training_25 = getitem_77 = None\n",
      "    relu__25 = torch.ops.aten.relu_.default(getitem_75);  getitem_75 = None\n",
      "    _param_constant77 = self.features_denseblock2_denselayer6_layers_conv2_weight\n",
      "    conv2d_25 = torch.ops.aten.conv2d.default(relu__25, _param_constant77, None, [1, 1], [1, 1]);  relu__25 = _param_constant77 = None\n",
      "    cat_11 = torch.ops.aten.cat.default([cat_10, conv2d_25], 1);  cat_10 = conv2d_25 = None\n",
      "    empty_26 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_26 = None\n",
      "    _param_constant78 = self.features_denseblock2_denselayer7_layers_norm1_weight\n",
      "    _param_constant79 = self.features_denseblock2_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant52 = self.features_denseblock2_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant53 = self.features_denseblock2_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_11, _param_constant78, _param_constant79, _tensor_constant52, _tensor_constant53, 0.1, 1e-05);  _param_constant78 = _param_constant79 = _tensor_constant52 = _tensor_constant53 = None\n",
      "    getitem_78 = _native_batch_norm_legit_no_training_26[0]\n",
      "    getitem_79 = _native_batch_norm_legit_no_training_26[1];  getitem_79 = None\n",
      "    getitem_80 = _native_batch_norm_legit_no_training_26[2];  _native_batch_norm_legit_no_training_26 = getitem_80 = None\n",
      "    relu__26 = torch.ops.aten.relu_.default(getitem_78);  getitem_78 = None\n",
      "    _param_constant80 = self.features_denseblock2_denselayer7_layers_conv1_weight\n",
      "    conv2d_26 = torch.ops.aten.conv2d.default(relu__26, _param_constant80);  relu__26 = _param_constant80 = None\n",
      "    empty_27 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_27 = None\n",
      "    _param_constant81 = self.features_denseblock2_denselayer7_layers_norm2_weight\n",
      "    _param_constant82 = self.features_denseblock2_denselayer7_layers_norm2_bias\n",
      "    _tensor_constant54 = self.features_denseblock2_denselayer7_layers_norm2_running_mean\n",
      "    _tensor_constant55 = self.features_denseblock2_denselayer7_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_26, _param_constant81, _param_constant82, _tensor_constant54, _tensor_constant55, 0.1, 1e-05);  conv2d_26 = _param_constant81 = _param_constant82 = _tensor_constant54 = _tensor_constant55 = None\n",
      "    getitem_81 = _native_batch_norm_legit_no_training_27[0]\n",
      "    getitem_82 = _native_batch_norm_legit_no_training_27[1];  getitem_82 = None\n",
      "    getitem_83 = _native_batch_norm_legit_no_training_27[2];  _native_batch_norm_legit_no_training_27 = getitem_83 = None\n",
      "    relu__27 = torch.ops.aten.relu_.default(getitem_81);  getitem_81 = None\n",
      "    _param_constant83 = self.features_denseblock2_denselayer7_layers_conv2_weight\n",
      "    conv2d_27 = torch.ops.aten.conv2d.default(relu__27, _param_constant83, None, [1, 1], [1, 1]);  relu__27 = _param_constant83 = None\n",
      "    cat_12 = torch.ops.aten.cat.default([cat_11, conv2d_27], 1);  cat_11 = conv2d_27 = None\n",
      "    empty_28 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_28 = None\n",
      "    _param_constant84 = self.features_denseblock2_denselayer8_layers_norm1_weight\n",
      "    _param_constant85 = self.features_denseblock2_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant56 = self.features_denseblock2_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant57 = self.features_denseblock2_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_12, _param_constant84, _param_constant85, _tensor_constant56, _tensor_constant57, 0.1, 1e-05);  _param_constant84 = _param_constant85 = _tensor_constant56 = _tensor_constant57 = None\n",
      "    getitem_84 = _native_batch_norm_legit_no_training_28[0]\n",
      "    getitem_85 = _native_batch_norm_legit_no_training_28[1];  getitem_85 = None\n",
      "    getitem_86 = _native_batch_norm_legit_no_training_28[2];  _native_batch_norm_legit_no_training_28 = getitem_86 = None\n",
      "    relu__28 = torch.ops.aten.relu_.default(getitem_84);  getitem_84 = None\n",
      "    _param_constant86 = self.features_denseblock2_denselayer8_layers_conv1_weight\n",
      "    conv2d_28 = torch.ops.aten.conv2d.default(relu__28, _param_constant86);  relu__28 = _param_constant86 = None\n",
      "    empty_29 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_29 = None\n",
      "    _param_constant87 = self.features_denseblock2_denselayer8_layers_norm2_weight\n",
      "    _param_constant88 = self.features_denseblock2_denselayer8_layers_norm2_bias\n",
      "    _tensor_constant58 = self.features_denseblock2_denselayer8_layers_norm2_running_mean\n",
      "    _tensor_constant59 = self.features_denseblock2_denselayer8_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, _param_constant87, _param_constant88, _tensor_constant58, _tensor_constant59, 0.1, 1e-05);  conv2d_28 = _param_constant87 = _param_constant88 = _tensor_constant58 = _tensor_constant59 = None\n",
      "    getitem_87 = _native_batch_norm_legit_no_training_29[0]\n",
      "    getitem_88 = _native_batch_norm_legit_no_training_29[1];  getitem_88 = None\n",
      "    getitem_89 = _native_batch_norm_legit_no_training_29[2];  _native_batch_norm_legit_no_training_29 = getitem_89 = None\n",
      "    relu__29 = torch.ops.aten.relu_.default(getitem_87);  getitem_87 = None\n",
      "    _param_constant89 = self.features_denseblock2_denselayer8_layers_conv2_weight\n",
      "    conv2d_29 = torch.ops.aten.conv2d.default(relu__29, _param_constant89, None, [1, 1], [1, 1]);  relu__29 = _param_constant89 = None\n",
      "    cat_13 = torch.ops.aten.cat.default([cat_12, conv2d_29], 1);  cat_12 = conv2d_29 = None\n",
      "    empty_30 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_30 = None\n",
      "    _param_constant90 = self.features_denseblock2_denselayer9_layers_norm1_weight\n",
      "    _param_constant91 = self.features_denseblock2_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant60 = self.features_denseblock2_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant61 = self.features_denseblock2_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_13, _param_constant90, _param_constant91, _tensor_constant60, _tensor_constant61, 0.1, 1e-05);  _param_constant90 = _param_constant91 = _tensor_constant60 = _tensor_constant61 = None\n",
      "    getitem_90 = _native_batch_norm_legit_no_training_30[0]\n",
      "    getitem_91 = _native_batch_norm_legit_no_training_30[1];  getitem_91 = None\n",
      "    getitem_92 = _native_batch_norm_legit_no_training_30[2];  _native_batch_norm_legit_no_training_30 = getitem_92 = None\n",
      "    relu__30 = torch.ops.aten.relu_.default(getitem_90);  getitem_90 = None\n",
      "    _param_constant92 = self.features_denseblock2_denselayer9_layers_conv1_weight\n",
      "    conv2d_30 = torch.ops.aten.conv2d.default(relu__30, _param_constant92);  relu__30 = _param_constant92 = None\n",
      "    empty_31 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_31 = None\n",
      "    _param_constant93 = self.features_denseblock2_denselayer9_layers_norm2_weight\n",
      "    _param_constant94 = self.features_denseblock2_denselayer9_layers_norm2_bias\n",
      "    _tensor_constant62 = self.features_denseblock2_denselayer9_layers_norm2_running_mean\n",
      "    _tensor_constant63 = self.features_denseblock2_denselayer9_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, _param_constant93, _param_constant94, _tensor_constant62, _tensor_constant63, 0.1, 1e-05);  conv2d_30 = _param_constant93 = _param_constant94 = _tensor_constant62 = _tensor_constant63 = None\n",
      "    getitem_93 = _native_batch_norm_legit_no_training_31[0]\n",
      "    getitem_94 = _native_batch_norm_legit_no_training_31[1];  getitem_94 = None\n",
      "    getitem_95 = _native_batch_norm_legit_no_training_31[2];  _native_batch_norm_legit_no_training_31 = getitem_95 = None\n",
      "    relu__31 = torch.ops.aten.relu_.default(getitem_93);  getitem_93 = None\n",
      "    _param_constant95 = self.features_denseblock2_denselayer9_layers_conv2_weight\n",
      "    conv2d_31 = torch.ops.aten.conv2d.default(relu__31, _param_constant95, None, [1, 1], [1, 1]);  relu__31 = _param_constant95 = None\n",
      "    cat_14 = torch.ops.aten.cat.default([cat_13, conv2d_31], 1);  cat_13 = conv2d_31 = None\n",
      "    empty_32 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_32 = None\n",
      "    _param_constant96 = self.features_denseblock2_denselayer10_layers_norm1_weight\n",
      "    _param_constant97 = self.features_denseblock2_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant64 = self.features_denseblock2_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant65 = self.features_denseblock2_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_14, _param_constant96, _param_constant97, _tensor_constant64, _tensor_constant65, 0.1, 1e-05);  _param_constant96 = _param_constant97 = _tensor_constant64 = _tensor_constant65 = None\n",
      "    getitem_96 = _native_batch_norm_legit_no_training_32[0]\n",
      "    getitem_97 = _native_batch_norm_legit_no_training_32[1];  getitem_97 = None\n",
      "    getitem_98 = _native_batch_norm_legit_no_training_32[2];  _native_batch_norm_legit_no_training_32 = getitem_98 = None\n",
      "    relu__32 = torch.ops.aten.relu_.default(getitem_96);  getitem_96 = None\n",
      "    _param_constant98 = self.features_denseblock2_denselayer10_layers_conv1_weight\n",
      "    conv2d_32 = torch.ops.aten.conv2d.default(relu__32, _param_constant98);  relu__32 = _param_constant98 = None\n",
      "    empty_33 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_33 = None\n",
      "    _param_constant99 = self.features_denseblock2_denselayer10_layers_norm2_weight\n",
      "    _param_constant100 = self.features_denseblock2_denselayer10_layers_norm2_bias\n",
      "    _tensor_constant66 = self.features_denseblock2_denselayer10_layers_norm2_running_mean\n",
      "    _tensor_constant67 = self.features_denseblock2_denselayer10_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_32, _param_constant99, _param_constant100, _tensor_constant66, _tensor_constant67, 0.1, 1e-05);  conv2d_32 = _param_constant99 = _param_constant100 = _tensor_constant66 = _tensor_constant67 = None\n",
      "    getitem_99 = _native_batch_norm_legit_no_training_33[0]\n",
      "    getitem_100 = _native_batch_norm_legit_no_training_33[1];  getitem_100 = None\n",
      "    getitem_101 = _native_batch_norm_legit_no_training_33[2];  _native_batch_norm_legit_no_training_33 = getitem_101 = None\n",
      "    relu__33 = torch.ops.aten.relu_.default(getitem_99);  getitem_99 = None\n",
      "    _param_constant101 = self.features_denseblock2_denselayer10_layers_conv2_weight\n",
      "    conv2d_33 = torch.ops.aten.conv2d.default(relu__33, _param_constant101, None, [1, 1], [1, 1]);  relu__33 = _param_constant101 = None\n",
      "    cat_15 = torch.ops.aten.cat.default([cat_14, conv2d_33], 1);  cat_14 = conv2d_33 = None\n",
      "    empty_34 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_34 = None\n",
      "    _param_constant102 = self.features_denseblock2_denselayer11_layers_norm1_weight\n",
      "    _param_constant103 = self.features_denseblock2_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant68 = self.features_denseblock2_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant69 = self.features_denseblock2_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_15, _param_constant102, _param_constant103, _tensor_constant68, _tensor_constant69, 0.1, 1e-05);  _param_constant102 = _param_constant103 = _tensor_constant68 = _tensor_constant69 = None\n",
      "    getitem_102 = _native_batch_norm_legit_no_training_34[0]\n",
      "    getitem_103 = _native_batch_norm_legit_no_training_34[1];  getitem_103 = None\n",
      "    getitem_104 = _native_batch_norm_legit_no_training_34[2];  _native_batch_norm_legit_no_training_34 = getitem_104 = None\n",
      "    relu__34 = torch.ops.aten.relu_.default(getitem_102);  getitem_102 = None\n",
      "    _param_constant104 = self.features_denseblock2_denselayer11_layers_conv1_weight\n",
      "    conv2d_34 = torch.ops.aten.conv2d.default(relu__34, _param_constant104);  relu__34 = _param_constant104 = None\n",
      "    empty_35 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_35 = None\n",
      "    _param_constant105 = self.features_denseblock2_denselayer11_layers_norm2_weight\n",
      "    _param_constant106 = self.features_denseblock2_denselayer11_layers_norm2_bias\n",
      "    _tensor_constant70 = self.features_denseblock2_denselayer11_layers_norm2_running_mean\n",
      "    _tensor_constant71 = self.features_denseblock2_denselayer11_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_34, _param_constant105, _param_constant106, _tensor_constant70, _tensor_constant71, 0.1, 1e-05);  conv2d_34 = _param_constant105 = _param_constant106 = _tensor_constant70 = _tensor_constant71 = None\n",
      "    getitem_105 = _native_batch_norm_legit_no_training_35[0]\n",
      "    getitem_106 = _native_batch_norm_legit_no_training_35[1];  getitem_106 = None\n",
      "    getitem_107 = _native_batch_norm_legit_no_training_35[2];  _native_batch_norm_legit_no_training_35 = getitem_107 = None\n",
      "    relu__35 = torch.ops.aten.relu_.default(getitem_105);  getitem_105 = None\n",
      "    _param_constant107 = self.features_denseblock2_denselayer11_layers_conv2_weight\n",
      "    conv2d_35 = torch.ops.aten.conv2d.default(relu__35, _param_constant107, None, [1, 1], [1, 1]);  relu__35 = _param_constant107 = None\n",
      "    cat_16 = torch.ops.aten.cat.default([cat_15, conv2d_35], 1);  cat_15 = conv2d_35 = None\n",
      "    empty_36 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_36 = None\n",
      "    _param_constant108 = self.features_denseblock2_denselayer12_layers_norm1_weight\n",
      "    _param_constant109 = self.features_denseblock2_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant72 = self.features_denseblock2_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant73 = self.features_denseblock2_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_16, _param_constant108, _param_constant109, _tensor_constant72, _tensor_constant73, 0.1, 1e-05);  _param_constant108 = _param_constant109 = _tensor_constant72 = _tensor_constant73 = None\n",
      "    getitem_108 = _native_batch_norm_legit_no_training_36[0]\n",
      "    getitem_109 = _native_batch_norm_legit_no_training_36[1];  getitem_109 = None\n",
      "    getitem_110 = _native_batch_norm_legit_no_training_36[2];  _native_batch_norm_legit_no_training_36 = getitem_110 = None\n",
      "    relu__36 = torch.ops.aten.relu_.default(getitem_108);  getitem_108 = None\n",
      "    _param_constant110 = self.features_denseblock2_denselayer12_layers_conv1_weight\n",
      "    conv2d_36 = torch.ops.aten.conv2d.default(relu__36, _param_constant110);  relu__36 = _param_constant110 = None\n",
      "    empty_37 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_37 = None\n",
      "    _param_constant111 = self.features_denseblock2_denselayer12_layers_norm2_weight\n",
      "    _param_constant112 = self.features_denseblock2_denselayer12_layers_norm2_bias\n",
      "    _tensor_constant74 = self.features_denseblock2_denselayer12_layers_norm2_running_mean\n",
      "    _tensor_constant75 = self.features_denseblock2_denselayer12_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_36, _param_constant111, _param_constant112, _tensor_constant74, _tensor_constant75, 0.1, 1e-05);  conv2d_36 = _param_constant111 = _param_constant112 = _tensor_constant74 = _tensor_constant75 = None\n",
      "    getitem_111 = _native_batch_norm_legit_no_training_37[0]\n",
      "    getitem_112 = _native_batch_norm_legit_no_training_37[1];  getitem_112 = None\n",
      "    getitem_113 = _native_batch_norm_legit_no_training_37[2];  _native_batch_norm_legit_no_training_37 = getitem_113 = None\n",
      "    relu__37 = torch.ops.aten.relu_.default(getitem_111);  getitem_111 = None\n",
      "    _param_constant113 = self.features_denseblock2_denselayer12_layers_conv2_weight\n",
      "    conv2d_37 = torch.ops.aten.conv2d.default(relu__37, _param_constant113, None, [1, 1], [1, 1]);  relu__37 = _param_constant113 = None\n",
      "    cat_17 = torch.ops.aten.cat.default([cat_16, conv2d_37], 1);  cat_16 = conv2d_37 = None\n",
      "    empty_38 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_38 = None\n",
      "    _param_constant114 = self.features_transition2_norm_weight\n",
      "    _param_constant115 = self.features_transition2_norm_bias\n",
      "    _tensor_constant76 = self.features_transition2_norm_running_mean\n",
      "    _tensor_constant77 = self.features_transition2_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_17, _param_constant114, _param_constant115, _tensor_constant76, _tensor_constant77, 0.1, 1e-05);  cat_17 = _param_constant114 = _param_constant115 = _tensor_constant76 = _tensor_constant77 = None\n",
      "    getitem_114 = _native_batch_norm_legit_no_training_38[0]\n",
      "    getitem_115 = _native_batch_norm_legit_no_training_38[1];  getitem_115 = None\n",
      "    getitem_116 = _native_batch_norm_legit_no_training_38[2];  _native_batch_norm_legit_no_training_38 = getitem_116 = None\n",
      "    relu__38 = torch.ops.aten.relu_.default(getitem_114);  getitem_114 = None\n",
      "    _param_constant116 = self.features_transition2_conv_weight\n",
      "    conv2d_38 = torch.ops.aten.conv2d.default(relu__38, _param_constant116);  relu__38 = _param_constant116 = None\n",
      "    avg_pool2d_1 = torch.ops.aten.avg_pool2d.default(conv2d_38, [2, 2], [2, 2]);  conv2d_38 = None\n",
      "    empty_39 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_39 = None\n",
      "    _param_constant117 = self.features_denseblock3_denselayer1_layers_norm1_weight\n",
      "    _param_constant118 = self.features_denseblock3_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant78 = self.features_denseblock3_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant79 = self.features_denseblock3_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_1, _param_constant117, _param_constant118, _tensor_constant78, _tensor_constant79, 0.1, 1e-05);  _param_constant117 = _param_constant118 = _tensor_constant78 = _tensor_constant79 = None\n",
      "    getitem_117 = _native_batch_norm_legit_no_training_39[0]\n",
      "    getitem_118 = _native_batch_norm_legit_no_training_39[1];  getitem_118 = None\n",
      "    getitem_119 = _native_batch_norm_legit_no_training_39[2];  _native_batch_norm_legit_no_training_39 = getitem_119 = None\n",
      "    relu__39 = torch.ops.aten.relu_.default(getitem_117);  getitem_117 = None\n",
      "    _param_constant119 = self.features_denseblock3_denselayer1_layers_conv1_weight\n",
      "    conv2d_39 = torch.ops.aten.conv2d.default(relu__39, _param_constant119);  relu__39 = _param_constant119 = None\n",
      "    empty_40 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_40 = None\n",
      "    _param_constant120 = self.features_denseblock3_denselayer1_layers_norm2_weight\n",
      "    _param_constant121 = self.features_denseblock3_denselayer1_layers_norm2_bias\n",
      "    _tensor_constant80 = self.features_denseblock3_denselayer1_layers_norm2_running_mean\n",
      "    _tensor_constant81 = self.features_denseblock3_denselayer1_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_39, _param_constant120, _param_constant121, _tensor_constant80, _tensor_constant81, 0.1, 1e-05);  conv2d_39 = _param_constant120 = _param_constant121 = _tensor_constant80 = _tensor_constant81 = None\n",
      "    getitem_120 = _native_batch_norm_legit_no_training_40[0]\n",
      "    getitem_121 = _native_batch_norm_legit_no_training_40[1];  getitem_121 = None\n",
      "    getitem_122 = _native_batch_norm_legit_no_training_40[2];  _native_batch_norm_legit_no_training_40 = getitem_122 = None\n",
      "    relu__40 = torch.ops.aten.relu_.default(getitem_120);  getitem_120 = None\n",
      "    _param_constant122 = self.features_denseblock3_denselayer1_layers_conv2_weight\n",
      "    conv2d_40 = torch.ops.aten.conv2d.default(relu__40, _param_constant122, None, [1, 1], [1, 1]);  relu__40 = _param_constant122 = None\n",
      "    cat_18 = torch.ops.aten.cat.default([avg_pool2d_1, conv2d_40], 1);  avg_pool2d_1 = conv2d_40 = None\n",
      "    empty_41 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_41 = None\n",
      "    _param_constant123 = self.features_denseblock3_denselayer2_layers_norm1_weight\n",
      "    _param_constant124 = self.features_denseblock3_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant82 = self.features_denseblock3_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant83 = self.features_denseblock3_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_18, _param_constant123, _param_constant124, _tensor_constant82, _tensor_constant83, 0.1, 1e-05);  _param_constant123 = _param_constant124 = _tensor_constant82 = _tensor_constant83 = None\n",
      "    getitem_123 = _native_batch_norm_legit_no_training_41[0]\n",
      "    getitem_124 = _native_batch_norm_legit_no_training_41[1];  getitem_124 = None\n",
      "    getitem_125 = _native_batch_norm_legit_no_training_41[2];  _native_batch_norm_legit_no_training_41 = getitem_125 = None\n",
      "    relu__41 = torch.ops.aten.relu_.default(getitem_123);  getitem_123 = None\n",
      "    _param_constant125 = self.features_denseblock3_denselayer2_layers_conv1_weight\n",
      "    conv2d_41 = torch.ops.aten.conv2d.default(relu__41, _param_constant125);  relu__41 = _param_constant125 = None\n",
      "    empty_42 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_42 = None\n",
      "    _param_constant126 = self.features_denseblock3_denselayer2_layers_norm2_weight\n",
      "    _param_constant127 = self.features_denseblock3_denselayer2_layers_norm2_bias\n",
      "    _tensor_constant84 = self.features_denseblock3_denselayer2_layers_norm2_running_mean\n",
      "    _tensor_constant85 = self.features_denseblock3_denselayer2_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_41, _param_constant126, _param_constant127, _tensor_constant84, _tensor_constant85, 0.1, 1e-05);  conv2d_41 = _param_constant126 = _param_constant127 = _tensor_constant84 = _tensor_constant85 = None\n",
      "    getitem_126 = _native_batch_norm_legit_no_training_42[0]\n",
      "    getitem_127 = _native_batch_norm_legit_no_training_42[1];  getitem_127 = None\n",
      "    getitem_128 = _native_batch_norm_legit_no_training_42[2];  _native_batch_norm_legit_no_training_42 = getitem_128 = None\n",
      "    relu__42 = torch.ops.aten.relu_.default(getitem_126);  getitem_126 = None\n",
      "    _param_constant128 = self.features_denseblock3_denselayer2_layers_conv2_weight\n",
      "    conv2d_42 = torch.ops.aten.conv2d.default(relu__42, _param_constant128, None, [1, 1], [1, 1]);  relu__42 = _param_constant128 = None\n",
      "    cat_19 = torch.ops.aten.cat.default([cat_18, conv2d_42], 1);  cat_18 = conv2d_42 = None\n",
      "    empty_43 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_43 = None\n",
      "    _param_constant129 = self.features_denseblock3_denselayer3_layers_norm1_weight\n",
      "    _param_constant130 = self.features_denseblock3_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant86 = self.features_denseblock3_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant87 = self.features_denseblock3_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_19, _param_constant129, _param_constant130, _tensor_constant86, _tensor_constant87, 0.1, 1e-05);  _param_constant129 = _param_constant130 = _tensor_constant86 = _tensor_constant87 = None\n",
      "    getitem_129 = _native_batch_norm_legit_no_training_43[0]\n",
      "    getitem_130 = _native_batch_norm_legit_no_training_43[1];  getitem_130 = None\n",
      "    getitem_131 = _native_batch_norm_legit_no_training_43[2];  _native_batch_norm_legit_no_training_43 = getitem_131 = None\n",
      "    relu__43 = torch.ops.aten.relu_.default(getitem_129);  getitem_129 = None\n",
      "    _param_constant131 = self.features_denseblock3_denselayer3_layers_conv1_weight\n",
      "    conv2d_43 = torch.ops.aten.conv2d.default(relu__43, _param_constant131);  relu__43 = _param_constant131 = None\n",
      "    empty_44 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_44 = None\n",
      "    _param_constant132 = self.features_denseblock3_denselayer3_layers_norm2_weight\n",
      "    _param_constant133 = self.features_denseblock3_denselayer3_layers_norm2_bias\n",
      "    _tensor_constant88 = self.features_denseblock3_denselayer3_layers_norm2_running_mean\n",
      "    _tensor_constant89 = self.features_denseblock3_denselayer3_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_43, _param_constant132, _param_constant133, _tensor_constant88, _tensor_constant89, 0.1, 1e-05);  conv2d_43 = _param_constant132 = _param_constant133 = _tensor_constant88 = _tensor_constant89 = None\n",
      "    getitem_132 = _native_batch_norm_legit_no_training_44[0]\n",
      "    getitem_133 = _native_batch_norm_legit_no_training_44[1];  getitem_133 = None\n",
      "    getitem_134 = _native_batch_norm_legit_no_training_44[2];  _native_batch_norm_legit_no_training_44 = getitem_134 = None\n",
      "    relu__44 = torch.ops.aten.relu_.default(getitem_132);  getitem_132 = None\n",
      "    _param_constant134 = self.features_denseblock3_denselayer3_layers_conv2_weight\n",
      "    conv2d_44 = torch.ops.aten.conv2d.default(relu__44, _param_constant134, None, [1, 1], [1, 1]);  relu__44 = _param_constant134 = None\n",
      "    cat_20 = torch.ops.aten.cat.default([cat_19, conv2d_44], 1);  cat_19 = conv2d_44 = None\n",
      "    empty_45 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_45 = None\n",
      "    _param_constant135 = self.features_denseblock3_denselayer4_layers_norm1_weight\n",
      "    _param_constant136 = self.features_denseblock3_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant90 = self.features_denseblock3_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant91 = self.features_denseblock3_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_20, _param_constant135, _param_constant136, _tensor_constant90, _tensor_constant91, 0.1, 1e-05);  _param_constant135 = _param_constant136 = _tensor_constant90 = _tensor_constant91 = None\n",
      "    getitem_135 = _native_batch_norm_legit_no_training_45[0]\n",
      "    getitem_136 = _native_batch_norm_legit_no_training_45[1];  getitem_136 = None\n",
      "    getitem_137 = _native_batch_norm_legit_no_training_45[2];  _native_batch_norm_legit_no_training_45 = getitem_137 = None\n",
      "    relu__45 = torch.ops.aten.relu_.default(getitem_135);  getitem_135 = None\n",
      "    _param_constant137 = self.features_denseblock3_denselayer4_layers_conv1_weight\n",
      "    conv2d_45 = torch.ops.aten.conv2d.default(relu__45, _param_constant137);  relu__45 = _param_constant137 = None\n",
      "    empty_46 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_46 = None\n",
      "    _param_constant138 = self.features_denseblock3_denselayer4_layers_norm2_weight\n",
      "    _param_constant139 = self.features_denseblock3_denselayer4_layers_norm2_bias\n",
      "    _tensor_constant92 = self.features_denseblock3_denselayer4_layers_norm2_running_mean\n",
      "    _tensor_constant93 = self.features_denseblock3_denselayer4_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_45, _param_constant138, _param_constant139, _tensor_constant92, _tensor_constant93, 0.1, 1e-05);  conv2d_45 = _param_constant138 = _param_constant139 = _tensor_constant92 = _tensor_constant93 = None\n",
      "    getitem_138 = _native_batch_norm_legit_no_training_46[0]\n",
      "    getitem_139 = _native_batch_norm_legit_no_training_46[1];  getitem_139 = None\n",
      "    getitem_140 = _native_batch_norm_legit_no_training_46[2];  _native_batch_norm_legit_no_training_46 = getitem_140 = None\n",
      "    relu__46 = torch.ops.aten.relu_.default(getitem_138);  getitem_138 = None\n",
      "    _param_constant140 = self.features_denseblock3_denselayer4_layers_conv2_weight\n",
      "    conv2d_46 = torch.ops.aten.conv2d.default(relu__46, _param_constant140, None, [1, 1], [1, 1]);  relu__46 = _param_constant140 = None\n",
      "    cat_21 = torch.ops.aten.cat.default([cat_20, conv2d_46], 1);  cat_20 = conv2d_46 = None\n",
      "    empty_47 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_47 = None\n",
      "    _param_constant141 = self.features_denseblock3_denselayer5_layers_norm1_weight\n",
      "    _param_constant142 = self.features_denseblock3_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant94 = self.features_denseblock3_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant95 = self.features_denseblock3_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_21, _param_constant141, _param_constant142, _tensor_constant94, _tensor_constant95, 0.1, 1e-05);  _param_constant141 = _param_constant142 = _tensor_constant94 = _tensor_constant95 = None\n",
      "    getitem_141 = _native_batch_norm_legit_no_training_47[0]\n",
      "    getitem_142 = _native_batch_norm_legit_no_training_47[1];  getitem_142 = None\n",
      "    getitem_143 = _native_batch_norm_legit_no_training_47[2];  _native_batch_norm_legit_no_training_47 = getitem_143 = None\n",
      "    relu__47 = torch.ops.aten.relu_.default(getitem_141);  getitem_141 = None\n",
      "    _param_constant143 = self.features_denseblock3_denselayer5_layers_conv1_weight\n",
      "    conv2d_47 = torch.ops.aten.conv2d.default(relu__47, _param_constant143);  relu__47 = _param_constant143 = None\n",
      "    empty_48 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_48 = None\n",
      "    _param_constant144 = self.features_denseblock3_denselayer5_layers_norm2_weight\n",
      "    _param_constant145 = self.features_denseblock3_denselayer5_layers_norm2_bias\n",
      "    _tensor_constant96 = self.features_denseblock3_denselayer5_layers_norm2_running_mean\n",
      "    _tensor_constant97 = self.features_denseblock3_denselayer5_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_47, _param_constant144, _param_constant145, _tensor_constant96, _tensor_constant97, 0.1, 1e-05);  conv2d_47 = _param_constant144 = _param_constant145 = _tensor_constant96 = _tensor_constant97 = None\n",
      "    getitem_144 = _native_batch_norm_legit_no_training_48[0]\n",
      "    getitem_145 = _native_batch_norm_legit_no_training_48[1];  getitem_145 = None\n",
      "    getitem_146 = _native_batch_norm_legit_no_training_48[2];  _native_batch_norm_legit_no_training_48 = getitem_146 = None\n",
      "    relu__48 = torch.ops.aten.relu_.default(getitem_144);  getitem_144 = None\n",
      "    _param_constant146 = self.features_denseblock3_denselayer5_layers_conv2_weight\n",
      "    conv2d_48 = torch.ops.aten.conv2d.default(relu__48, _param_constant146, None, [1, 1], [1, 1]);  relu__48 = _param_constant146 = None\n",
      "    cat_22 = torch.ops.aten.cat.default([cat_21, conv2d_48], 1);  cat_21 = conv2d_48 = None\n",
      "    empty_49 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_49 = None\n",
      "    _param_constant147 = self.features_denseblock3_denselayer6_layers_norm1_weight\n",
      "    _param_constant148 = self.features_denseblock3_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant98 = self.features_denseblock3_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant99 = self.features_denseblock3_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_22, _param_constant147, _param_constant148, _tensor_constant98, _tensor_constant99, 0.1, 1e-05);  _param_constant147 = _param_constant148 = _tensor_constant98 = _tensor_constant99 = None\n",
      "    getitem_147 = _native_batch_norm_legit_no_training_49[0]\n",
      "    getitem_148 = _native_batch_norm_legit_no_training_49[1];  getitem_148 = None\n",
      "    getitem_149 = _native_batch_norm_legit_no_training_49[2];  _native_batch_norm_legit_no_training_49 = getitem_149 = None\n",
      "    relu__49 = torch.ops.aten.relu_.default(getitem_147);  getitem_147 = None\n",
      "    _param_constant149 = self.features_denseblock3_denselayer6_layers_conv1_weight\n",
      "    conv2d_49 = torch.ops.aten.conv2d.default(relu__49, _param_constant149);  relu__49 = _param_constant149 = None\n",
      "    empty_50 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_50 = None\n",
      "    _param_constant150 = self.features_denseblock3_denselayer6_layers_norm2_weight\n",
      "    _param_constant151 = self.features_denseblock3_denselayer6_layers_norm2_bias\n",
      "    _tensor_constant100 = self.features_denseblock3_denselayer6_layers_norm2_running_mean\n",
      "    _tensor_constant101 = self.features_denseblock3_denselayer6_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, _param_constant150, _param_constant151, _tensor_constant100, _tensor_constant101, 0.1, 1e-05);  conv2d_49 = _param_constant150 = _param_constant151 = _tensor_constant100 = _tensor_constant101 = None\n",
      "    getitem_150 = _native_batch_norm_legit_no_training_50[0]\n",
      "    getitem_151 = _native_batch_norm_legit_no_training_50[1];  getitem_151 = None\n",
      "    getitem_152 = _native_batch_norm_legit_no_training_50[2];  _native_batch_norm_legit_no_training_50 = getitem_152 = None\n",
      "    relu__50 = torch.ops.aten.relu_.default(getitem_150);  getitem_150 = None\n",
      "    _param_constant152 = self.features_denseblock3_denselayer6_layers_conv2_weight\n",
      "    conv2d_50 = torch.ops.aten.conv2d.default(relu__50, _param_constant152, None, [1, 1], [1, 1]);  relu__50 = _param_constant152 = None\n",
      "    cat_23 = torch.ops.aten.cat.default([cat_22, conv2d_50], 1);  cat_22 = conv2d_50 = None\n",
      "    empty_51 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_51 = None\n",
      "    _param_constant153 = self.features_denseblock3_denselayer7_layers_norm1_weight\n",
      "    _param_constant154 = self.features_denseblock3_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant102 = self.features_denseblock3_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant103 = self.features_denseblock3_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_23, _param_constant153, _param_constant154, _tensor_constant102, _tensor_constant103, 0.1, 1e-05);  _param_constant153 = _param_constant154 = _tensor_constant102 = _tensor_constant103 = None\n",
      "    getitem_153 = _native_batch_norm_legit_no_training_51[0]\n",
      "    getitem_154 = _native_batch_norm_legit_no_training_51[1];  getitem_154 = None\n",
      "    getitem_155 = _native_batch_norm_legit_no_training_51[2];  _native_batch_norm_legit_no_training_51 = getitem_155 = None\n",
      "    relu__51 = torch.ops.aten.relu_.default(getitem_153);  getitem_153 = None\n",
      "    _param_constant155 = self.features_denseblock3_denselayer7_layers_conv1_weight\n",
      "    conv2d_51 = torch.ops.aten.conv2d.default(relu__51, _param_constant155);  relu__51 = _param_constant155 = None\n",
      "    empty_52 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_52 = None\n",
      "    _param_constant156 = self.features_denseblock3_denselayer7_layers_norm2_weight\n",
      "    _param_constant157 = self.features_denseblock3_denselayer7_layers_norm2_bias\n",
      "    _tensor_constant104 = self.features_denseblock3_denselayer7_layers_norm2_running_mean\n",
      "    _tensor_constant105 = self.features_denseblock3_denselayer7_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_52 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_51, _param_constant156, _param_constant157, _tensor_constant104, _tensor_constant105, 0.1, 1e-05);  conv2d_51 = _param_constant156 = _param_constant157 = _tensor_constant104 = _tensor_constant105 = None\n",
      "    getitem_156 = _native_batch_norm_legit_no_training_52[0]\n",
      "    getitem_157 = _native_batch_norm_legit_no_training_52[1];  getitem_157 = None\n",
      "    getitem_158 = _native_batch_norm_legit_no_training_52[2];  _native_batch_norm_legit_no_training_52 = getitem_158 = None\n",
      "    relu__52 = torch.ops.aten.relu_.default(getitem_156);  getitem_156 = None\n",
      "    _param_constant158 = self.features_denseblock3_denselayer7_layers_conv2_weight\n",
      "    conv2d_52 = torch.ops.aten.conv2d.default(relu__52, _param_constant158, None, [1, 1], [1, 1]);  relu__52 = _param_constant158 = None\n",
      "    cat_24 = torch.ops.aten.cat.default([cat_23, conv2d_52], 1);  cat_23 = conv2d_52 = None\n",
      "    empty_53 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_53 = None\n",
      "    _param_constant159 = self.features_denseblock3_denselayer8_layers_norm1_weight\n",
      "    _param_constant160 = self.features_denseblock3_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant106 = self.features_denseblock3_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant107 = self.features_denseblock3_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_53 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_24, _param_constant159, _param_constant160, _tensor_constant106, _tensor_constant107, 0.1, 1e-05);  _param_constant159 = _param_constant160 = _tensor_constant106 = _tensor_constant107 = None\n",
      "    getitem_159 = _native_batch_norm_legit_no_training_53[0]\n",
      "    getitem_160 = _native_batch_norm_legit_no_training_53[1];  getitem_160 = None\n",
      "    getitem_161 = _native_batch_norm_legit_no_training_53[2];  _native_batch_norm_legit_no_training_53 = getitem_161 = None\n",
      "    relu__53 = torch.ops.aten.relu_.default(getitem_159);  getitem_159 = None\n",
      "    _param_constant161 = self.features_denseblock3_denselayer8_layers_conv1_weight\n",
      "    conv2d_53 = torch.ops.aten.conv2d.default(relu__53, _param_constant161);  relu__53 = _param_constant161 = None\n",
      "    empty_54 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_54 = None\n",
      "    _param_constant162 = self.features_denseblock3_denselayer8_layers_norm2_weight\n",
      "    _param_constant163 = self.features_denseblock3_denselayer8_layers_norm2_bias\n",
      "    _tensor_constant108 = self.features_denseblock3_denselayer8_layers_norm2_running_mean\n",
      "    _tensor_constant109 = self.features_denseblock3_denselayer8_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_54 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_53, _param_constant162, _param_constant163, _tensor_constant108, _tensor_constant109, 0.1, 1e-05);  conv2d_53 = _param_constant162 = _param_constant163 = _tensor_constant108 = _tensor_constant109 = None\n",
      "    getitem_162 = _native_batch_norm_legit_no_training_54[0]\n",
      "    getitem_163 = _native_batch_norm_legit_no_training_54[1];  getitem_163 = None\n",
      "    getitem_164 = _native_batch_norm_legit_no_training_54[2];  _native_batch_norm_legit_no_training_54 = getitem_164 = None\n",
      "    relu__54 = torch.ops.aten.relu_.default(getitem_162);  getitem_162 = None\n",
      "    _param_constant164 = self.features_denseblock3_denselayer8_layers_conv2_weight\n",
      "    conv2d_54 = torch.ops.aten.conv2d.default(relu__54, _param_constant164, None, [1, 1], [1, 1]);  relu__54 = _param_constant164 = None\n",
      "    cat_25 = torch.ops.aten.cat.default([cat_24, conv2d_54], 1);  cat_24 = conv2d_54 = None\n",
      "    empty_55 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_55 = None\n",
      "    _param_constant165 = self.features_denseblock3_denselayer9_layers_norm1_weight\n",
      "    _param_constant166 = self.features_denseblock3_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant110 = self.features_denseblock3_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant111 = self.features_denseblock3_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_55 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_25, _param_constant165, _param_constant166, _tensor_constant110, _tensor_constant111, 0.1, 1e-05);  _param_constant165 = _param_constant166 = _tensor_constant110 = _tensor_constant111 = None\n",
      "    getitem_165 = _native_batch_norm_legit_no_training_55[0]\n",
      "    getitem_166 = _native_batch_norm_legit_no_training_55[1];  getitem_166 = None\n",
      "    getitem_167 = _native_batch_norm_legit_no_training_55[2];  _native_batch_norm_legit_no_training_55 = getitem_167 = None\n",
      "    relu__55 = torch.ops.aten.relu_.default(getitem_165);  getitem_165 = None\n",
      "    _param_constant167 = self.features_denseblock3_denselayer9_layers_conv1_weight\n",
      "    conv2d_55 = torch.ops.aten.conv2d.default(relu__55, _param_constant167);  relu__55 = _param_constant167 = None\n",
      "    empty_56 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_56 = None\n",
      "    _param_constant168 = self.features_denseblock3_denselayer9_layers_norm2_weight\n",
      "    _param_constant169 = self.features_denseblock3_denselayer9_layers_norm2_bias\n",
      "    _tensor_constant112 = self.features_denseblock3_denselayer9_layers_norm2_running_mean\n",
      "    _tensor_constant113 = self.features_denseblock3_denselayer9_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_56 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_55, _param_constant168, _param_constant169, _tensor_constant112, _tensor_constant113, 0.1, 1e-05);  conv2d_55 = _param_constant168 = _param_constant169 = _tensor_constant112 = _tensor_constant113 = None\n",
      "    getitem_168 = _native_batch_norm_legit_no_training_56[0]\n",
      "    getitem_169 = _native_batch_norm_legit_no_training_56[1];  getitem_169 = None\n",
      "    getitem_170 = _native_batch_norm_legit_no_training_56[2];  _native_batch_norm_legit_no_training_56 = getitem_170 = None\n",
      "    relu__56 = torch.ops.aten.relu_.default(getitem_168);  getitem_168 = None\n",
      "    _param_constant170 = self.features_denseblock3_denselayer9_layers_conv2_weight\n",
      "    conv2d_56 = torch.ops.aten.conv2d.default(relu__56, _param_constant170, None, [1, 1], [1, 1]);  relu__56 = _param_constant170 = None\n",
      "    cat_26 = torch.ops.aten.cat.default([cat_25, conv2d_56], 1);  cat_25 = conv2d_56 = None\n",
      "    empty_57 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_57 = None\n",
      "    _param_constant171 = self.features_denseblock3_denselayer10_layers_norm1_weight\n",
      "    _param_constant172 = self.features_denseblock3_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant114 = self.features_denseblock3_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant115 = self.features_denseblock3_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_57 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_26, _param_constant171, _param_constant172, _tensor_constant114, _tensor_constant115, 0.1, 1e-05);  _param_constant171 = _param_constant172 = _tensor_constant114 = _tensor_constant115 = None\n",
      "    getitem_171 = _native_batch_norm_legit_no_training_57[0]\n",
      "    getitem_172 = _native_batch_norm_legit_no_training_57[1];  getitem_172 = None\n",
      "    getitem_173 = _native_batch_norm_legit_no_training_57[2];  _native_batch_norm_legit_no_training_57 = getitem_173 = None\n",
      "    relu__57 = torch.ops.aten.relu_.default(getitem_171);  getitem_171 = None\n",
      "    _param_constant173 = self.features_denseblock3_denselayer10_layers_conv1_weight\n",
      "    conv2d_57 = torch.ops.aten.conv2d.default(relu__57, _param_constant173);  relu__57 = _param_constant173 = None\n",
      "    empty_58 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_58 = None\n",
      "    _param_constant174 = self.features_denseblock3_denselayer10_layers_norm2_weight\n",
      "    _param_constant175 = self.features_denseblock3_denselayer10_layers_norm2_bias\n",
      "    _tensor_constant116 = self.features_denseblock3_denselayer10_layers_norm2_running_mean\n",
      "    _tensor_constant117 = self.features_denseblock3_denselayer10_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_58 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_57, _param_constant174, _param_constant175, _tensor_constant116, _tensor_constant117, 0.1, 1e-05);  conv2d_57 = _param_constant174 = _param_constant175 = _tensor_constant116 = _tensor_constant117 = None\n",
      "    getitem_174 = _native_batch_norm_legit_no_training_58[0]\n",
      "    getitem_175 = _native_batch_norm_legit_no_training_58[1];  getitem_175 = None\n",
      "    getitem_176 = _native_batch_norm_legit_no_training_58[2];  _native_batch_norm_legit_no_training_58 = getitem_176 = None\n",
      "    relu__58 = torch.ops.aten.relu_.default(getitem_174);  getitem_174 = None\n",
      "    _param_constant176 = self.features_denseblock3_denselayer10_layers_conv2_weight\n",
      "    conv2d_58 = torch.ops.aten.conv2d.default(relu__58, _param_constant176, None, [1, 1], [1, 1]);  relu__58 = _param_constant176 = None\n",
      "    cat_27 = torch.ops.aten.cat.default([cat_26, conv2d_58], 1);  cat_26 = conv2d_58 = None\n",
      "    empty_59 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_59 = None\n",
      "    _param_constant177 = self.features_denseblock3_denselayer11_layers_norm1_weight\n",
      "    _param_constant178 = self.features_denseblock3_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant118 = self.features_denseblock3_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant119 = self.features_denseblock3_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_59 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_27, _param_constant177, _param_constant178, _tensor_constant118, _tensor_constant119, 0.1, 1e-05);  _param_constant177 = _param_constant178 = _tensor_constant118 = _tensor_constant119 = None\n",
      "    getitem_177 = _native_batch_norm_legit_no_training_59[0]\n",
      "    getitem_178 = _native_batch_norm_legit_no_training_59[1];  getitem_178 = None\n",
      "    getitem_179 = _native_batch_norm_legit_no_training_59[2];  _native_batch_norm_legit_no_training_59 = getitem_179 = None\n",
      "    relu__59 = torch.ops.aten.relu_.default(getitem_177);  getitem_177 = None\n",
      "    _param_constant179 = self.features_denseblock3_denselayer11_layers_conv1_weight\n",
      "    conv2d_59 = torch.ops.aten.conv2d.default(relu__59, _param_constant179);  relu__59 = _param_constant179 = None\n",
      "    empty_60 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_60 = None\n",
      "    _param_constant180 = self.features_denseblock3_denselayer11_layers_norm2_weight\n",
      "    _param_constant181 = self.features_denseblock3_denselayer11_layers_norm2_bias\n",
      "    _tensor_constant120 = self.features_denseblock3_denselayer11_layers_norm2_running_mean\n",
      "    _tensor_constant121 = self.features_denseblock3_denselayer11_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_60 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_59, _param_constant180, _param_constant181, _tensor_constant120, _tensor_constant121, 0.1, 1e-05);  conv2d_59 = _param_constant180 = _param_constant181 = _tensor_constant120 = _tensor_constant121 = None\n",
      "    getitem_180 = _native_batch_norm_legit_no_training_60[0]\n",
      "    getitem_181 = _native_batch_norm_legit_no_training_60[1];  getitem_181 = None\n",
      "    getitem_182 = _native_batch_norm_legit_no_training_60[2];  _native_batch_norm_legit_no_training_60 = getitem_182 = None\n",
      "    relu__60 = torch.ops.aten.relu_.default(getitem_180);  getitem_180 = None\n",
      "    _param_constant182 = self.features_denseblock3_denselayer11_layers_conv2_weight\n",
      "    conv2d_60 = torch.ops.aten.conv2d.default(relu__60, _param_constant182, None, [1, 1], [1, 1]);  relu__60 = _param_constant182 = None\n",
      "    cat_28 = torch.ops.aten.cat.default([cat_27, conv2d_60], 1);  cat_27 = conv2d_60 = None\n",
      "    empty_61 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_61 = None\n",
      "    _param_constant183 = self.features_denseblock3_denselayer12_layers_norm1_weight\n",
      "    _param_constant184 = self.features_denseblock3_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant122 = self.features_denseblock3_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant123 = self.features_denseblock3_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_61 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_28, _param_constant183, _param_constant184, _tensor_constant122, _tensor_constant123, 0.1, 1e-05);  _param_constant183 = _param_constant184 = _tensor_constant122 = _tensor_constant123 = None\n",
      "    getitem_183 = _native_batch_norm_legit_no_training_61[0]\n",
      "    getitem_184 = _native_batch_norm_legit_no_training_61[1];  getitem_184 = None\n",
      "    getitem_185 = _native_batch_norm_legit_no_training_61[2];  _native_batch_norm_legit_no_training_61 = getitem_185 = None\n",
      "    relu__61 = torch.ops.aten.relu_.default(getitem_183);  getitem_183 = None\n",
      "    _param_constant185 = self.features_denseblock3_denselayer12_layers_conv1_weight\n",
      "    conv2d_61 = torch.ops.aten.conv2d.default(relu__61, _param_constant185);  relu__61 = _param_constant185 = None\n",
      "    empty_62 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_62 = None\n",
      "    _param_constant186 = self.features_denseblock3_denselayer12_layers_norm2_weight\n",
      "    _param_constant187 = self.features_denseblock3_denselayer12_layers_norm2_bias\n",
      "    _tensor_constant124 = self.features_denseblock3_denselayer12_layers_norm2_running_mean\n",
      "    _tensor_constant125 = self.features_denseblock3_denselayer12_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_62 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_61, _param_constant186, _param_constant187, _tensor_constant124, _tensor_constant125, 0.1, 1e-05);  conv2d_61 = _param_constant186 = _param_constant187 = _tensor_constant124 = _tensor_constant125 = None\n",
      "    getitem_186 = _native_batch_norm_legit_no_training_62[0]\n",
      "    getitem_187 = _native_batch_norm_legit_no_training_62[1];  getitem_187 = None\n",
      "    getitem_188 = _native_batch_norm_legit_no_training_62[2];  _native_batch_norm_legit_no_training_62 = getitem_188 = None\n",
      "    relu__62 = torch.ops.aten.relu_.default(getitem_186);  getitem_186 = None\n",
      "    _param_constant188 = self.features_denseblock3_denselayer12_layers_conv2_weight\n",
      "    conv2d_62 = torch.ops.aten.conv2d.default(relu__62, _param_constant188, None, [1, 1], [1, 1]);  relu__62 = _param_constant188 = None\n",
      "    cat_29 = torch.ops.aten.cat.default([cat_28, conv2d_62], 1);  cat_28 = conv2d_62 = None\n",
      "    empty_63 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_63 = None\n",
      "    _param_constant189 = self.features_denseblock3_denselayer13_layers_norm1_weight\n",
      "    _param_constant190 = self.features_denseblock3_denselayer13_layers_norm1_bias\n",
      "    _tensor_constant126 = self.features_denseblock3_denselayer13_layers_norm1_running_mean\n",
      "    _tensor_constant127 = self.features_denseblock3_denselayer13_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_63 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_29, _param_constant189, _param_constant190, _tensor_constant126, _tensor_constant127, 0.1, 1e-05);  _param_constant189 = _param_constant190 = _tensor_constant126 = _tensor_constant127 = None\n",
      "    getitem_189 = _native_batch_norm_legit_no_training_63[0]\n",
      "    getitem_190 = _native_batch_norm_legit_no_training_63[1];  getitem_190 = None\n",
      "    getitem_191 = _native_batch_norm_legit_no_training_63[2];  _native_batch_norm_legit_no_training_63 = getitem_191 = None\n",
      "    relu__63 = torch.ops.aten.relu_.default(getitem_189);  getitem_189 = None\n",
      "    _param_constant191 = self.features_denseblock3_denselayer13_layers_conv1_weight\n",
      "    conv2d_63 = torch.ops.aten.conv2d.default(relu__63, _param_constant191);  relu__63 = _param_constant191 = None\n",
      "    empty_64 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_64 = None\n",
      "    _param_constant192 = self.features_denseblock3_denselayer13_layers_norm2_weight\n",
      "    _param_constant193 = self.features_denseblock3_denselayer13_layers_norm2_bias\n",
      "    _tensor_constant128 = self.features_denseblock3_denselayer13_layers_norm2_running_mean\n",
      "    _tensor_constant129 = self.features_denseblock3_denselayer13_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_64 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_63, _param_constant192, _param_constant193, _tensor_constant128, _tensor_constant129, 0.1, 1e-05);  conv2d_63 = _param_constant192 = _param_constant193 = _tensor_constant128 = _tensor_constant129 = None\n",
      "    getitem_192 = _native_batch_norm_legit_no_training_64[0]\n",
      "    getitem_193 = _native_batch_norm_legit_no_training_64[1];  getitem_193 = None\n",
      "    getitem_194 = _native_batch_norm_legit_no_training_64[2];  _native_batch_norm_legit_no_training_64 = getitem_194 = None\n",
      "    relu__64 = torch.ops.aten.relu_.default(getitem_192);  getitem_192 = None\n",
      "    _param_constant194 = self.features_denseblock3_denselayer13_layers_conv2_weight\n",
      "    conv2d_64 = torch.ops.aten.conv2d.default(relu__64, _param_constant194, None, [1, 1], [1, 1]);  relu__64 = _param_constant194 = None\n",
      "    cat_30 = torch.ops.aten.cat.default([cat_29, conv2d_64], 1);  cat_29 = conv2d_64 = None\n",
      "    empty_65 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_65 = None\n",
      "    _param_constant195 = self.features_denseblock3_denselayer14_layers_norm1_weight\n",
      "    _param_constant196 = self.features_denseblock3_denselayer14_layers_norm1_bias\n",
      "    _tensor_constant130 = self.features_denseblock3_denselayer14_layers_norm1_running_mean\n",
      "    _tensor_constant131 = self.features_denseblock3_denselayer14_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_65 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_30, _param_constant195, _param_constant196, _tensor_constant130, _tensor_constant131, 0.1, 1e-05);  _param_constant195 = _param_constant196 = _tensor_constant130 = _tensor_constant131 = None\n",
      "    getitem_195 = _native_batch_norm_legit_no_training_65[0]\n",
      "    getitem_196 = _native_batch_norm_legit_no_training_65[1];  getitem_196 = None\n",
      "    getitem_197 = _native_batch_norm_legit_no_training_65[2];  _native_batch_norm_legit_no_training_65 = getitem_197 = None\n",
      "    relu__65 = torch.ops.aten.relu_.default(getitem_195);  getitem_195 = None\n",
      "    _param_constant197 = self.features_denseblock3_denselayer14_layers_conv1_weight\n",
      "    conv2d_65 = torch.ops.aten.conv2d.default(relu__65, _param_constant197);  relu__65 = _param_constant197 = None\n",
      "    empty_66 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_66 = None\n",
      "    _param_constant198 = self.features_denseblock3_denselayer14_layers_norm2_weight\n",
      "    _param_constant199 = self.features_denseblock3_denselayer14_layers_norm2_bias\n",
      "    _tensor_constant132 = self.features_denseblock3_denselayer14_layers_norm2_running_mean\n",
      "    _tensor_constant133 = self.features_denseblock3_denselayer14_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_66 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_65, _param_constant198, _param_constant199, _tensor_constant132, _tensor_constant133, 0.1, 1e-05);  conv2d_65 = _param_constant198 = _param_constant199 = _tensor_constant132 = _tensor_constant133 = None\n",
      "    getitem_198 = _native_batch_norm_legit_no_training_66[0]\n",
      "    getitem_199 = _native_batch_norm_legit_no_training_66[1];  getitem_199 = None\n",
      "    getitem_200 = _native_batch_norm_legit_no_training_66[2];  _native_batch_norm_legit_no_training_66 = getitem_200 = None\n",
      "    relu__66 = torch.ops.aten.relu_.default(getitem_198);  getitem_198 = None\n",
      "    _param_constant200 = self.features_denseblock3_denselayer14_layers_conv2_weight\n",
      "    conv2d_66 = torch.ops.aten.conv2d.default(relu__66, _param_constant200, None, [1, 1], [1, 1]);  relu__66 = _param_constant200 = None\n",
      "    cat_31 = torch.ops.aten.cat.default([cat_30, conv2d_66], 1);  cat_30 = conv2d_66 = None\n",
      "    empty_67 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_67 = None\n",
      "    _param_constant201 = self.features_denseblock3_denselayer15_layers_norm1_weight\n",
      "    _param_constant202 = self.features_denseblock3_denselayer15_layers_norm1_bias\n",
      "    _tensor_constant134 = self.features_denseblock3_denselayer15_layers_norm1_running_mean\n",
      "    _tensor_constant135 = self.features_denseblock3_denselayer15_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_67 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_31, _param_constant201, _param_constant202, _tensor_constant134, _tensor_constant135, 0.1, 1e-05);  _param_constant201 = _param_constant202 = _tensor_constant134 = _tensor_constant135 = None\n",
      "    getitem_201 = _native_batch_norm_legit_no_training_67[0]\n",
      "    getitem_202 = _native_batch_norm_legit_no_training_67[1];  getitem_202 = None\n",
      "    getitem_203 = _native_batch_norm_legit_no_training_67[2];  _native_batch_norm_legit_no_training_67 = getitem_203 = None\n",
      "    relu__67 = torch.ops.aten.relu_.default(getitem_201);  getitem_201 = None\n",
      "    _param_constant203 = self.features_denseblock3_denselayer15_layers_conv1_weight\n",
      "    conv2d_67 = torch.ops.aten.conv2d.default(relu__67, _param_constant203);  relu__67 = _param_constant203 = None\n",
      "    empty_68 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_68 = None\n",
      "    _param_constant204 = self.features_denseblock3_denselayer15_layers_norm2_weight\n",
      "    _param_constant205 = self.features_denseblock3_denselayer15_layers_norm2_bias\n",
      "    _tensor_constant136 = self.features_denseblock3_denselayer15_layers_norm2_running_mean\n",
      "    _tensor_constant137 = self.features_denseblock3_denselayer15_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_68 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_67, _param_constant204, _param_constant205, _tensor_constant136, _tensor_constant137, 0.1, 1e-05);  conv2d_67 = _param_constant204 = _param_constant205 = _tensor_constant136 = _tensor_constant137 = None\n",
      "    getitem_204 = _native_batch_norm_legit_no_training_68[0]\n",
      "    getitem_205 = _native_batch_norm_legit_no_training_68[1];  getitem_205 = None\n",
      "    getitem_206 = _native_batch_norm_legit_no_training_68[2];  _native_batch_norm_legit_no_training_68 = getitem_206 = None\n",
      "    relu__68 = torch.ops.aten.relu_.default(getitem_204);  getitem_204 = None\n",
      "    _param_constant206 = self.features_denseblock3_denselayer15_layers_conv2_weight\n",
      "    conv2d_68 = torch.ops.aten.conv2d.default(relu__68, _param_constant206, None, [1, 1], [1, 1]);  relu__68 = _param_constant206 = None\n",
      "    cat_32 = torch.ops.aten.cat.default([cat_31, conv2d_68], 1);  cat_31 = conv2d_68 = None\n",
      "    empty_69 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_69 = None\n",
      "    _param_constant207 = self.features_denseblock3_denselayer16_layers_norm1_weight\n",
      "    _param_constant208 = self.features_denseblock3_denselayer16_layers_norm1_bias\n",
      "    _tensor_constant138 = self.features_denseblock3_denselayer16_layers_norm1_running_mean\n",
      "    _tensor_constant139 = self.features_denseblock3_denselayer16_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_69 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_32, _param_constant207, _param_constant208, _tensor_constant138, _tensor_constant139, 0.1, 1e-05);  _param_constant207 = _param_constant208 = _tensor_constant138 = _tensor_constant139 = None\n",
      "    getitem_207 = _native_batch_norm_legit_no_training_69[0]\n",
      "    getitem_208 = _native_batch_norm_legit_no_training_69[1];  getitem_208 = None\n",
      "    getitem_209 = _native_batch_norm_legit_no_training_69[2];  _native_batch_norm_legit_no_training_69 = getitem_209 = None\n",
      "    relu__69 = torch.ops.aten.relu_.default(getitem_207);  getitem_207 = None\n",
      "    _param_constant209 = self.features_denseblock3_denselayer16_layers_conv1_weight\n",
      "    conv2d_69 = torch.ops.aten.conv2d.default(relu__69, _param_constant209);  relu__69 = _param_constant209 = None\n",
      "    empty_70 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_70 = None\n",
      "    _param_constant210 = self.features_denseblock3_denselayer16_layers_norm2_weight\n",
      "    _param_constant211 = self.features_denseblock3_denselayer16_layers_norm2_bias\n",
      "    _tensor_constant140 = self.features_denseblock3_denselayer16_layers_norm2_running_mean\n",
      "    _tensor_constant141 = self.features_denseblock3_denselayer16_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_70 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_69, _param_constant210, _param_constant211, _tensor_constant140, _tensor_constant141, 0.1, 1e-05);  conv2d_69 = _param_constant210 = _param_constant211 = _tensor_constant140 = _tensor_constant141 = None\n",
      "    getitem_210 = _native_batch_norm_legit_no_training_70[0]\n",
      "    getitem_211 = _native_batch_norm_legit_no_training_70[1];  getitem_211 = None\n",
      "    getitem_212 = _native_batch_norm_legit_no_training_70[2];  _native_batch_norm_legit_no_training_70 = getitem_212 = None\n",
      "    relu__70 = torch.ops.aten.relu_.default(getitem_210);  getitem_210 = None\n",
      "    _param_constant212 = self.features_denseblock3_denselayer16_layers_conv2_weight\n",
      "    conv2d_70 = torch.ops.aten.conv2d.default(relu__70, _param_constant212, None, [1, 1], [1, 1]);  relu__70 = _param_constant212 = None\n",
      "    cat_33 = torch.ops.aten.cat.default([cat_32, conv2d_70], 1);  cat_32 = conv2d_70 = None\n",
      "    empty_71 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_71 = None\n",
      "    _param_constant213 = self.features_denseblock3_denselayer17_layers_norm1_weight\n",
      "    _param_constant214 = self.features_denseblock3_denselayer17_layers_norm1_bias\n",
      "    _tensor_constant142 = self.features_denseblock3_denselayer17_layers_norm1_running_mean\n",
      "    _tensor_constant143 = self.features_denseblock3_denselayer17_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_71 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_33, _param_constant213, _param_constant214, _tensor_constant142, _tensor_constant143, 0.1, 1e-05);  _param_constant213 = _param_constant214 = _tensor_constant142 = _tensor_constant143 = None\n",
      "    getitem_213 = _native_batch_norm_legit_no_training_71[0]\n",
      "    getitem_214 = _native_batch_norm_legit_no_training_71[1];  getitem_214 = None\n",
      "    getitem_215 = _native_batch_norm_legit_no_training_71[2];  _native_batch_norm_legit_no_training_71 = getitem_215 = None\n",
      "    relu__71 = torch.ops.aten.relu_.default(getitem_213);  getitem_213 = None\n",
      "    _param_constant215 = self.features_denseblock3_denselayer17_layers_conv1_weight\n",
      "    conv2d_71 = torch.ops.aten.conv2d.default(relu__71, _param_constant215);  relu__71 = _param_constant215 = None\n",
      "    empty_72 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_72 = None\n",
      "    _param_constant216 = self.features_denseblock3_denselayer17_layers_norm2_weight\n",
      "    _param_constant217 = self.features_denseblock3_denselayer17_layers_norm2_bias\n",
      "    _tensor_constant144 = self.features_denseblock3_denselayer17_layers_norm2_running_mean\n",
      "    _tensor_constant145 = self.features_denseblock3_denselayer17_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_72 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_71, _param_constant216, _param_constant217, _tensor_constant144, _tensor_constant145, 0.1, 1e-05);  conv2d_71 = _param_constant216 = _param_constant217 = _tensor_constant144 = _tensor_constant145 = None\n",
      "    getitem_216 = _native_batch_norm_legit_no_training_72[0]\n",
      "    getitem_217 = _native_batch_norm_legit_no_training_72[1];  getitem_217 = None\n",
      "    getitem_218 = _native_batch_norm_legit_no_training_72[2];  _native_batch_norm_legit_no_training_72 = getitem_218 = None\n",
      "    relu__72 = torch.ops.aten.relu_.default(getitem_216);  getitem_216 = None\n",
      "    _param_constant218 = self.features_denseblock3_denselayer17_layers_conv2_weight\n",
      "    conv2d_72 = torch.ops.aten.conv2d.default(relu__72, _param_constant218, None, [1, 1], [1, 1]);  relu__72 = _param_constant218 = None\n",
      "    cat_34 = torch.ops.aten.cat.default([cat_33, conv2d_72], 1);  cat_33 = conv2d_72 = None\n",
      "    empty_73 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_73 = None\n",
      "    _param_constant219 = self.features_denseblock3_denselayer18_layers_norm1_weight\n",
      "    _param_constant220 = self.features_denseblock3_denselayer18_layers_norm1_bias\n",
      "    _tensor_constant146 = self.features_denseblock3_denselayer18_layers_norm1_running_mean\n",
      "    _tensor_constant147 = self.features_denseblock3_denselayer18_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_73 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_34, _param_constant219, _param_constant220, _tensor_constant146, _tensor_constant147, 0.1, 1e-05);  _param_constant219 = _param_constant220 = _tensor_constant146 = _tensor_constant147 = None\n",
      "    getitem_219 = _native_batch_norm_legit_no_training_73[0]\n",
      "    getitem_220 = _native_batch_norm_legit_no_training_73[1];  getitem_220 = None\n",
      "    getitem_221 = _native_batch_norm_legit_no_training_73[2];  _native_batch_norm_legit_no_training_73 = getitem_221 = None\n",
      "    relu__73 = torch.ops.aten.relu_.default(getitem_219);  getitem_219 = None\n",
      "    _param_constant221 = self.features_denseblock3_denselayer18_layers_conv1_weight\n",
      "    conv2d_73 = torch.ops.aten.conv2d.default(relu__73, _param_constant221);  relu__73 = _param_constant221 = None\n",
      "    empty_74 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_74 = None\n",
      "    _param_constant222 = self.features_denseblock3_denselayer18_layers_norm2_weight\n",
      "    _param_constant223 = self.features_denseblock3_denselayer18_layers_norm2_bias\n",
      "    _tensor_constant148 = self.features_denseblock3_denselayer18_layers_norm2_running_mean\n",
      "    _tensor_constant149 = self.features_denseblock3_denselayer18_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_74 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_73, _param_constant222, _param_constant223, _tensor_constant148, _tensor_constant149, 0.1, 1e-05);  conv2d_73 = _param_constant222 = _param_constant223 = _tensor_constant148 = _tensor_constant149 = None\n",
      "    getitem_222 = _native_batch_norm_legit_no_training_74[0]\n",
      "    getitem_223 = _native_batch_norm_legit_no_training_74[1];  getitem_223 = None\n",
      "    getitem_224 = _native_batch_norm_legit_no_training_74[2];  _native_batch_norm_legit_no_training_74 = getitem_224 = None\n",
      "    relu__74 = torch.ops.aten.relu_.default(getitem_222);  getitem_222 = None\n",
      "    _param_constant224 = self.features_denseblock3_denselayer18_layers_conv2_weight\n",
      "    conv2d_74 = torch.ops.aten.conv2d.default(relu__74, _param_constant224, None, [1, 1], [1, 1]);  relu__74 = _param_constant224 = None\n",
      "    cat_35 = torch.ops.aten.cat.default([cat_34, conv2d_74], 1);  cat_34 = conv2d_74 = None\n",
      "    empty_75 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_75 = None\n",
      "    _param_constant225 = self.features_denseblock3_denselayer19_layers_norm1_weight\n",
      "    _param_constant226 = self.features_denseblock3_denselayer19_layers_norm1_bias\n",
      "    _tensor_constant150 = self.features_denseblock3_denselayer19_layers_norm1_running_mean\n",
      "    _tensor_constant151 = self.features_denseblock3_denselayer19_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_75 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_35, _param_constant225, _param_constant226, _tensor_constant150, _tensor_constant151, 0.1, 1e-05);  _param_constant225 = _param_constant226 = _tensor_constant150 = _tensor_constant151 = None\n",
      "    getitem_225 = _native_batch_norm_legit_no_training_75[0]\n",
      "    getitem_226 = _native_batch_norm_legit_no_training_75[1];  getitem_226 = None\n",
      "    getitem_227 = _native_batch_norm_legit_no_training_75[2];  _native_batch_norm_legit_no_training_75 = getitem_227 = None\n",
      "    relu__75 = torch.ops.aten.relu_.default(getitem_225);  getitem_225 = None\n",
      "    _param_constant227 = self.features_denseblock3_denselayer19_layers_conv1_weight\n",
      "    conv2d_75 = torch.ops.aten.conv2d.default(relu__75, _param_constant227);  relu__75 = _param_constant227 = None\n",
      "    empty_76 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_76 = None\n",
      "    _param_constant228 = self.features_denseblock3_denselayer19_layers_norm2_weight\n",
      "    _param_constant229 = self.features_denseblock3_denselayer19_layers_norm2_bias\n",
      "    _tensor_constant152 = self.features_denseblock3_denselayer19_layers_norm2_running_mean\n",
      "    _tensor_constant153 = self.features_denseblock3_denselayer19_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_76 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_75, _param_constant228, _param_constant229, _tensor_constant152, _tensor_constant153, 0.1, 1e-05);  conv2d_75 = _param_constant228 = _param_constant229 = _tensor_constant152 = _tensor_constant153 = None\n",
      "    getitem_228 = _native_batch_norm_legit_no_training_76[0]\n",
      "    getitem_229 = _native_batch_norm_legit_no_training_76[1];  getitem_229 = None\n",
      "    getitem_230 = _native_batch_norm_legit_no_training_76[2];  _native_batch_norm_legit_no_training_76 = getitem_230 = None\n",
      "    relu__76 = torch.ops.aten.relu_.default(getitem_228);  getitem_228 = None\n",
      "    _param_constant230 = self.features_denseblock3_denselayer19_layers_conv2_weight\n",
      "    conv2d_76 = torch.ops.aten.conv2d.default(relu__76, _param_constant230, None, [1, 1], [1, 1]);  relu__76 = _param_constant230 = None\n",
      "    cat_36 = torch.ops.aten.cat.default([cat_35, conv2d_76], 1);  cat_35 = conv2d_76 = None\n",
      "    empty_77 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_77 = None\n",
      "    _param_constant231 = self.features_denseblock3_denselayer20_layers_norm1_weight\n",
      "    _param_constant232 = self.features_denseblock3_denselayer20_layers_norm1_bias\n",
      "    _tensor_constant154 = self.features_denseblock3_denselayer20_layers_norm1_running_mean\n",
      "    _tensor_constant155 = self.features_denseblock3_denselayer20_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_77 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_36, _param_constant231, _param_constant232, _tensor_constant154, _tensor_constant155, 0.1, 1e-05);  _param_constant231 = _param_constant232 = _tensor_constant154 = _tensor_constant155 = None\n",
      "    getitem_231 = _native_batch_norm_legit_no_training_77[0]\n",
      "    getitem_232 = _native_batch_norm_legit_no_training_77[1];  getitem_232 = None\n",
      "    getitem_233 = _native_batch_norm_legit_no_training_77[2];  _native_batch_norm_legit_no_training_77 = getitem_233 = None\n",
      "    relu__77 = torch.ops.aten.relu_.default(getitem_231);  getitem_231 = None\n",
      "    _param_constant233 = self.features_denseblock3_denselayer20_layers_conv1_weight\n",
      "    conv2d_77 = torch.ops.aten.conv2d.default(relu__77, _param_constant233);  relu__77 = _param_constant233 = None\n",
      "    empty_78 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_78 = None\n",
      "    _param_constant234 = self.features_denseblock3_denselayer20_layers_norm2_weight\n",
      "    _param_constant235 = self.features_denseblock3_denselayer20_layers_norm2_bias\n",
      "    _tensor_constant156 = self.features_denseblock3_denselayer20_layers_norm2_running_mean\n",
      "    _tensor_constant157 = self.features_denseblock3_denselayer20_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_78 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_77, _param_constant234, _param_constant235, _tensor_constant156, _tensor_constant157, 0.1, 1e-05);  conv2d_77 = _param_constant234 = _param_constant235 = _tensor_constant156 = _tensor_constant157 = None\n",
      "    getitem_234 = _native_batch_norm_legit_no_training_78[0]\n",
      "    getitem_235 = _native_batch_norm_legit_no_training_78[1];  getitem_235 = None\n",
      "    getitem_236 = _native_batch_norm_legit_no_training_78[2];  _native_batch_norm_legit_no_training_78 = getitem_236 = None\n",
      "    relu__78 = torch.ops.aten.relu_.default(getitem_234);  getitem_234 = None\n",
      "    _param_constant236 = self.features_denseblock3_denselayer20_layers_conv2_weight\n",
      "    conv2d_78 = torch.ops.aten.conv2d.default(relu__78, _param_constant236, None, [1, 1], [1, 1]);  relu__78 = _param_constant236 = None\n",
      "    cat_37 = torch.ops.aten.cat.default([cat_36, conv2d_78], 1);  cat_36 = conv2d_78 = None\n",
      "    empty_79 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_79 = None\n",
      "    _param_constant237 = self.features_denseblock3_denselayer21_layers_norm1_weight\n",
      "    _param_constant238 = self.features_denseblock3_denselayer21_layers_norm1_bias\n",
      "    _tensor_constant158 = self.features_denseblock3_denselayer21_layers_norm1_running_mean\n",
      "    _tensor_constant159 = self.features_denseblock3_denselayer21_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_79 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_37, _param_constant237, _param_constant238, _tensor_constant158, _tensor_constant159, 0.1, 1e-05);  _param_constant237 = _param_constant238 = _tensor_constant158 = _tensor_constant159 = None\n",
      "    getitem_237 = _native_batch_norm_legit_no_training_79[0]\n",
      "    getitem_238 = _native_batch_norm_legit_no_training_79[1];  getitem_238 = None\n",
      "    getitem_239 = _native_batch_norm_legit_no_training_79[2];  _native_batch_norm_legit_no_training_79 = getitem_239 = None\n",
      "    relu__79 = torch.ops.aten.relu_.default(getitem_237);  getitem_237 = None\n",
      "    _param_constant239 = self.features_denseblock3_denselayer21_layers_conv1_weight\n",
      "    conv2d_79 = torch.ops.aten.conv2d.default(relu__79, _param_constant239);  relu__79 = _param_constant239 = None\n",
      "    empty_80 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_80 = None\n",
      "    _param_constant240 = self.features_denseblock3_denselayer21_layers_norm2_weight\n",
      "    _param_constant241 = self.features_denseblock3_denselayer21_layers_norm2_bias\n",
      "    _tensor_constant160 = self.features_denseblock3_denselayer21_layers_norm2_running_mean\n",
      "    _tensor_constant161 = self.features_denseblock3_denselayer21_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_80 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_79, _param_constant240, _param_constant241, _tensor_constant160, _tensor_constant161, 0.1, 1e-05);  conv2d_79 = _param_constant240 = _param_constant241 = _tensor_constant160 = _tensor_constant161 = None\n",
      "    getitem_240 = _native_batch_norm_legit_no_training_80[0]\n",
      "    getitem_241 = _native_batch_norm_legit_no_training_80[1];  getitem_241 = None\n",
      "    getitem_242 = _native_batch_norm_legit_no_training_80[2];  _native_batch_norm_legit_no_training_80 = getitem_242 = None\n",
      "    relu__80 = torch.ops.aten.relu_.default(getitem_240);  getitem_240 = None\n",
      "    _param_constant242 = self.features_denseblock3_denselayer21_layers_conv2_weight\n",
      "    conv2d_80 = torch.ops.aten.conv2d.default(relu__80, _param_constant242, None, [1, 1], [1, 1]);  relu__80 = _param_constant242 = None\n",
      "    cat_38 = torch.ops.aten.cat.default([cat_37, conv2d_80], 1);  cat_37 = conv2d_80 = None\n",
      "    empty_81 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_81 = None\n",
      "    _param_constant243 = self.features_denseblock3_denselayer22_layers_norm1_weight\n",
      "    _param_constant244 = self.features_denseblock3_denselayer22_layers_norm1_bias\n",
      "    _tensor_constant162 = self.features_denseblock3_denselayer22_layers_norm1_running_mean\n",
      "    _tensor_constant163 = self.features_denseblock3_denselayer22_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_81 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_38, _param_constant243, _param_constant244, _tensor_constant162, _tensor_constant163, 0.1, 1e-05);  _param_constant243 = _param_constant244 = _tensor_constant162 = _tensor_constant163 = None\n",
      "    getitem_243 = _native_batch_norm_legit_no_training_81[0]\n",
      "    getitem_244 = _native_batch_norm_legit_no_training_81[1];  getitem_244 = None\n",
      "    getitem_245 = _native_batch_norm_legit_no_training_81[2];  _native_batch_norm_legit_no_training_81 = getitem_245 = None\n",
      "    relu__81 = torch.ops.aten.relu_.default(getitem_243);  getitem_243 = None\n",
      "    _param_constant245 = self.features_denseblock3_denselayer22_layers_conv1_weight\n",
      "    conv2d_81 = torch.ops.aten.conv2d.default(relu__81, _param_constant245);  relu__81 = _param_constant245 = None\n",
      "    empty_82 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_82 = None\n",
      "    _param_constant246 = self.features_denseblock3_denselayer22_layers_norm2_weight\n",
      "    _param_constant247 = self.features_denseblock3_denselayer22_layers_norm2_bias\n",
      "    _tensor_constant164 = self.features_denseblock3_denselayer22_layers_norm2_running_mean\n",
      "    _tensor_constant165 = self.features_denseblock3_denselayer22_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_82 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_81, _param_constant246, _param_constant247, _tensor_constant164, _tensor_constant165, 0.1, 1e-05);  conv2d_81 = _param_constant246 = _param_constant247 = _tensor_constant164 = _tensor_constant165 = None\n",
      "    getitem_246 = _native_batch_norm_legit_no_training_82[0]\n",
      "    getitem_247 = _native_batch_norm_legit_no_training_82[1];  getitem_247 = None\n",
      "    getitem_248 = _native_batch_norm_legit_no_training_82[2];  _native_batch_norm_legit_no_training_82 = getitem_248 = None\n",
      "    relu__82 = torch.ops.aten.relu_.default(getitem_246);  getitem_246 = None\n",
      "    _param_constant248 = self.features_denseblock3_denselayer22_layers_conv2_weight\n",
      "    conv2d_82 = torch.ops.aten.conv2d.default(relu__82, _param_constant248, None, [1, 1], [1, 1]);  relu__82 = _param_constant248 = None\n",
      "    cat_39 = torch.ops.aten.cat.default([cat_38, conv2d_82], 1);  cat_38 = conv2d_82 = None\n",
      "    empty_83 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_83 = None\n",
      "    _param_constant249 = self.features_denseblock3_denselayer23_layers_norm1_weight\n",
      "    _param_constant250 = self.features_denseblock3_denselayer23_layers_norm1_bias\n",
      "    _tensor_constant166 = self.features_denseblock3_denselayer23_layers_norm1_running_mean\n",
      "    _tensor_constant167 = self.features_denseblock3_denselayer23_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_83 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_39, _param_constant249, _param_constant250, _tensor_constant166, _tensor_constant167, 0.1, 1e-05);  _param_constant249 = _param_constant250 = _tensor_constant166 = _tensor_constant167 = None\n",
      "    getitem_249 = _native_batch_norm_legit_no_training_83[0]\n",
      "    getitem_250 = _native_batch_norm_legit_no_training_83[1];  getitem_250 = None\n",
      "    getitem_251 = _native_batch_norm_legit_no_training_83[2];  _native_batch_norm_legit_no_training_83 = getitem_251 = None\n",
      "    relu__83 = torch.ops.aten.relu_.default(getitem_249);  getitem_249 = None\n",
      "    _param_constant251 = self.features_denseblock3_denselayer23_layers_conv1_weight\n",
      "    conv2d_83 = torch.ops.aten.conv2d.default(relu__83, _param_constant251);  relu__83 = _param_constant251 = None\n",
      "    empty_84 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_84 = None\n",
      "    _param_constant252 = self.features_denseblock3_denselayer23_layers_norm2_weight\n",
      "    _param_constant253 = self.features_denseblock3_denselayer23_layers_norm2_bias\n",
      "    _tensor_constant168 = self.features_denseblock3_denselayer23_layers_norm2_running_mean\n",
      "    _tensor_constant169 = self.features_denseblock3_denselayer23_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_84 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_83, _param_constant252, _param_constant253, _tensor_constant168, _tensor_constant169, 0.1, 1e-05);  conv2d_83 = _param_constant252 = _param_constant253 = _tensor_constant168 = _tensor_constant169 = None\n",
      "    getitem_252 = _native_batch_norm_legit_no_training_84[0]\n",
      "    getitem_253 = _native_batch_norm_legit_no_training_84[1];  getitem_253 = None\n",
      "    getitem_254 = _native_batch_norm_legit_no_training_84[2];  _native_batch_norm_legit_no_training_84 = getitem_254 = None\n",
      "    relu__84 = torch.ops.aten.relu_.default(getitem_252);  getitem_252 = None\n",
      "    _param_constant254 = self.features_denseblock3_denselayer23_layers_conv2_weight\n",
      "    conv2d_84 = torch.ops.aten.conv2d.default(relu__84, _param_constant254, None, [1, 1], [1, 1]);  relu__84 = _param_constant254 = None\n",
      "    cat_40 = torch.ops.aten.cat.default([cat_39, conv2d_84], 1);  cat_39 = conv2d_84 = None\n",
      "    empty_85 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_85 = None\n",
      "    _param_constant255 = self.features_denseblock3_denselayer24_layers_norm1_weight\n",
      "    _param_constant256 = self.features_denseblock3_denselayer24_layers_norm1_bias\n",
      "    _tensor_constant170 = self.features_denseblock3_denselayer24_layers_norm1_running_mean\n",
      "    _tensor_constant171 = self.features_denseblock3_denselayer24_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_85 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_40, _param_constant255, _param_constant256, _tensor_constant170, _tensor_constant171, 0.1, 1e-05);  _param_constant255 = _param_constant256 = _tensor_constant170 = _tensor_constant171 = None\n",
      "    getitem_255 = _native_batch_norm_legit_no_training_85[0]\n",
      "    getitem_256 = _native_batch_norm_legit_no_training_85[1];  getitem_256 = None\n",
      "    getitem_257 = _native_batch_norm_legit_no_training_85[2];  _native_batch_norm_legit_no_training_85 = getitem_257 = None\n",
      "    relu__85 = torch.ops.aten.relu_.default(getitem_255);  getitem_255 = None\n",
      "    _param_constant257 = self.features_denseblock3_denselayer24_layers_conv1_weight\n",
      "    conv2d_85 = torch.ops.aten.conv2d.default(relu__85, _param_constant257);  relu__85 = _param_constant257 = None\n",
      "    empty_86 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_86 = None\n",
      "    _param_constant258 = self.features_denseblock3_denselayer24_layers_norm2_weight\n",
      "    _param_constant259 = self.features_denseblock3_denselayer24_layers_norm2_bias\n",
      "    _tensor_constant172 = self.features_denseblock3_denselayer24_layers_norm2_running_mean\n",
      "    _tensor_constant173 = self.features_denseblock3_denselayer24_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_86 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_85, _param_constant258, _param_constant259, _tensor_constant172, _tensor_constant173, 0.1, 1e-05);  conv2d_85 = _param_constant258 = _param_constant259 = _tensor_constant172 = _tensor_constant173 = None\n",
      "    getitem_258 = _native_batch_norm_legit_no_training_86[0]\n",
      "    getitem_259 = _native_batch_norm_legit_no_training_86[1];  getitem_259 = None\n",
      "    getitem_260 = _native_batch_norm_legit_no_training_86[2];  _native_batch_norm_legit_no_training_86 = getitem_260 = None\n",
      "    relu__86 = torch.ops.aten.relu_.default(getitem_258);  getitem_258 = None\n",
      "    _param_constant260 = self.features_denseblock3_denselayer24_layers_conv2_weight\n",
      "    conv2d_86 = torch.ops.aten.conv2d.default(relu__86, _param_constant260, None, [1, 1], [1, 1]);  relu__86 = _param_constant260 = None\n",
      "    cat_41 = torch.ops.aten.cat.default([cat_40, conv2d_86], 1);  cat_40 = conv2d_86 = None\n",
      "    empty_87 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_87 = None\n",
      "    _param_constant261 = self.features_transition3_norm_weight\n",
      "    _param_constant262 = self.features_transition3_norm_bias\n",
      "    _tensor_constant174 = self.features_transition3_norm_running_mean\n",
      "    _tensor_constant175 = self.features_transition3_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_87 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_41, _param_constant261, _param_constant262, _tensor_constant174, _tensor_constant175, 0.1, 1e-05);  cat_41 = _param_constant261 = _param_constant262 = _tensor_constant174 = _tensor_constant175 = None\n",
      "    getitem_261 = _native_batch_norm_legit_no_training_87[0]\n",
      "    getitem_262 = _native_batch_norm_legit_no_training_87[1];  getitem_262 = None\n",
      "    getitem_263 = _native_batch_norm_legit_no_training_87[2];  _native_batch_norm_legit_no_training_87 = getitem_263 = None\n",
      "    relu__87 = torch.ops.aten.relu_.default(getitem_261);  getitem_261 = None\n",
      "    _param_constant263 = self.features_transition3_conv_weight\n",
      "    conv2d_87 = torch.ops.aten.conv2d.default(relu__87, _param_constant263);  relu__87 = _param_constant263 = None\n",
      "    avg_pool2d_2 = torch.ops.aten.avg_pool2d.default(conv2d_87, [2, 2], [2, 2]);  conv2d_87 = None\n",
      "    empty_88 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_88 = None\n",
      "    _param_constant264 = self.features_denseblock4_denselayer1_layers_norm1_weight\n",
      "    _param_constant265 = self.features_denseblock4_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant176 = self.features_denseblock4_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant177 = self.features_denseblock4_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_88 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_2, _param_constant264, _param_constant265, _tensor_constant176, _tensor_constant177, 0.1, 1e-05);  _param_constant264 = _param_constant265 = _tensor_constant176 = _tensor_constant177 = None\n",
      "    getitem_264 = _native_batch_norm_legit_no_training_88[0]\n",
      "    getitem_265 = _native_batch_norm_legit_no_training_88[1];  getitem_265 = None\n",
      "    getitem_266 = _native_batch_norm_legit_no_training_88[2];  _native_batch_norm_legit_no_training_88 = getitem_266 = None\n",
      "    relu__88 = torch.ops.aten.relu_.default(getitem_264);  getitem_264 = None\n",
      "    _param_constant266 = self.features_denseblock4_denselayer1_layers_conv1_weight\n",
      "    conv2d_88 = torch.ops.aten.conv2d.default(relu__88, _param_constant266);  relu__88 = _param_constant266 = None\n",
      "    empty_89 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_89 = None\n",
      "    _param_constant267 = self.features_denseblock4_denselayer1_layers_norm2_weight\n",
      "    _param_constant268 = self.features_denseblock4_denselayer1_layers_norm2_bias\n",
      "    _tensor_constant178 = self.features_denseblock4_denselayer1_layers_norm2_running_mean\n",
      "    _tensor_constant179 = self.features_denseblock4_denselayer1_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_89 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_88, _param_constant267, _param_constant268, _tensor_constant178, _tensor_constant179, 0.1, 1e-05);  conv2d_88 = _param_constant267 = _param_constant268 = _tensor_constant178 = _tensor_constant179 = None\n",
      "    getitem_267 = _native_batch_norm_legit_no_training_89[0]\n",
      "    getitem_268 = _native_batch_norm_legit_no_training_89[1];  getitem_268 = None\n",
      "    getitem_269 = _native_batch_norm_legit_no_training_89[2];  _native_batch_norm_legit_no_training_89 = getitem_269 = None\n",
      "    relu__89 = torch.ops.aten.relu_.default(getitem_267);  getitem_267 = None\n",
      "    _param_constant269 = self.features_denseblock4_denselayer1_layers_conv2_weight\n",
      "    conv2d_89 = torch.ops.aten.conv2d.default(relu__89, _param_constant269, None, [1, 1], [1, 1]);  relu__89 = _param_constant269 = None\n",
      "    cat_42 = torch.ops.aten.cat.default([avg_pool2d_2, conv2d_89], 1);  avg_pool2d_2 = conv2d_89 = None\n",
      "    empty_90 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_90 = None\n",
      "    _param_constant270 = self.features_denseblock4_denselayer2_layers_norm1_weight\n",
      "    _param_constant271 = self.features_denseblock4_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant180 = self.features_denseblock4_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant181 = self.features_denseblock4_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_90 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_42, _param_constant270, _param_constant271, _tensor_constant180, _tensor_constant181, 0.1, 1e-05);  _param_constant270 = _param_constant271 = _tensor_constant180 = _tensor_constant181 = None\n",
      "    getitem_270 = _native_batch_norm_legit_no_training_90[0]\n",
      "    getitem_271 = _native_batch_norm_legit_no_training_90[1];  getitem_271 = None\n",
      "    getitem_272 = _native_batch_norm_legit_no_training_90[2];  _native_batch_norm_legit_no_training_90 = getitem_272 = None\n",
      "    relu__90 = torch.ops.aten.relu_.default(getitem_270);  getitem_270 = None\n",
      "    _param_constant272 = self.features_denseblock4_denselayer2_layers_conv1_weight\n",
      "    conv2d_90 = torch.ops.aten.conv2d.default(relu__90, _param_constant272);  relu__90 = _param_constant272 = None\n",
      "    empty_91 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_91 = None\n",
      "    _param_constant273 = self.features_denseblock4_denselayer2_layers_norm2_weight\n",
      "    _param_constant274 = self.features_denseblock4_denselayer2_layers_norm2_bias\n",
      "    _tensor_constant182 = self.features_denseblock4_denselayer2_layers_norm2_running_mean\n",
      "    _tensor_constant183 = self.features_denseblock4_denselayer2_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_91 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_90, _param_constant273, _param_constant274, _tensor_constant182, _tensor_constant183, 0.1, 1e-05);  conv2d_90 = _param_constant273 = _param_constant274 = _tensor_constant182 = _tensor_constant183 = None\n",
      "    getitem_273 = _native_batch_norm_legit_no_training_91[0]\n",
      "    getitem_274 = _native_batch_norm_legit_no_training_91[1];  getitem_274 = None\n",
      "    getitem_275 = _native_batch_norm_legit_no_training_91[2];  _native_batch_norm_legit_no_training_91 = getitem_275 = None\n",
      "    relu__91 = torch.ops.aten.relu_.default(getitem_273);  getitem_273 = None\n",
      "    _param_constant275 = self.features_denseblock4_denselayer2_layers_conv2_weight\n",
      "    conv2d_91 = torch.ops.aten.conv2d.default(relu__91, _param_constant275, None, [1, 1], [1, 1]);  relu__91 = _param_constant275 = None\n",
      "    cat_43 = torch.ops.aten.cat.default([cat_42, conv2d_91], 1);  cat_42 = conv2d_91 = None\n",
      "    empty_92 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_92 = None\n",
      "    _param_constant276 = self.features_denseblock4_denselayer3_layers_norm1_weight\n",
      "    _param_constant277 = self.features_denseblock4_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant184 = self.features_denseblock4_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant185 = self.features_denseblock4_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_92 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_43, _param_constant276, _param_constant277, _tensor_constant184, _tensor_constant185, 0.1, 1e-05);  _param_constant276 = _param_constant277 = _tensor_constant184 = _tensor_constant185 = None\n",
      "    getitem_276 = _native_batch_norm_legit_no_training_92[0]\n",
      "    getitem_277 = _native_batch_norm_legit_no_training_92[1];  getitem_277 = None\n",
      "    getitem_278 = _native_batch_norm_legit_no_training_92[2];  _native_batch_norm_legit_no_training_92 = getitem_278 = None\n",
      "    relu__92 = torch.ops.aten.relu_.default(getitem_276);  getitem_276 = None\n",
      "    _param_constant278 = self.features_denseblock4_denselayer3_layers_conv1_weight\n",
      "    conv2d_92 = torch.ops.aten.conv2d.default(relu__92, _param_constant278);  relu__92 = _param_constant278 = None\n",
      "    empty_93 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_93 = None\n",
      "    _param_constant279 = self.features_denseblock4_denselayer3_layers_norm2_weight\n",
      "    _param_constant280 = self.features_denseblock4_denselayer3_layers_norm2_bias\n",
      "    _tensor_constant186 = self.features_denseblock4_denselayer3_layers_norm2_running_mean\n",
      "    _tensor_constant187 = self.features_denseblock4_denselayer3_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_93 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_92, _param_constant279, _param_constant280, _tensor_constant186, _tensor_constant187, 0.1, 1e-05);  conv2d_92 = _param_constant279 = _param_constant280 = _tensor_constant186 = _tensor_constant187 = None\n",
      "    getitem_279 = _native_batch_norm_legit_no_training_93[0]\n",
      "    getitem_280 = _native_batch_norm_legit_no_training_93[1];  getitem_280 = None\n",
      "    getitem_281 = _native_batch_norm_legit_no_training_93[2];  _native_batch_norm_legit_no_training_93 = getitem_281 = None\n",
      "    relu__93 = torch.ops.aten.relu_.default(getitem_279);  getitem_279 = None\n",
      "    _param_constant281 = self.features_denseblock4_denselayer3_layers_conv2_weight\n",
      "    conv2d_93 = torch.ops.aten.conv2d.default(relu__93, _param_constant281, None, [1, 1], [1, 1]);  relu__93 = _param_constant281 = None\n",
      "    cat_44 = torch.ops.aten.cat.default([cat_43, conv2d_93], 1);  cat_43 = conv2d_93 = None\n",
      "    empty_94 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_94 = None\n",
      "    _param_constant282 = self.features_denseblock4_denselayer4_layers_norm1_weight\n",
      "    _param_constant283 = self.features_denseblock4_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant188 = self.features_denseblock4_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant189 = self.features_denseblock4_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_94 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_44, _param_constant282, _param_constant283, _tensor_constant188, _tensor_constant189, 0.1, 1e-05);  _param_constant282 = _param_constant283 = _tensor_constant188 = _tensor_constant189 = None\n",
      "    getitem_282 = _native_batch_norm_legit_no_training_94[0]\n",
      "    getitem_283 = _native_batch_norm_legit_no_training_94[1];  getitem_283 = None\n",
      "    getitem_284 = _native_batch_norm_legit_no_training_94[2];  _native_batch_norm_legit_no_training_94 = getitem_284 = None\n",
      "    relu__94 = torch.ops.aten.relu_.default(getitem_282);  getitem_282 = None\n",
      "    _param_constant284 = self.features_denseblock4_denselayer4_layers_conv1_weight\n",
      "    conv2d_94 = torch.ops.aten.conv2d.default(relu__94, _param_constant284);  relu__94 = _param_constant284 = None\n",
      "    empty_95 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_95 = None\n",
      "    _param_constant285 = self.features_denseblock4_denselayer4_layers_norm2_weight\n",
      "    _param_constant286 = self.features_denseblock4_denselayer4_layers_norm2_bias\n",
      "    _tensor_constant190 = self.features_denseblock4_denselayer4_layers_norm2_running_mean\n",
      "    _tensor_constant191 = self.features_denseblock4_denselayer4_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_95 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_94, _param_constant285, _param_constant286, _tensor_constant190, _tensor_constant191, 0.1, 1e-05);  conv2d_94 = _param_constant285 = _param_constant286 = _tensor_constant190 = _tensor_constant191 = None\n",
      "    getitem_285 = _native_batch_norm_legit_no_training_95[0]\n",
      "    getitem_286 = _native_batch_norm_legit_no_training_95[1];  getitem_286 = None\n",
      "    getitem_287 = _native_batch_norm_legit_no_training_95[2];  _native_batch_norm_legit_no_training_95 = getitem_287 = None\n",
      "    relu__95 = torch.ops.aten.relu_.default(getitem_285);  getitem_285 = None\n",
      "    _param_constant287 = self.features_denseblock4_denselayer4_layers_conv2_weight\n",
      "    conv2d_95 = torch.ops.aten.conv2d.default(relu__95, _param_constant287, None, [1, 1], [1, 1]);  relu__95 = _param_constant287 = None\n",
      "    cat_45 = torch.ops.aten.cat.default([cat_44, conv2d_95], 1);  cat_44 = conv2d_95 = None\n",
      "    empty_96 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_96 = None\n",
      "    _param_constant288 = self.features_denseblock4_denselayer5_layers_norm1_weight\n",
      "    _param_constant289 = self.features_denseblock4_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant192 = self.features_denseblock4_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant193 = self.features_denseblock4_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_96 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_45, _param_constant288, _param_constant289, _tensor_constant192, _tensor_constant193, 0.1, 1e-05);  _param_constant288 = _param_constant289 = _tensor_constant192 = _tensor_constant193 = None\n",
      "    getitem_288 = _native_batch_norm_legit_no_training_96[0]\n",
      "    getitem_289 = _native_batch_norm_legit_no_training_96[1];  getitem_289 = None\n",
      "    getitem_290 = _native_batch_norm_legit_no_training_96[2];  _native_batch_norm_legit_no_training_96 = getitem_290 = None\n",
      "    relu__96 = torch.ops.aten.relu_.default(getitem_288);  getitem_288 = None\n",
      "    _param_constant290 = self.features_denseblock4_denselayer5_layers_conv1_weight\n",
      "    conv2d_96 = torch.ops.aten.conv2d.default(relu__96, _param_constant290);  relu__96 = _param_constant290 = None\n",
      "    empty_97 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_97 = None\n",
      "    _param_constant291 = self.features_denseblock4_denselayer5_layers_norm2_weight\n",
      "    _param_constant292 = self.features_denseblock4_denselayer5_layers_norm2_bias\n",
      "    _tensor_constant194 = self.features_denseblock4_denselayer5_layers_norm2_running_mean\n",
      "    _tensor_constant195 = self.features_denseblock4_denselayer5_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_97 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_96, _param_constant291, _param_constant292, _tensor_constant194, _tensor_constant195, 0.1, 1e-05);  conv2d_96 = _param_constant291 = _param_constant292 = _tensor_constant194 = _tensor_constant195 = None\n",
      "    getitem_291 = _native_batch_norm_legit_no_training_97[0]\n",
      "    getitem_292 = _native_batch_norm_legit_no_training_97[1];  getitem_292 = None\n",
      "    getitem_293 = _native_batch_norm_legit_no_training_97[2];  _native_batch_norm_legit_no_training_97 = getitem_293 = None\n",
      "    relu__97 = torch.ops.aten.relu_.default(getitem_291);  getitem_291 = None\n",
      "    _param_constant293 = self.features_denseblock4_denselayer5_layers_conv2_weight\n",
      "    conv2d_97 = torch.ops.aten.conv2d.default(relu__97, _param_constant293, None, [1, 1], [1, 1]);  relu__97 = _param_constant293 = None\n",
      "    cat_46 = torch.ops.aten.cat.default([cat_45, conv2d_97], 1);  cat_45 = conv2d_97 = None\n",
      "    empty_98 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_98 = None\n",
      "    _param_constant294 = self.features_denseblock4_denselayer6_layers_norm1_weight\n",
      "    _param_constant295 = self.features_denseblock4_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant196 = self.features_denseblock4_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant197 = self.features_denseblock4_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_98 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_46, _param_constant294, _param_constant295, _tensor_constant196, _tensor_constant197, 0.1, 1e-05);  _param_constant294 = _param_constant295 = _tensor_constant196 = _tensor_constant197 = None\n",
      "    getitem_294 = _native_batch_norm_legit_no_training_98[0]\n",
      "    getitem_295 = _native_batch_norm_legit_no_training_98[1];  getitem_295 = None\n",
      "    getitem_296 = _native_batch_norm_legit_no_training_98[2];  _native_batch_norm_legit_no_training_98 = getitem_296 = None\n",
      "    relu__98 = torch.ops.aten.relu_.default(getitem_294);  getitem_294 = None\n",
      "    _param_constant296 = self.features_denseblock4_denselayer6_layers_conv1_weight\n",
      "    conv2d_98 = torch.ops.aten.conv2d.default(relu__98, _param_constant296);  relu__98 = _param_constant296 = None\n",
      "    empty_99 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_99 = None\n",
      "    _param_constant297 = self.features_denseblock4_denselayer6_layers_norm2_weight\n",
      "    _param_constant298 = self.features_denseblock4_denselayer6_layers_norm2_bias\n",
      "    _tensor_constant198 = self.features_denseblock4_denselayer6_layers_norm2_running_mean\n",
      "    _tensor_constant199 = self.features_denseblock4_denselayer6_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_99 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_98, _param_constant297, _param_constant298, _tensor_constant198, _tensor_constant199, 0.1, 1e-05);  conv2d_98 = _param_constant297 = _param_constant298 = _tensor_constant198 = _tensor_constant199 = None\n",
      "    getitem_297 = _native_batch_norm_legit_no_training_99[0]\n",
      "    getitem_298 = _native_batch_norm_legit_no_training_99[1];  getitem_298 = None\n",
      "    getitem_299 = _native_batch_norm_legit_no_training_99[2];  _native_batch_norm_legit_no_training_99 = getitem_299 = None\n",
      "    relu__99 = torch.ops.aten.relu_.default(getitem_297);  getitem_297 = None\n",
      "    _param_constant299 = self.features_denseblock4_denselayer6_layers_conv2_weight\n",
      "    conv2d_99 = torch.ops.aten.conv2d.default(relu__99, _param_constant299, None, [1, 1], [1, 1]);  relu__99 = _param_constant299 = None\n",
      "    cat_47 = torch.ops.aten.cat.default([cat_46, conv2d_99], 1);  cat_46 = conv2d_99 = None\n",
      "    empty_100 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_100 = None\n",
      "    _param_constant300 = self.features_denseblock4_denselayer7_layers_norm1_weight\n",
      "    _param_constant301 = self.features_denseblock4_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant200 = self.features_denseblock4_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant201 = self.features_denseblock4_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_100 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_47, _param_constant300, _param_constant301, _tensor_constant200, _tensor_constant201, 0.1, 1e-05);  _param_constant300 = _param_constant301 = _tensor_constant200 = _tensor_constant201 = None\n",
      "    getitem_300 = _native_batch_norm_legit_no_training_100[0]\n",
      "    getitem_301 = _native_batch_norm_legit_no_training_100[1];  getitem_301 = None\n",
      "    getitem_302 = _native_batch_norm_legit_no_training_100[2];  _native_batch_norm_legit_no_training_100 = getitem_302 = None\n",
      "    relu__100 = torch.ops.aten.relu_.default(getitem_300);  getitem_300 = None\n",
      "    _param_constant302 = self.features_denseblock4_denselayer7_layers_conv1_weight\n",
      "    conv2d_100 = torch.ops.aten.conv2d.default(relu__100, _param_constant302);  relu__100 = _param_constant302 = None\n",
      "    empty_101 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_101 = None\n",
      "    _param_constant303 = self.features_denseblock4_denselayer7_layers_norm2_weight\n",
      "    _param_constant304 = self.features_denseblock4_denselayer7_layers_norm2_bias\n",
      "    _tensor_constant202 = self.features_denseblock4_denselayer7_layers_norm2_running_mean\n",
      "    _tensor_constant203 = self.features_denseblock4_denselayer7_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_101 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_100, _param_constant303, _param_constant304, _tensor_constant202, _tensor_constant203, 0.1, 1e-05);  conv2d_100 = _param_constant303 = _param_constant304 = _tensor_constant202 = _tensor_constant203 = None\n",
      "    getitem_303 = _native_batch_norm_legit_no_training_101[0]\n",
      "    getitem_304 = _native_batch_norm_legit_no_training_101[1];  getitem_304 = None\n",
      "    getitem_305 = _native_batch_norm_legit_no_training_101[2];  _native_batch_norm_legit_no_training_101 = getitem_305 = None\n",
      "    relu__101 = torch.ops.aten.relu_.default(getitem_303);  getitem_303 = None\n",
      "    _param_constant305 = self.features_denseblock4_denselayer7_layers_conv2_weight\n",
      "    conv2d_101 = torch.ops.aten.conv2d.default(relu__101, _param_constant305, None, [1, 1], [1, 1]);  relu__101 = _param_constant305 = None\n",
      "    cat_48 = torch.ops.aten.cat.default([cat_47, conv2d_101], 1);  cat_47 = conv2d_101 = None\n",
      "    empty_102 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_102 = None\n",
      "    _param_constant306 = self.features_denseblock4_denselayer8_layers_norm1_weight\n",
      "    _param_constant307 = self.features_denseblock4_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant204 = self.features_denseblock4_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant205 = self.features_denseblock4_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_102 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_48, _param_constant306, _param_constant307, _tensor_constant204, _tensor_constant205, 0.1, 1e-05);  _param_constant306 = _param_constant307 = _tensor_constant204 = _tensor_constant205 = None\n",
      "    getitem_306 = _native_batch_norm_legit_no_training_102[0]\n",
      "    getitem_307 = _native_batch_norm_legit_no_training_102[1];  getitem_307 = None\n",
      "    getitem_308 = _native_batch_norm_legit_no_training_102[2];  _native_batch_norm_legit_no_training_102 = getitem_308 = None\n",
      "    relu__102 = torch.ops.aten.relu_.default(getitem_306);  getitem_306 = None\n",
      "    _param_constant308 = self.features_denseblock4_denselayer8_layers_conv1_weight\n",
      "    conv2d_102 = torch.ops.aten.conv2d.default(relu__102, _param_constant308);  relu__102 = _param_constant308 = None\n",
      "    empty_103 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_103 = None\n",
      "    _param_constant309 = self.features_denseblock4_denselayer8_layers_norm2_weight\n",
      "    _param_constant310 = self.features_denseblock4_denselayer8_layers_norm2_bias\n",
      "    _tensor_constant206 = self.features_denseblock4_denselayer8_layers_norm2_running_mean\n",
      "    _tensor_constant207 = self.features_denseblock4_denselayer8_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_103 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_102, _param_constant309, _param_constant310, _tensor_constant206, _tensor_constant207, 0.1, 1e-05);  conv2d_102 = _param_constant309 = _param_constant310 = _tensor_constant206 = _tensor_constant207 = None\n",
      "    getitem_309 = _native_batch_norm_legit_no_training_103[0]\n",
      "    getitem_310 = _native_batch_norm_legit_no_training_103[1];  getitem_310 = None\n",
      "    getitem_311 = _native_batch_norm_legit_no_training_103[2];  _native_batch_norm_legit_no_training_103 = getitem_311 = None\n",
      "    relu__103 = torch.ops.aten.relu_.default(getitem_309);  getitem_309 = None\n",
      "    _param_constant311 = self.features_denseblock4_denselayer8_layers_conv2_weight\n",
      "    conv2d_103 = torch.ops.aten.conv2d.default(relu__103, _param_constant311, None, [1, 1], [1, 1]);  relu__103 = _param_constant311 = None\n",
      "    cat_49 = torch.ops.aten.cat.default([cat_48, conv2d_103], 1);  cat_48 = conv2d_103 = None\n",
      "    empty_104 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_104 = None\n",
      "    _param_constant312 = self.features_denseblock4_denselayer9_layers_norm1_weight\n",
      "    _param_constant313 = self.features_denseblock4_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant208 = self.features_denseblock4_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant209 = self.features_denseblock4_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_104 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_49, _param_constant312, _param_constant313, _tensor_constant208, _tensor_constant209, 0.1, 1e-05);  _param_constant312 = _param_constant313 = _tensor_constant208 = _tensor_constant209 = None\n",
      "    getitem_312 = _native_batch_norm_legit_no_training_104[0]\n",
      "    getitem_313 = _native_batch_norm_legit_no_training_104[1];  getitem_313 = None\n",
      "    getitem_314 = _native_batch_norm_legit_no_training_104[2];  _native_batch_norm_legit_no_training_104 = getitem_314 = None\n",
      "    relu__104 = torch.ops.aten.relu_.default(getitem_312);  getitem_312 = None\n",
      "    _param_constant314 = self.features_denseblock4_denselayer9_layers_conv1_weight\n",
      "    conv2d_104 = torch.ops.aten.conv2d.default(relu__104, _param_constant314);  relu__104 = _param_constant314 = None\n",
      "    empty_105 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_105 = None\n",
      "    _param_constant315 = self.features_denseblock4_denselayer9_layers_norm2_weight\n",
      "    _param_constant316 = self.features_denseblock4_denselayer9_layers_norm2_bias\n",
      "    _tensor_constant210 = self.features_denseblock4_denselayer9_layers_norm2_running_mean\n",
      "    _tensor_constant211 = self.features_denseblock4_denselayer9_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_105 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_104, _param_constant315, _param_constant316, _tensor_constant210, _tensor_constant211, 0.1, 1e-05);  conv2d_104 = _param_constant315 = _param_constant316 = _tensor_constant210 = _tensor_constant211 = None\n",
      "    getitem_315 = _native_batch_norm_legit_no_training_105[0]\n",
      "    getitem_316 = _native_batch_norm_legit_no_training_105[1];  getitem_316 = None\n",
      "    getitem_317 = _native_batch_norm_legit_no_training_105[2];  _native_batch_norm_legit_no_training_105 = getitem_317 = None\n",
      "    relu__105 = torch.ops.aten.relu_.default(getitem_315);  getitem_315 = None\n",
      "    _param_constant317 = self.features_denseblock4_denselayer9_layers_conv2_weight\n",
      "    conv2d_105 = torch.ops.aten.conv2d.default(relu__105, _param_constant317, None, [1, 1], [1, 1]);  relu__105 = _param_constant317 = None\n",
      "    cat_50 = torch.ops.aten.cat.default([cat_49, conv2d_105], 1);  cat_49 = conv2d_105 = None\n",
      "    empty_106 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_106 = None\n",
      "    _param_constant318 = self.features_denseblock4_denselayer10_layers_norm1_weight\n",
      "    _param_constant319 = self.features_denseblock4_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant212 = self.features_denseblock4_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant213 = self.features_denseblock4_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_106 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_50, _param_constant318, _param_constant319, _tensor_constant212, _tensor_constant213, 0.1, 1e-05);  _param_constant318 = _param_constant319 = _tensor_constant212 = _tensor_constant213 = None\n",
      "    getitem_318 = _native_batch_norm_legit_no_training_106[0]\n",
      "    getitem_319 = _native_batch_norm_legit_no_training_106[1];  getitem_319 = None\n",
      "    getitem_320 = _native_batch_norm_legit_no_training_106[2];  _native_batch_norm_legit_no_training_106 = getitem_320 = None\n",
      "    relu__106 = torch.ops.aten.relu_.default(getitem_318);  getitem_318 = None\n",
      "    _param_constant320 = self.features_denseblock4_denselayer10_layers_conv1_weight\n",
      "    conv2d_106 = torch.ops.aten.conv2d.default(relu__106, _param_constant320);  relu__106 = _param_constant320 = None\n",
      "    empty_107 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_107 = None\n",
      "    _param_constant321 = self.features_denseblock4_denselayer10_layers_norm2_weight\n",
      "    _param_constant322 = self.features_denseblock4_denselayer10_layers_norm2_bias\n",
      "    _tensor_constant214 = self.features_denseblock4_denselayer10_layers_norm2_running_mean\n",
      "    _tensor_constant215 = self.features_denseblock4_denselayer10_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_107 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_106, _param_constant321, _param_constant322, _tensor_constant214, _tensor_constant215, 0.1, 1e-05);  conv2d_106 = _param_constant321 = _param_constant322 = _tensor_constant214 = _tensor_constant215 = None\n",
      "    getitem_321 = _native_batch_norm_legit_no_training_107[0]\n",
      "    getitem_322 = _native_batch_norm_legit_no_training_107[1];  getitem_322 = None\n",
      "    getitem_323 = _native_batch_norm_legit_no_training_107[2];  _native_batch_norm_legit_no_training_107 = getitem_323 = None\n",
      "    relu__107 = torch.ops.aten.relu_.default(getitem_321);  getitem_321 = None\n",
      "    _param_constant323 = self.features_denseblock4_denselayer10_layers_conv2_weight\n",
      "    conv2d_107 = torch.ops.aten.conv2d.default(relu__107, _param_constant323, None, [1, 1], [1, 1]);  relu__107 = _param_constant323 = None\n",
      "    cat_51 = torch.ops.aten.cat.default([cat_50, conv2d_107], 1);  cat_50 = conv2d_107 = None\n",
      "    empty_108 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_108 = None\n",
      "    _param_constant324 = self.features_denseblock4_denselayer11_layers_norm1_weight\n",
      "    _param_constant325 = self.features_denseblock4_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant216 = self.features_denseblock4_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant217 = self.features_denseblock4_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_108 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_51, _param_constant324, _param_constant325, _tensor_constant216, _tensor_constant217, 0.1, 1e-05);  _param_constant324 = _param_constant325 = _tensor_constant216 = _tensor_constant217 = None\n",
      "    getitem_324 = _native_batch_norm_legit_no_training_108[0]\n",
      "    getitem_325 = _native_batch_norm_legit_no_training_108[1];  getitem_325 = None\n",
      "    getitem_326 = _native_batch_norm_legit_no_training_108[2];  _native_batch_norm_legit_no_training_108 = getitem_326 = None\n",
      "    relu__108 = torch.ops.aten.relu_.default(getitem_324);  getitem_324 = None\n",
      "    _param_constant326 = self.features_denseblock4_denselayer11_layers_conv1_weight\n",
      "    conv2d_108 = torch.ops.aten.conv2d.default(relu__108, _param_constant326);  relu__108 = _param_constant326 = None\n",
      "    empty_109 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_109 = None\n",
      "    _param_constant327 = self.features_denseblock4_denselayer11_layers_norm2_weight\n",
      "    _param_constant328 = self.features_denseblock4_denselayer11_layers_norm2_bias\n",
      "    _tensor_constant218 = self.features_denseblock4_denselayer11_layers_norm2_running_mean\n",
      "    _tensor_constant219 = self.features_denseblock4_denselayer11_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_109 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_108, _param_constant327, _param_constant328, _tensor_constant218, _tensor_constant219, 0.1, 1e-05);  conv2d_108 = _param_constant327 = _param_constant328 = _tensor_constant218 = _tensor_constant219 = None\n",
      "    getitem_327 = _native_batch_norm_legit_no_training_109[0]\n",
      "    getitem_328 = _native_batch_norm_legit_no_training_109[1];  getitem_328 = None\n",
      "    getitem_329 = _native_batch_norm_legit_no_training_109[2];  _native_batch_norm_legit_no_training_109 = getitem_329 = None\n",
      "    relu__109 = torch.ops.aten.relu_.default(getitem_327);  getitem_327 = None\n",
      "    _param_constant329 = self.features_denseblock4_denselayer11_layers_conv2_weight\n",
      "    conv2d_109 = torch.ops.aten.conv2d.default(relu__109, _param_constant329, None, [1, 1], [1, 1]);  relu__109 = _param_constant329 = None\n",
      "    cat_52 = torch.ops.aten.cat.default([cat_51, conv2d_109], 1);  cat_51 = conv2d_109 = None\n",
      "    empty_110 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_110 = None\n",
      "    _param_constant330 = self.features_denseblock4_denselayer12_layers_norm1_weight\n",
      "    _param_constant331 = self.features_denseblock4_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant220 = self.features_denseblock4_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant221 = self.features_denseblock4_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_110 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_52, _param_constant330, _param_constant331, _tensor_constant220, _tensor_constant221, 0.1, 1e-05);  _param_constant330 = _param_constant331 = _tensor_constant220 = _tensor_constant221 = None\n",
      "    getitem_330 = _native_batch_norm_legit_no_training_110[0]\n",
      "    getitem_331 = _native_batch_norm_legit_no_training_110[1];  getitem_331 = None\n",
      "    getitem_332 = _native_batch_norm_legit_no_training_110[2];  _native_batch_norm_legit_no_training_110 = getitem_332 = None\n",
      "    relu__110 = torch.ops.aten.relu_.default(getitem_330);  getitem_330 = None\n",
      "    _param_constant332 = self.features_denseblock4_denselayer12_layers_conv1_weight\n",
      "    conv2d_110 = torch.ops.aten.conv2d.default(relu__110, _param_constant332);  relu__110 = _param_constant332 = None\n",
      "    empty_111 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_111 = None\n",
      "    _param_constant333 = self.features_denseblock4_denselayer12_layers_norm2_weight\n",
      "    _param_constant334 = self.features_denseblock4_denselayer12_layers_norm2_bias\n",
      "    _tensor_constant222 = self.features_denseblock4_denselayer12_layers_norm2_running_mean\n",
      "    _tensor_constant223 = self.features_denseblock4_denselayer12_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_111 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_110, _param_constant333, _param_constant334, _tensor_constant222, _tensor_constant223, 0.1, 1e-05);  conv2d_110 = _param_constant333 = _param_constant334 = _tensor_constant222 = _tensor_constant223 = None\n",
      "    getitem_333 = _native_batch_norm_legit_no_training_111[0]\n",
      "    getitem_334 = _native_batch_norm_legit_no_training_111[1];  getitem_334 = None\n",
      "    getitem_335 = _native_batch_norm_legit_no_training_111[2];  _native_batch_norm_legit_no_training_111 = getitem_335 = None\n",
      "    relu__111 = torch.ops.aten.relu_.default(getitem_333);  getitem_333 = None\n",
      "    _param_constant335 = self.features_denseblock4_denselayer12_layers_conv2_weight\n",
      "    conv2d_111 = torch.ops.aten.conv2d.default(relu__111, _param_constant335, None, [1, 1], [1, 1]);  relu__111 = _param_constant335 = None\n",
      "    cat_53 = torch.ops.aten.cat.default([cat_52, conv2d_111], 1);  cat_52 = conv2d_111 = None\n",
      "    empty_112 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_112 = None\n",
      "    _param_constant336 = self.features_denseblock4_denselayer13_layers_norm1_weight\n",
      "    _param_constant337 = self.features_denseblock4_denselayer13_layers_norm1_bias\n",
      "    _tensor_constant224 = self.features_denseblock4_denselayer13_layers_norm1_running_mean\n",
      "    _tensor_constant225 = self.features_denseblock4_denselayer13_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_112 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_53, _param_constant336, _param_constant337, _tensor_constant224, _tensor_constant225, 0.1, 1e-05);  _param_constant336 = _param_constant337 = _tensor_constant224 = _tensor_constant225 = None\n",
      "    getitem_336 = _native_batch_norm_legit_no_training_112[0]\n",
      "    getitem_337 = _native_batch_norm_legit_no_training_112[1];  getitem_337 = None\n",
      "    getitem_338 = _native_batch_norm_legit_no_training_112[2];  _native_batch_norm_legit_no_training_112 = getitem_338 = None\n",
      "    relu__112 = torch.ops.aten.relu_.default(getitem_336);  getitem_336 = None\n",
      "    _param_constant338 = self.features_denseblock4_denselayer13_layers_conv1_weight\n",
      "    conv2d_112 = torch.ops.aten.conv2d.default(relu__112, _param_constant338);  relu__112 = _param_constant338 = None\n",
      "    empty_113 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_113 = None\n",
      "    _param_constant339 = self.features_denseblock4_denselayer13_layers_norm2_weight\n",
      "    _param_constant340 = self.features_denseblock4_denselayer13_layers_norm2_bias\n",
      "    _tensor_constant226 = self.features_denseblock4_denselayer13_layers_norm2_running_mean\n",
      "    _tensor_constant227 = self.features_denseblock4_denselayer13_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_113 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_112, _param_constant339, _param_constant340, _tensor_constant226, _tensor_constant227, 0.1, 1e-05);  conv2d_112 = _param_constant339 = _param_constant340 = _tensor_constant226 = _tensor_constant227 = None\n",
      "    getitem_339 = _native_batch_norm_legit_no_training_113[0]\n",
      "    getitem_340 = _native_batch_norm_legit_no_training_113[1];  getitem_340 = None\n",
      "    getitem_341 = _native_batch_norm_legit_no_training_113[2];  _native_batch_norm_legit_no_training_113 = getitem_341 = None\n",
      "    relu__113 = torch.ops.aten.relu_.default(getitem_339);  getitem_339 = None\n",
      "    _param_constant341 = self.features_denseblock4_denselayer13_layers_conv2_weight\n",
      "    conv2d_113 = torch.ops.aten.conv2d.default(relu__113, _param_constant341, None, [1, 1], [1, 1]);  relu__113 = _param_constant341 = None\n",
      "    cat_54 = torch.ops.aten.cat.default([cat_53, conv2d_113], 1);  cat_53 = conv2d_113 = None\n",
      "    empty_114 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_114 = None\n",
      "    _param_constant342 = self.features_denseblock4_denselayer14_layers_norm1_weight\n",
      "    _param_constant343 = self.features_denseblock4_denselayer14_layers_norm1_bias\n",
      "    _tensor_constant228 = self.features_denseblock4_denselayer14_layers_norm1_running_mean\n",
      "    _tensor_constant229 = self.features_denseblock4_denselayer14_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_114 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_54, _param_constant342, _param_constant343, _tensor_constant228, _tensor_constant229, 0.1, 1e-05);  _param_constant342 = _param_constant343 = _tensor_constant228 = _tensor_constant229 = None\n",
      "    getitem_342 = _native_batch_norm_legit_no_training_114[0]\n",
      "    getitem_343 = _native_batch_norm_legit_no_training_114[1];  getitem_343 = None\n",
      "    getitem_344 = _native_batch_norm_legit_no_training_114[2];  _native_batch_norm_legit_no_training_114 = getitem_344 = None\n",
      "    relu__114 = torch.ops.aten.relu_.default(getitem_342);  getitem_342 = None\n",
      "    _param_constant344 = self.features_denseblock4_denselayer14_layers_conv1_weight\n",
      "    conv2d_114 = torch.ops.aten.conv2d.default(relu__114, _param_constant344);  relu__114 = _param_constant344 = None\n",
      "    empty_115 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_115 = None\n",
      "    _param_constant345 = self.features_denseblock4_denselayer14_layers_norm2_weight\n",
      "    _param_constant346 = self.features_denseblock4_denselayer14_layers_norm2_bias\n",
      "    _tensor_constant230 = self.features_denseblock4_denselayer14_layers_norm2_running_mean\n",
      "    _tensor_constant231 = self.features_denseblock4_denselayer14_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_115 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_114, _param_constant345, _param_constant346, _tensor_constant230, _tensor_constant231, 0.1, 1e-05);  conv2d_114 = _param_constant345 = _param_constant346 = _tensor_constant230 = _tensor_constant231 = None\n",
      "    getitem_345 = _native_batch_norm_legit_no_training_115[0]\n",
      "    getitem_346 = _native_batch_norm_legit_no_training_115[1];  getitem_346 = None\n",
      "    getitem_347 = _native_batch_norm_legit_no_training_115[2];  _native_batch_norm_legit_no_training_115 = getitem_347 = None\n",
      "    relu__115 = torch.ops.aten.relu_.default(getitem_345);  getitem_345 = None\n",
      "    _param_constant347 = self.features_denseblock4_denselayer14_layers_conv2_weight\n",
      "    conv2d_115 = torch.ops.aten.conv2d.default(relu__115, _param_constant347, None, [1, 1], [1, 1]);  relu__115 = _param_constant347 = None\n",
      "    cat_55 = torch.ops.aten.cat.default([cat_54, conv2d_115], 1);  cat_54 = conv2d_115 = None\n",
      "    empty_116 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_116 = None\n",
      "    _param_constant348 = self.features_denseblock4_denselayer15_layers_norm1_weight\n",
      "    _param_constant349 = self.features_denseblock4_denselayer15_layers_norm1_bias\n",
      "    _tensor_constant232 = self.features_denseblock4_denselayer15_layers_norm1_running_mean\n",
      "    _tensor_constant233 = self.features_denseblock4_denselayer15_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_116 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_55, _param_constant348, _param_constant349, _tensor_constant232, _tensor_constant233, 0.1, 1e-05);  _param_constant348 = _param_constant349 = _tensor_constant232 = _tensor_constant233 = None\n",
      "    getitem_348 = _native_batch_norm_legit_no_training_116[0]\n",
      "    getitem_349 = _native_batch_norm_legit_no_training_116[1];  getitem_349 = None\n",
      "    getitem_350 = _native_batch_norm_legit_no_training_116[2];  _native_batch_norm_legit_no_training_116 = getitem_350 = None\n",
      "    relu__116 = torch.ops.aten.relu_.default(getitem_348);  getitem_348 = None\n",
      "    _param_constant350 = self.features_denseblock4_denselayer15_layers_conv1_weight\n",
      "    conv2d_116 = torch.ops.aten.conv2d.default(relu__116, _param_constant350);  relu__116 = _param_constant350 = None\n",
      "    empty_117 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_117 = None\n",
      "    _param_constant351 = self.features_denseblock4_denselayer15_layers_norm2_weight\n",
      "    _param_constant352 = self.features_denseblock4_denselayer15_layers_norm2_bias\n",
      "    _tensor_constant234 = self.features_denseblock4_denselayer15_layers_norm2_running_mean\n",
      "    _tensor_constant235 = self.features_denseblock4_denselayer15_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_117 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_116, _param_constant351, _param_constant352, _tensor_constant234, _tensor_constant235, 0.1, 1e-05);  conv2d_116 = _param_constant351 = _param_constant352 = _tensor_constant234 = _tensor_constant235 = None\n",
      "    getitem_351 = _native_batch_norm_legit_no_training_117[0]\n",
      "    getitem_352 = _native_batch_norm_legit_no_training_117[1];  getitem_352 = None\n",
      "    getitem_353 = _native_batch_norm_legit_no_training_117[2];  _native_batch_norm_legit_no_training_117 = getitem_353 = None\n",
      "    relu__117 = torch.ops.aten.relu_.default(getitem_351);  getitem_351 = None\n",
      "    _param_constant353 = self.features_denseblock4_denselayer15_layers_conv2_weight\n",
      "    conv2d_117 = torch.ops.aten.conv2d.default(relu__117, _param_constant353, None, [1, 1], [1, 1]);  relu__117 = _param_constant353 = None\n",
      "    cat_56 = torch.ops.aten.cat.default([cat_55, conv2d_117], 1);  cat_55 = conv2d_117 = None\n",
      "    empty_118 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_118 = None\n",
      "    _param_constant354 = self.features_denseblock4_denselayer16_layers_norm1_weight\n",
      "    _param_constant355 = self.features_denseblock4_denselayer16_layers_norm1_bias\n",
      "    _tensor_constant236 = self.features_denseblock4_denselayer16_layers_norm1_running_mean\n",
      "    _tensor_constant237 = self.features_denseblock4_denselayer16_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_118 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_56, _param_constant354, _param_constant355, _tensor_constant236, _tensor_constant237, 0.1, 1e-05);  _param_constant354 = _param_constant355 = _tensor_constant236 = _tensor_constant237 = None\n",
      "    getitem_354 = _native_batch_norm_legit_no_training_118[0]\n",
      "    getitem_355 = _native_batch_norm_legit_no_training_118[1];  getitem_355 = None\n",
      "    getitem_356 = _native_batch_norm_legit_no_training_118[2];  _native_batch_norm_legit_no_training_118 = getitem_356 = None\n",
      "    relu__118 = torch.ops.aten.relu_.default(getitem_354);  getitem_354 = None\n",
      "    _param_constant356 = self.features_denseblock4_denselayer16_layers_conv1_weight\n",
      "    conv2d_118 = torch.ops.aten.conv2d.default(relu__118, _param_constant356);  relu__118 = _param_constant356 = None\n",
      "    empty_119 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_119 = None\n",
      "    _param_constant357 = self.features_denseblock4_denselayer16_layers_norm2_weight\n",
      "    _param_constant358 = self.features_denseblock4_denselayer16_layers_norm2_bias\n",
      "    _tensor_constant238 = self.features_denseblock4_denselayer16_layers_norm2_running_mean\n",
      "    _tensor_constant239 = self.features_denseblock4_denselayer16_layers_norm2_running_var\n",
      "    _native_batch_norm_legit_no_training_119 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_118, _param_constant357, _param_constant358, _tensor_constant238, _tensor_constant239, 0.1, 1e-05);  conv2d_118 = _param_constant357 = _param_constant358 = _tensor_constant238 = _tensor_constant239 = None\n",
      "    getitem_357 = _native_batch_norm_legit_no_training_119[0]\n",
      "    getitem_358 = _native_batch_norm_legit_no_training_119[1];  getitem_358 = None\n",
      "    getitem_359 = _native_batch_norm_legit_no_training_119[2];  _native_batch_norm_legit_no_training_119 = getitem_359 = None\n",
      "    relu__119 = torch.ops.aten.relu_.default(getitem_357);  getitem_357 = None\n",
      "    _param_constant359 = self.features_denseblock4_denselayer16_layers_conv2_weight\n",
      "    conv2d_119 = torch.ops.aten.conv2d.default(relu__119, _param_constant359, None, [1, 1], [1, 1]);  relu__119 = _param_constant359 = None\n",
      "    cat_57 = torch.ops.aten.cat.default([cat_56, conv2d_119], 1);  cat_56 = conv2d_119 = None\n",
      "    empty_120 = torch.ops.aten.empty.memory_format([0], dtype = torch.uint8, layout = torch.strided, device = device(type='cpu'));  empty_120 = None\n",
      "    _param_constant360 = self.features_norm5_weight\n",
      "    _param_constant361 = self.features_norm5_bias\n",
      "    _tensor_constant240 = self.features_norm5_running_mean\n",
      "    _tensor_constant241 = self.features_norm5_running_var\n",
      "    _native_batch_norm_legit_no_training_120 = torch.ops.aten._native_batch_norm_legit_no_training.default(cat_57, _param_constant360, _param_constant361, _tensor_constant240, _tensor_constant241, 0.1, 1e-05);  cat_57 = _param_constant360 = _param_constant361 = _tensor_constant240 = _tensor_constant241 = None\n",
      "    getitem_360 = _native_batch_norm_legit_no_training_120[0]\n",
      "    getitem_361 = _native_batch_norm_legit_no_training_120[1];  getitem_361 = None\n",
      "    getitem_362 = _native_batch_norm_legit_no_training_120[2];  _native_batch_norm_legit_no_training_120 = getitem_362 = None\n",
      "    relu__120 = torch.ops.aten.relu_.default(getitem_360);  getitem_360 = None\n",
      "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(relu__120, [1, 1]);  relu__120 = None\n",
      "    flatten = torch.ops.aten.flatten.using_ints(adaptive_avg_pool2d, 1);  adaptive_avg_pool2d = None\n",
      "    _param_constant362 = self.class_layers_out_weight\n",
      "    _param_constant363 = self.class_layers_out_bias\n",
      "    linear = torch.ops.aten.linear.default(flatten, _param_constant362, _param_constant363);  flatten = _param_constant362 = _param_constant363 = None\n",
      "    return pytree.tree_unflatten([linear], self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-Autograd ATen Dialect Graph\")\n",
    "print(pre_autograd_aten_dialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantizer = XNNPACKQuantizer().set_global(get_symmetric_quantization_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.ao.quantization.quantizer.xnnpack_quantizer.XNNPACKQuantizer at 0x7b0e8e988e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_2) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_4) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_6) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_8) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_10) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_12) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_15) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_17) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_19) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_21) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_23) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_25) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_27) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_29) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_31) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_33) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_35) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_37) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_40) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_42) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_44) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_46) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_48) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_50) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_52) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_54) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_56) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_58) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_60) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_62) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_64) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_66) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_68) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_70) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_72) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_74) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_76) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_78) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_80) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_82) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_84) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_86) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_89) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_91) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_93) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_95) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_97) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_99) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_101) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_103) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_105) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_107) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_109) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_111) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_113) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_115) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_117) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n",
      "/home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/torch/fx/graph.py:1062: UserWarning: erase_node(_native_batch_norm_legit_no_training_119) on an already erased node\n",
      "  warnings.warn(f\"erase_node({to_erase}) on an already erased node\")\n"
     ]
    }
   ],
   "source": [
    "prepared_graph = prepare_pt2e(pre_autograd_aten_dialect, quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (activation_post_process_0): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_1): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_2): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_3): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_4): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_5): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_6): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_7): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_8): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_9): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_10): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_11): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_12): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_13): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_14): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_15): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_16): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_17): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_18): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_19): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_20): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_21): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_22): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_23): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_24): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_25): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_26): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_27): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_28): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_29): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_30): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_31): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_32): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_33): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_34): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_35): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_36): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_37): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_38): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_39): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_40): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_41): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_42): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_48): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_43): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_44): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_45): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_46): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_47): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_49): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_50): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_51): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_52): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_53): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_54): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_55): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_56): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_57): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_58): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_59): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_60): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_61): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_62): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_63): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_64): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_65): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_66): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_67): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_68): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_69): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_70): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_71): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_72): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_73): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_74): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_75): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_76): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_77): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_78): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_79): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_80): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_81): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_82): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_83): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_84): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_85): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_86): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_87): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_88): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_89): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_90): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_91): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_92): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_93): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_94): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_95): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_96): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_97): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_98): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_99): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_100): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_101): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_102): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_103): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_104): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_105): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_106): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_107): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_108): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_109): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_110): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_111): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_112): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_113): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_114): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_115): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_116): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_117): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_118): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_124): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_119): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_120): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_121): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_122): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_123): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_125): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_126): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_127): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_128): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_129): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_130): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_131): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_132): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_133): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_134): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_135): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_136): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_137): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_138): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_139): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_140): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_141): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_142): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_143): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_144): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_145): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_146): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_147): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_148): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_149): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_150): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_151): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_152): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_153): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_154): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_155): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_156): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_157): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_158): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_159): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_160): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_161): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_162): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_163): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_164): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_165): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_166): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_167): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_168): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_169): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_170): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_171): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_172): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_173): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_174): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_175): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_176): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_177): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_178): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_179): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_180): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_181): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_182): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_183): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_184): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_185): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_186): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_187): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_188): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_189): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_190): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_191): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_192): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_193): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_194): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_195): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_196): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_197): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_198): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_199): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_200): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_201): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_202): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_203): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_204): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_205): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_206): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_207): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_208): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_209): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_210): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_211): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_212): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_213): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_214): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_215): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_216): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_217): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_218): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_219): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_220): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_221): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_222): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_223): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_224): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_225): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_226): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_227): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_228): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_229): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_230): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_231): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_232): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_233): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_234): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_235): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_236): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_237): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_238): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_239): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_240): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_241): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_242): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_243): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_244): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_245): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_246): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_247): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_248): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_249): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_250): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_251): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_252): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_253): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_254): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_255): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_256): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_257): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_258): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_259): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_260): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_261): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_262): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_263): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_264): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_265): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_266): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_272): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_267): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_268): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_269): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_270): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_271): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_273): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_274): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_275): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_276): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_277): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_278): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_279): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_280): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_281): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_282): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_283): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_284): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_285): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_286): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_287): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_288): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_289): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_290): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_291): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_292): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_293): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_294): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_295): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_296): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_297): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_298): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_299): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_300): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_301): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_302): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_303): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_304): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_305): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_306): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_307): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_308): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_309): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_310): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_311): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_312): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_313): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_314): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_315): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_316): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_317): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_318): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_319): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_320): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_321): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_322): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_323): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_324): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_325): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_326): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_327): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_328): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_329): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_330): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_331): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_332): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_333): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_334): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_335): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_336): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_337): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_338): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_339): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_340): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_341): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_342): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_343): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_344): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_345): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_346): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_347): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_348): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_349): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_350): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_351): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_352): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_353): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_354): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_355): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_356): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_357): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_358): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_359): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_360): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_361): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_362): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_363): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_364): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_365): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_366): HistogramObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_367): MinMaxObserver(min_val=inf, max_val=-inf)\n",
       "  (activation_post_process_368): HistogramObserver(min_val=inf, max_val=-inf)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate(prepared_graph, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate with a sample dataset\n",
    "converted_graph = convert_pt2e(prepared_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Graph\n",
      "GraphModule()\n",
      "\n",
      "\n",
      "\n",
      "def forward(self, x):\n",
      "    arg0, = fx_pytree.tree_flatten_spec(([x], {}), self._in_spec)\n",
      "    arg0_1 = arg0\n",
      "    quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(arg0_1, 0.0309614110738039, 0, -128, 127, torch.int8);  arg0_1 = None\n",
      "    dequantize_per_tensor_default = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default, 0.0309614110738039, 0, -128, 127, torch.int8);  quantize_per_tensor_default = None\n",
      "    _frozen_param0 = self._frozen_param0\n",
      "    dequantize_per_tensor_default_1 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param0, 0.01635424979031086, 0, -127, 127, torch.int8);  _frozen_param0 = None\n",
      "    features_conv0_weight_bias = self.features_conv0_weight_bias\n",
      "    conv2d = torch.ops.aten.conv2d.default(dequantize_per_tensor_default, dequantize_per_tensor_default_1, features_conv0_weight_bias, [2, 2], [3, 3]);  dequantize_per_tensor_default = dequantize_per_tensor_default_1 = features_conv0_weight_bias = None\n",
      "    relu_ = torch.ops.aten.relu_.default(conv2d);  conv2d = None\n",
      "    quantize_per_tensor_default_2 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_, 0.15412181615829468, -13, -128, 127, torch.int8);  relu_ = None\n",
      "    dequantize_per_tensor_default_2 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_2, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_2 = None\n",
      "    max_pool2d = torch.ops.aten.max_pool2d.default(dequantize_per_tensor_default_2, [3, 3], [2, 2], [1, 1]);  dequantize_per_tensor_default_2 = None\n",
      "    quantize_per_tensor_default_3 = torch.ops.quantized_decomposed.quantize_per_tensor.default(max_pool2d, 0.15412181615829468, -13, -128, 127, torch.int8);  max_pool2d = None\n",
      "    dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_369 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
      "    _param_constant3 = self.features_denseblock1_denselayer1_layers_norm1_weight\n",
      "    _param_constant4 = self.features_denseblock1_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant2 = self.features_denseblock1_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant3 = self.features_denseblock1_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_3, _param_constant3, _param_constant4, _tensor_constant2, _tensor_constant3, 0.1, 1e-05);  dequantize_per_tensor_default_3 = _param_constant3 = _param_constant4 = _tensor_constant2 = _tensor_constant3 = None\n",
      "    getitem_3 = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
      "    relu__1 = torch.ops.aten.relu_.default(getitem_3);  getitem_3 = None\n",
      "    quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__1, 0.14546501636505127, -128, -128, 127, torch.int8);  relu__1 = None\n",
      "    dequantize_per_tensor_default_4 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_4, 0.14546501636505127, -128, -128, 127, torch.int8);  quantize_per_tensor_default_4 = None\n",
      "    _frozen_param1 = self._frozen_param1\n",
      "    dequantize_per_tensor_default_5 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param1, 0.011223173700273037, 0, -127, 127, torch.int8);  _frozen_param1 = None\n",
      "    features_denseblock1_denselayer1_layers_conv1_weight_bias = self.features_denseblock1_denselayer1_layers_conv1_weight_bias\n",
      "    conv2d_1 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_4, dequantize_per_tensor_default_5, features_denseblock1_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_default_4 = dequantize_per_tensor_default_5 = features_denseblock1_denselayer1_layers_conv1_weight_bias = None\n",
      "    relu__2 = torch.ops.aten.relu_.default(conv2d_1);  conv2d_1 = None\n",
      "    quantize_per_tensor_default_6 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__2, 0.04576343670487404, -128, -128, 127, torch.int8);  relu__2 = None\n",
      "    dequantize_per_tensor_default_6 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_6, 0.04576343670487404, -128, -128, 127, torch.int8);  quantize_per_tensor_default_6 = None\n",
      "    _frozen_param2 = self._frozen_param2\n",
      "    dequantize_per_tensor_default_7 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param2, 0.003611508058384061, 0, -127, 127, torch.int8);  _frozen_param2 = None\n",
      "    conv2d_2 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_6, dequantize_per_tensor_default_7, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_6 = dequantize_per_tensor_default_7 = None\n",
      "    quantize_per_tensor_default_8 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_2 = None\n",
      "    dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
      "    cat = torch.ops.aten.cat.default([dequantize_per_tensor_default_369, dequantize_per_tensor_default_8], 1);  dequantize_per_tensor_default_369 = dequantize_per_tensor_default_8 = None\n",
      "    quantize_per_tensor_default_9 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat, 0.15412181615829468, -13, -128, 127, torch.int8);  cat = None\n",
      "    dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_370 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_9 = None\n",
      "    _param_constant9 = self.features_denseblock1_denselayer2_layers_norm1_weight\n",
      "    _param_constant10 = self.features_denseblock1_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant6 = self.features_denseblock1_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant7 = self.features_denseblock1_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_9, _param_constant9, _param_constant10, _tensor_constant6, _tensor_constant7, 0.1, 1e-05);  dequantize_per_tensor_default_9 = _param_constant9 = _param_constant10 = _tensor_constant6 = _tensor_constant7 = None\n",
      "    getitem_9 = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
      "    relu__3 = torch.ops.aten.relu_.default(getitem_9);  getitem_9 = None\n",
      "    quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__3, 0.3290613889694214, -128, -128, 127, torch.int8);  relu__3 = None\n",
      "    dequantize_per_tensor_default_10 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_10, 0.3290613889694214, -128, -128, 127, torch.int8);  quantize_per_tensor_default_10 = None\n",
      "    _frozen_param3 = self._frozen_param3\n",
      "    dequantize_per_tensor_default_11 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param3, 0.007783120032399893, 0, -127, 127, torch.int8);  _frozen_param3 = None\n",
      "    features_denseblock1_denselayer2_layers_conv1_weight_bias = self.features_denseblock1_denselayer2_layers_conv1_weight_bias\n",
      "    conv2d_3 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_10, dequantize_per_tensor_default_11, features_denseblock1_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_default_10 = dequantize_per_tensor_default_11 = features_denseblock1_denselayer2_layers_conv1_weight_bias = None\n",
      "    relu__4 = torch.ops.aten.relu_.default(conv2d_3);  conv2d_3 = None\n",
      "    quantize_per_tensor_default_12 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__4, 0.11768194288015366, -128, -128, 127, torch.int8);  relu__4 = None\n",
      "    dequantize_per_tensor_default_12 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_12, 0.11768194288015366, -128, -128, 127, torch.int8);  quantize_per_tensor_default_12 = None\n",
      "    _frozen_param4 = self._frozen_param4\n",
      "    dequantize_per_tensor_default_13 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param4, 0.0034869362134486437, 0, -127, 127, torch.int8);  _frozen_param4 = None\n",
      "    conv2d_4 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_12, dequantize_per_tensor_default_13, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_12 = dequantize_per_tensor_default_13 = None\n",
      "    quantize_per_tensor_default_14 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_4 = None\n",
      "    dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
      "    cat_1 = torch.ops.aten.cat.default([dequantize_per_tensor_default_370, dequantize_per_tensor_default_14], 1);  dequantize_per_tensor_default_370 = dequantize_per_tensor_default_14 = None\n",
      "    quantize_per_tensor_default_15 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_1, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_1 = None\n",
      "    dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_371 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_15 = None\n",
      "    _param_constant15 = self.features_denseblock1_denselayer3_layers_norm1_weight\n",
      "    _param_constant16 = self.features_denseblock1_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant10 = self.features_denseblock1_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant11 = self.features_denseblock1_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_15, _param_constant15, _param_constant16, _tensor_constant10, _tensor_constant11, 0.1, 1e-05);  dequantize_per_tensor_default_15 = _param_constant15 = _param_constant16 = _tensor_constant10 = _tensor_constant11 = None\n",
      "    getitem_15 = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
      "    relu__5 = torch.ops.aten.relu_.default(getitem_15);  getitem_15 = None\n",
      "    quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__5, 0.10120505094528198, -128, -128, 127, torch.int8);  relu__5 = None\n",
      "    dequantize_per_tensor_default_16 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_16, 0.10120505094528198, -128, -128, 127, torch.int8);  quantize_per_tensor_default_16 = None\n",
      "    _frozen_param5 = self._frozen_param5\n",
      "    dequantize_per_tensor_default_17 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param5, 0.007038871757686138, 0, -127, 127, torch.int8);  _frozen_param5 = None\n",
      "    features_denseblock1_denselayer3_layers_conv1_weight_bias = self.features_denseblock1_denselayer3_layers_conv1_weight_bias\n",
      "    conv2d_5 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_16, dequantize_per_tensor_default_17, features_denseblock1_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_default_16 = dequantize_per_tensor_default_17 = features_denseblock1_denselayer3_layers_conv1_weight_bias = None\n",
      "    relu__6 = torch.ops.aten.relu_.default(conv2d_5);  conv2d_5 = None\n",
      "    quantize_per_tensor_default_18 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__6, 0.027735194191336632, -128, -128, 127, torch.int8);  relu__6 = None\n",
      "    dequantize_per_tensor_default_18 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_18, 0.027735194191336632, -128, -128, 127, torch.int8);  quantize_per_tensor_default_18 = None\n",
      "    _frozen_param6 = self._frozen_param6\n",
      "    dequantize_per_tensor_default_19 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param6, 0.002163182944059372, 0, -127, 127, torch.int8);  _frozen_param6 = None\n",
      "    conv2d_6 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_18, dequantize_per_tensor_default_19, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_18 = dequantize_per_tensor_default_19 = None\n",
      "    quantize_per_tensor_default_20 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_6 = None\n",
      "    dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_20 = None\n",
      "    cat_2 = torch.ops.aten.cat.default([dequantize_per_tensor_default_371, dequantize_per_tensor_default_20], 1);  dequantize_per_tensor_default_371 = dequantize_per_tensor_default_20 = None\n",
      "    quantize_per_tensor_default_21 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_2, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_2 = None\n",
      "    dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_372 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
      "    _param_constant21 = self.features_denseblock1_denselayer4_layers_norm1_weight\n",
      "    _param_constant22 = self.features_denseblock1_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant14 = self.features_denseblock1_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant15 = self.features_denseblock1_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_21, _param_constant21, _param_constant22, _tensor_constant14, _tensor_constant15, 0.1, 1e-05);  dequantize_per_tensor_default_21 = _param_constant21 = _param_constant22 = _tensor_constant14 = _tensor_constant15 = None\n",
      "    getitem_21 = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
      "    relu__7 = torch.ops.aten.relu_.default(getitem_21);  getitem_21 = None\n",
      "    quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__7, 0.03223251551389694, -128, -128, 127, torch.int8);  relu__7 = None\n",
      "    dequantize_per_tensor_default_22 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_22, 0.03223251551389694, -128, -128, 127, torch.int8);  quantize_per_tensor_default_22 = None\n",
      "    _frozen_param7 = self._frozen_param7\n",
      "    dequantize_per_tensor_default_23 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param7, 0.006927610840648413, 0, -127, 127, torch.int8);  _frozen_param7 = None\n",
      "    features_denseblock1_denselayer4_layers_conv1_weight_bias = self.features_denseblock1_denselayer4_layers_conv1_weight_bias\n",
      "    conv2d_7 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_22, dequantize_per_tensor_default_23, features_denseblock1_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_default_22 = dequantize_per_tensor_default_23 = features_denseblock1_denselayer4_layers_conv1_weight_bias = None\n",
      "    relu__8 = torch.ops.aten.relu_.default(conv2d_7);  conv2d_7 = None\n",
      "    quantize_per_tensor_default_24 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__8, 0.0137783233076334, -128, -128, 127, torch.int8);  relu__8 = None\n",
      "    dequantize_per_tensor_default_24 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_24, 0.0137783233076334, -128, -128, 127, torch.int8);  quantize_per_tensor_default_24 = None\n",
      "    _frozen_param8 = self._frozen_param8\n",
      "    dequantize_per_tensor_default_25 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param8, 0.0016751647926867008, 0, -127, 127, torch.int8);  _frozen_param8 = None\n",
      "    conv2d_8 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_24, dequantize_per_tensor_default_25, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_24 = dequantize_per_tensor_default_25 = None\n",
      "    quantize_per_tensor_default_26 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_8, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_8 = None\n",
      "    dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_26 = None\n",
      "    cat_3 = torch.ops.aten.cat.default([dequantize_per_tensor_default_372, dequantize_per_tensor_default_26], 1);  dequantize_per_tensor_default_372 = dequantize_per_tensor_default_26 = None\n",
      "    quantize_per_tensor_default_27 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_3, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_3 = None\n",
      "    dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_373 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
      "    _param_constant27 = self.features_denseblock1_denselayer5_layers_norm1_weight\n",
      "    _param_constant28 = self.features_denseblock1_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant18 = self.features_denseblock1_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant19 = self.features_denseblock1_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_27, _param_constant27, _param_constant28, _tensor_constant18, _tensor_constant19, 0.1, 1e-05);  dequantize_per_tensor_default_27 = _param_constant27 = _param_constant28 = _tensor_constant18 = _tensor_constant19 = None\n",
      "    getitem_27 = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
      "    relu__9 = torch.ops.aten.relu_.default(getitem_27);  getitem_27 = None\n",
      "    quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__9, 0.05981072410941124, -128, -128, 127, torch.int8);  relu__9 = None\n",
      "    dequantize_per_tensor_default_28 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_28, 0.05981072410941124, -128, -128, 127, torch.int8);  quantize_per_tensor_default_28 = None\n",
      "    _frozen_param9 = self._frozen_param9\n",
      "    dequantize_per_tensor_default_29 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param9, 0.010060940869152546, 0, -127, 127, torch.int8);  _frozen_param9 = None\n",
      "    features_denseblock1_denselayer5_layers_conv1_weight_bias = self.features_denseblock1_denselayer5_layers_conv1_weight_bias\n",
      "    conv2d_9 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_28, dequantize_per_tensor_default_29, features_denseblock1_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_default_28 = dequantize_per_tensor_default_29 = features_denseblock1_denselayer5_layers_conv1_weight_bias = None\n",
      "    relu__10 = torch.ops.aten.relu_.default(conv2d_9);  conv2d_9 = None\n",
      "    quantize_per_tensor_default_30 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__10, 0.01713251695036888, -128, -128, 127, torch.int8);  relu__10 = None\n",
      "    dequantize_per_tensor_default_30 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_30, 0.01713251695036888, -128, -128, 127, torch.int8);  quantize_per_tensor_default_30 = None\n",
      "    _frozen_param10 = self._frozen_param10\n",
      "    dequantize_per_tensor_default_31 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param10, 0.0028601507656276226, 0, -127, 127, torch.int8);  _frozen_param10 = None\n",
      "    conv2d_10 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_30, dequantize_per_tensor_default_31, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_30 = dequantize_per_tensor_default_31 = None\n",
      "    quantize_per_tensor_default_32 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_10, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_10 = None\n",
      "    dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_32 = None\n",
      "    cat_4 = torch.ops.aten.cat.default([dequantize_per_tensor_default_373, dequantize_per_tensor_default_32], 1);  dequantize_per_tensor_default_373 = dequantize_per_tensor_default_32 = None\n",
      "    quantize_per_tensor_default_33 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_4, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_4 = None\n",
      "    dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_374 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
      "    _param_constant33 = self.features_denseblock1_denselayer6_layers_norm1_weight\n",
      "    _param_constant34 = self.features_denseblock1_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant22 = self.features_denseblock1_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant23 = self.features_denseblock1_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_33, _param_constant33, _param_constant34, _tensor_constant22, _tensor_constant23, 0.1, 1e-05);  dequantize_per_tensor_default_33 = _param_constant33 = _param_constant34 = _tensor_constant22 = _tensor_constant23 = None\n",
      "    getitem_33 = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
      "    relu__11 = torch.ops.aten.relu_.default(getitem_33);  getitem_33 = None\n",
      "    quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__11, 0.02181347645819187, -128, -128, 127, torch.int8);  relu__11 = None\n",
      "    dequantize_per_tensor_default_34 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_34, 0.02181347645819187, -128, -128, 127, torch.int8);  quantize_per_tensor_default_34 = None\n",
      "    _frozen_param11 = self._frozen_param11\n",
      "    dequantize_per_tensor_default_35 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param11, 0.014067327603697777, 0, -127, 127, torch.int8);  _frozen_param11 = None\n",
      "    features_denseblock1_denselayer6_layers_conv1_weight_bias = self.features_denseblock1_denselayer6_layers_conv1_weight_bias\n",
      "    conv2d_11 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_34, dequantize_per_tensor_default_35, features_denseblock1_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_default_34 = dequantize_per_tensor_default_35 = features_denseblock1_denselayer6_layers_conv1_weight_bias = None\n",
      "    relu__12 = torch.ops.aten.relu_.default(conv2d_11);  conv2d_11 = None\n",
      "    quantize_per_tensor_default_36 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__12, 0.012534106150269508, -128, -128, 127, torch.int8);  relu__12 = None\n",
      "    dequantize_per_tensor_default_36 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_36, 0.012534106150269508, -128, -128, 127, torch.int8);  quantize_per_tensor_default_36 = None\n",
      "    _frozen_param12 = self._frozen_param12\n",
      "    dequantize_per_tensor_default_37 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param12, 0.0021891833748668432, 0, -127, 127, torch.int8);  _frozen_param12 = None\n",
      "    conv2d_12 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_36, dequantize_per_tensor_default_37, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_36 = dequantize_per_tensor_default_37 = None\n",
      "    quantize_per_tensor_default_38 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_12 = None\n",
      "    dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_38 = None\n",
      "    cat_5 = torch.ops.aten.cat.default([dequantize_per_tensor_default_374, dequantize_per_tensor_default_38], 1);  dequantize_per_tensor_default_374 = dequantize_per_tensor_default_38 = None\n",
      "    quantize_per_tensor_default_39 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_5, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_5 = None\n",
      "    dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
      "    _param_constant39 = self.features_transition1_norm_weight\n",
      "    _param_constant40 = self.features_transition1_norm_bias\n",
      "    _tensor_constant26 = self.features_transition1_norm_running_mean\n",
      "    _tensor_constant27 = self.features_transition1_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_39, _param_constant39, _param_constant40, _tensor_constant26, _tensor_constant27, 0.1, 1e-05);  dequantize_per_tensor_default_39 = _param_constant39 = _param_constant40 = _tensor_constant26 = _tensor_constant27 = None\n",
      "    getitem_39 = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
      "    relu__13 = torch.ops.aten.relu_.default(getitem_39);  getitem_39 = None\n",
      "    quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__13, 0.11582395434379578, -128, -128, 127, torch.int8);  relu__13 = None\n",
      "    dequantize_per_tensor_default_40 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_40, 0.11582395434379578, -128, -128, 127, torch.int8);  quantize_per_tensor_default_40 = None\n",
      "    _frozen_param13 = self._frozen_param13\n",
      "    dequantize_per_tensor_default_41 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param13, 0.007403446361422539, 0, -127, 127, torch.int8);  _frozen_param13 = None\n",
      "    conv2d_13 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_40, dequantize_per_tensor_default_41);  dequantize_per_tensor_default_40 = dequantize_per_tensor_default_41 = None\n",
      "    quantize_per_tensor_default_42 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_13, 0.09962928295135498, 14, -128, 127, torch.int8);  conv2d_13 = None\n",
      "    dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.09962928295135498, 14, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
      "    avg_pool2d = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_default_42, [2, 2], [2, 2]);  dequantize_per_tensor_default_42 = None\n",
      "    quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_43 = None\n",
      "    _param_constant42 = self.features_denseblock2_denselayer1_layers_norm1_weight\n",
      "    _param_constant43 = self.features_denseblock2_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant28 = self.features_denseblock2_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant29 = self.features_denseblock2_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d, _param_constant42, _param_constant43, _tensor_constant28, _tensor_constant29, 0.1, 1e-05);  avg_pool2d = _param_constant42 = _param_constant43 = _tensor_constant28 = _tensor_constant29 = None\n",
      "    getitem_42 = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
      "    relu__14 = torch.ops.aten.relu_.default(getitem_42);  getitem_42 = None\n",
      "    quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__14, 0.028628453612327576, -128, -128, 127, torch.int8);  relu__14 = None\n",
      "    dequantize_per_tensor_default_44 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_44, 0.028628453612327576, -128, -128, 127, torch.int8);  quantize_per_tensor_default_44 = None\n",
      "    _frozen_param14 = self._frozen_param14\n",
      "    dequantize_per_tensor_default_45 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param14, 0.007619316689670086, 0, -127, 127, torch.int8);  _frozen_param14 = None\n",
      "    features_denseblock2_denselayer1_layers_conv1_weight_bias = self.features_denseblock2_denselayer1_layers_conv1_weight_bias\n",
      "    conv2d_14 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_44, dequantize_per_tensor_default_45, features_denseblock2_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_default_44 = dequantize_per_tensor_default_45 = features_denseblock2_denselayer1_layers_conv1_weight_bias = None\n",
      "    relu__15 = torch.ops.aten.relu_.default(conv2d_14);  conv2d_14 = None\n",
      "    quantize_per_tensor_default_46 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__15, 0.015536557883024216, -128, -128, 127, torch.int8);  relu__15 = None\n",
      "    dequantize_per_tensor_default_46 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_46, 0.015536557883024216, -128, -128, 127, torch.int8);  quantize_per_tensor_default_46 = None\n",
      "    _frozen_param15 = self._frozen_param15\n",
      "    dequantize_per_tensor_default_47 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param15, 0.0031634012702852488, 0, -127, 127, torch.int8);  _frozen_param15 = None\n",
      "    conv2d_15 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_46, dequantize_per_tensor_default_47, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_46 = dequantize_per_tensor_default_47 = None\n",
      "    quantize_per_tensor_default_48 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_15, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_15 = None\n",
      "    dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_48 = None\n",
      "    cat_6 = torch.ops.aten.cat.default([dequantize_per_tensor_default_43, dequantize_per_tensor_default_48], 1);  dequantize_per_tensor_default_43 = dequantize_per_tensor_default_48 = None\n",
      "    quantize_per_tensor_default_49 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_6, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_6 = None\n",
      "    dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_375 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_49 = None\n",
      "    _param_constant48 = self.features_denseblock2_denselayer2_layers_norm1_weight\n",
      "    _param_constant49 = self.features_denseblock2_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant32 = self.features_denseblock2_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant33 = self.features_denseblock2_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_49, _param_constant48, _param_constant49, _tensor_constant32, _tensor_constant33, 0.1, 1e-05);  dequantize_per_tensor_default_49 = _param_constant48 = _param_constant49 = _tensor_constant32 = _tensor_constant33 = None\n",
      "    getitem_48 = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
      "    relu__16 = torch.ops.aten.relu_.default(getitem_48);  getitem_48 = None\n",
      "    quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__16, 0.03705156221985817, -128, -128, 127, torch.int8);  relu__16 = None\n",
      "    dequantize_per_tensor_default_50 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_50, 0.03705156221985817, -128, -128, 127, torch.int8);  quantize_per_tensor_default_50 = None\n",
      "    _frozen_param16 = self._frozen_param16\n",
      "    dequantize_per_tensor_default_51 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param16, 0.007260892074555159, 0, -127, 127, torch.int8);  _frozen_param16 = None\n",
      "    features_denseblock2_denselayer2_layers_conv1_weight_bias = self.features_denseblock2_denselayer2_layers_conv1_weight_bias\n",
      "    conv2d_16 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_50, dequantize_per_tensor_default_51, features_denseblock2_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_default_50 = dequantize_per_tensor_default_51 = features_denseblock2_denselayer2_layers_conv1_weight_bias = None\n",
      "    relu__17 = torch.ops.aten.relu_.default(conv2d_16);  conv2d_16 = None\n",
      "    quantize_per_tensor_default_52 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__17, 0.01951760984957218, -128, -128, 127, torch.int8);  relu__17 = None\n",
      "    dequantize_per_tensor_default_52 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_52, 0.01951760984957218, -128, -128, 127, torch.int8);  quantize_per_tensor_default_52 = None\n",
      "    _frozen_param17 = self._frozen_param17\n",
      "    dequantize_per_tensor_default_53 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param17, 0.0017099434044212103, 0, -127, 127, torch.int8);  _frozen_param17 = None\n",
      "    conv2d_17 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_52, dequantize_per_tensor_default_53, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_52 = dequantize_per_tensor_default_53 = None\n",
      "    quantize_per_tensor_default_54 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_17 = None\n",
      "    dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_54 = None\n",
      "    cat_7 = torch.ops.aten.cat.default([dequantize_per_tensor_default_375, dequantize_per_tensor_default_54], 1);  dequantize_per_tensor_default_375 = dequantize_per_tensor_default_54 = None\n",
      "    quantize_per_tensor_default_55 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_7, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_7 = None\n",
      "    dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_376 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_55 = None\n",
      "    _param_constant54 = self.features_denseblock2_denselayer3_layers_norm1_weight\n",
      "    _param_constant55 = self.features_denseblock2_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant36 = self.features_denseblock2_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant37 = self.features_denseblock2_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_55, _param_constant54, _param_constant55, _tensor_constant36, _tensor_constant37, 0.1, 1e-05);  dequantize_per_tensor_default_55 = _param_constant54 = _param_constant55 = _tensor_constant36 = _tensor_constant37 = None\n",
      "    getitem_54 = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
      "    relu__18 = torch.ops.aten.relu_.default(getitem_54);  getitem_54 = None\n",
      "    quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__18, 0.018638765439391136, -128, -128, 127, torch.int8);  relu__18 = None\n",
      "    dequantize_per_tensor_default_56 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_56, 0.018638765439391136, -128, -128, 127, torch.int8);  quantize_per_tensor_default_56 = None\n",
      "    _frozen_param18 = self._frozen_param18\n",
      "    dequantize_per_tensor_default_57 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param18, 0.007643700111657381, 0, -127, 127, torch.int8);  _frozen_param18 = None\n",
      "    features_denseblock2_denselayer3_layers_conv1_weight_bias = self.features_denseblock2_denselayer3_layers_conv1_weight_bias\n",
      "    conv2d_18 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_56, dequantize_per_tensor_default_57, features_denseblock2_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_default_56 = dequantize_per_tensor_default_57 = features_denseblock2_denselayer3_layers_conv1_weight_bias = None\n",
      "    relu__19 = torch.ops.aten.relu_.default(conv2d_18);  conv2d_18 = None\n",
      "    quantize_per_tensor_default_58 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__19, 0.009119376540184021, -128, -128, 127, torch.int8);  relu__19 = None\n",
      "    dequantize_per_tensor_default_58 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_58, 0.009119376540184021, -128, -128, 127, torch.int8);  quantize_per_tensor_default_58 = None\n",
      "    _frozen_param19 = self._frozen_param19\n",
      "    dequantize_per_tensor_default_59 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param19, 0.0019441406475380063, 0, -127, 127, torch.int8);  _frozen_param19 = None\n",
      "    conv2d_19 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_58, dequantize_per_tensor_default_59, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_58 = dequantize_per_tensor_default_59 = None\n",
      "    quantize_per_tensor_default_60 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_19 = None\n",
      "    dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_60, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_60 = None\n",
      "    cat_8 = torch.ops.aten.cat.default([dequantize_per_tensor_default_376, dequantize_per_tensor_default_60], 1);  dequantize_per_tensor_default_376 = dequantize_per_tensor_default_60 = None\n",
      "    quantize_per_tensor_default_61 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_8, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_8 = None\n",
      "    dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_377 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_61 = None\n",
      "    _param_constant60 = self.features_denseblock2_denselayer4_layers_norm1_weight\n",
      "    _param_constant61 = self.features_denseblock2_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant40 = self.features_denseblock2_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant41 = self.features_denseblock2_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_61, _param_constant60, _param_constant61, _tensor_constant40, _tensor_constant41, 0.1, 1e-05);  dequantize_per_tensor_default_61 = _param_constant60 = _param_constant61 = _tensor_constant40 = _tensor_constant41 = None\n",
      "    getitem_60 = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
      "    relu__20 = torch.ops.aten.relu_.default(getitem_60);  getitem_60 = None\n",
      "    quantize_per_tensor_default_62 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__20, 0.029592720791697502, -128, -128, 127, torch.int8);  relu__20 = None\n",
      "    dequantize_per_tensor_default_62 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_62, 0.029592720791697502, -128, -128, 127, torch.int8);  quantize_per_tensor_default_62 = None\n",
      "    _frozen_param20 = self._frozen_param20\n",
      "    dequantize_per_tensor_default_63 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param20, 0.011065496131777763, 0, -127, 127, torch.int8);  _frozen_param20 = None\n",
      "    features_denseblock2_denselayer4_layers_conv1_weight_bias = self.features_denseblock2_denselayer4_layers_conv1_weight_bias\n",
      "    conv2d_20 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_62, dequantize_per_tensor_default_63, features_denseblock2_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_default_62 = dequantize_per_tensor_default_63 = features_denseblock2_denselayer4_layers_conv1_weight_bias = None\n",
      "    relu__21 = torch.ops.aten.relu_.default(conv2d_20);  conv2d_20 = None\n",
      "    quantize_per_tensor_default_64 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__21, 0.023821014910936356, -128, -128, 127, torch.int8);  relu__21 = None\n",
      "    dequantize_per_tensor_default_64 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_64, 0.023821014910936356, -128, -128, 127, torch.int8);  quantize_per_tensor_default_64 = None\n",
      "    _frozen_param21 = self._frozen_param21\n",
      "    dequantize_per_tensor_default_65 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param21, 0.00323011027649045, 0, -127, 127, torch.int8);  _frozen_param21 = None\n",
      "    conv2d_21 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_64, dequantize_per_tensor_default_65, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_64 = dequantize_per_tensor_default_65 = None\n",
      "    quantize_per_tensor_default_66 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_21, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_21 = None\n",
      "    dequantize_per_tensor_default_66 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_66, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_66 = None\n",
      "    cat_9 = torch.ops.aten.cat.default([dequantize_per_tensor_default_377, dequantize_per_tensor_default_66], 1);  dequantize_per_tensor_default_377 = dequantize_per_tensor_default_66 = None\n",
      "    quantize_per_tensor_default_67 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_9, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_9 = None\n",
      "    dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_378 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_67 = None\n",
      "    _param_constant66 = self.features_denseblock2_denselayer5_layers_norm1_weight\n",
      "    _param_constant67 = self.features_denseblock2_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant44 = self.features_denseblock2_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant45 = self.features_denseblock2_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_67, _param_constant66, _param_constant67, _tensor_constant44, _tensor_constant45, 0.1, 1e-05);  dequantize_per_tensor_default_67 = _param_constant66 = _param_constant67 = _tensor_constant44 = _tensor_constant45 = None\n",
      "    getitem_66 = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
      "    relu__22 = torch.ops.aten.relu_.default(getitem_66);  getitem_66 = None\n",
      "    quantize_per_tensor_default_68 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__22, 0.013898526318371296, -128, -128, 127, torch.int8);  relu__22 = None\n",
      "    dequantize_per_tensor_default_68 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_68, 0.013898526318371296, -128, -128, 127, torch.int8);  quantize_per_tensor_default_68 = None\n",
      "    _frozen_param22 = self._frozen_param22\n",
      "    dequantize_per_tensor_default_69 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param22, 0.0064514512196183205, 0, -127, 127, torch.int8);  _frozen_param22 = None\n",
      "    features_denseblock2_denselayer5_layers_conv1_weight_bias = self.features_denseblock2_denselayer5_layers_conv1_weight_bias\n",
      "    conv2d_22 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_68, dequantize_per_tensor_default_69, features_denseblock2_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_default_68 = dequantize_per_tensor_default_69 = features_denseblock2_denselayer5_layers_conv1_weight_bias = None\n",
      "    relu__23 = torch.ops.aten.relu_.default(conv2d_22);  conv2d_22 = None\n",
      "    quantize_per_tensor_default_70 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__23, 0.0094265416264534, -128, -128, 127, torch.int8);  relu__23 = None\n",
      "    dequantize_per_tensor_default_70 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_70, 0.0094265416264534, -128, -128, 127, torch.int8);  quantize_per_tensor_default_70 = None\n",
      "    _frozen_param23 = self._frozen_param23\n",
      "    dequantize_per_tensor_default_71 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param23, 0.0015792256454005837, 0, -127, 127, torch.int8);  _frozen_param23 = None\n",
      "    conv2d_23 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_70, dequantize_per_tensor_default_71, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_70 = dequantize_per_tensor_default_71 = None\n",
      "    quantize_per_tensor_default_72 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_23, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_23 = None\n",
      "    dequantize_per_tensor_default_72 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_72, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_72 = None\n",
      "    cat_10 = torch.ops.aten.cat.default([dequantize_per_tensor_default_378, dequantize_per_tensor_default_72], 1);  dequantize_per_tensor_default_378 = dequantize_per_tensor_default_72 = None\n",
      "    quantize_per_tensor_default_73 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_10, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_10 = None\n",
      "    dequantize_per_tensor_default_73 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_379 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_73 = None\n",
      "    _param_constant72 = self.features_denseblock2_denselayer6_layers_norm1_weight\n",
      "    _param_constant73 = self.features_denseblock2_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant48 = self.features_denseblock2_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant49 = self.features_denseblock2_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_73, _param_constant72, _param_constant73, _tensor_constant48, _tensor_constant49, 0.1, 1e-05);  dequantize_per_tensor_default_73 = _param_constant72 = _param_constant73 = _tensor_constant48 = _tensor_constant49 = None\n",
      "    getitem_72 = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
      "    relu__24 = torch.ops.aten.relu_.default(getitem_72);  getitem_72 = None\n",
      "    quantize_per_tensor_default_74 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__24, 0.025128398090600967, -128, -128, 127, torch.int8);  relu__24 = None\n",
      "    dequantize_per_tensor_default_74 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_74, 0.025128398090600967, -128, -128, 127, torch.int8);  quantize_per_tensor_default_74 = None\n",
      "    _frozen_param24 = self._frozen_param24\n",
      "    dequantize_per_tensor_default_75 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param24, 0.007715207524597645, 0, -127, 127, torch.int8);  _frozen_param24 = None\n",
      "    features_denseblock2_denselayer6_layers_conv1_weight_bias = self.features_denseblock2_denselayer6_layers_conv1_weight_bias\n",
      "    conv2d_24 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_74, dequantize_per_tensor_default_75, features_denseblock2_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_default_74 = dequantize_per_tensor_default_75 = features_denseblock2_denselayer6_layers_conv1_weight_bias = None\n",
      "    relu__25 = torch.ops.aten.relu_.default(conv2d_24);  conv2d_24 = None\n",
      "    quantize_per_tensor_default_76 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__25, 0.01569560542702675, -128, -128, 127, torch.int8);  relu__25 = None\n",
      "    dequantize_per_tensor_default_76 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_76, 0.01569560542702675, -128, -128, 127, torch.int8);  quantize_per_tensor_default_76 = None\n",
      "    _frozen_param25 = self._frozen_param25\n",
      "    dequantize_per_tensor_default_77 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param25, 0.003498468780890107, 0, -127, 127, torch.int8);  _frozen_param25 = None\n",
      "    conv2d_25 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_76, dequantize_per_tensor_default_77, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_76 = dequantize_per_tensor_default_77 = None\n",
      "    quantize_per_tensor_default_78 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_25, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_25 = None\n",
      "    dequantize_per_tensor_default_78 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_78, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_78 = None\n",
      "    cat_11 = torch.ops.aten.cat.default([dequantize_per_tensor_default_379, dequantize_per_tensor_default_78], 1);  dequantize_per_tensor_default_379 = dequantize_per_tensor_default_78 = None\n",
      "    quantize_per_tensor_default_79 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_11, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_11 = None\n",
      "    dequantize_per_tensor_default_79 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_380 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_79 = None\n",
      "    _param_constant78 = self.features_denseblock2_denselayer7_layers_norm1_weight\n",
      "    _param_constant79 = self.features_denseblock2_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant52 = self.features_denseblock2_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant53 = self.features_denseblock2_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_79, _param_constant78, _param_constant79, _tensor_constant52, _tensor_constant53, 0.1, 1e-05);  dequantize_per_tensor_default_79 = _param_constant78 = _param_constant79 = _tensor_constant52 = _tensor_constant53 = None\n",
      "    getitem_78 = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
      "    relu__26 = torch.ops.aten.relu_.default(getitem_78);  getitem_78 = None\n",
      "    quantize_per_tensor_default_80 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__26, 0.021912051364779472, -128, -128, 127, torch.int8);  relu__26 = None\n",
      "    dequantize_per_tensor_default_80 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_80, 0.021912051364779472, -128, -128, 127, torch.int8);  quantize_per_tensor_default_80 = None\n",
      "    _frozen_param26 = self._frozen_param26\n",
      "    dequantize_per_tensor_default_81 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param26, 0.008215930312871933, 0, -127, 127, torch.int8);  _frozen_param26 = None\n",
      "    features_denseblock2_denselayer7_layers_conv1_weight_bias = self.features_denseblock2_denselayer7_layers_conv1_weight_bias\n",
      "    conv2d_26 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_80, dequantize_per_tensor_default_81, features_denseblock2_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_default_80 = dequantize_per_tensor_default_81 = features_denseblock2_denselayer7_layers_conv1_weight_bias = None\n",
      "    relu__27 = torch.ops.aten.relu_.default(conv2d_26);  conv2d_26 = None\n",
      "    quantize_per_tensor_default_82 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__27, 0.016761358827352524, -128, -128, 127, torch.int8);  relu__27 = None\n",
      "    dequantize_per_tensor_default_82 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_82, 0.016761358827352524, -128, -128, 127, torch.int8);  quantize_per_tensor_default_82 = None\n",
      "    _frozen_param27 = self._frozen_param27\n",
      "    dequantize_per_tensor_default_83 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param27, 0.0024026758037507534, 0, -127, 127, torch.int8);  _frozen_param27 = None\n",
      "    conv2d_27 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_82, dequantize_per_tensor_default_83, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_82 = dequantize_per_tensor_default_83 = None\n",
      "    quantize_per_tensor_default_84 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_27, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_27 = None\n",
      "    dequantize_per_tensor_default_84 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_84, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_84 = None\n",
      "    cat_12 = torch.ops.aten.cat.default([dequantize_per_tensor_default_380, dequantize_per_tensor_default_84], 1);  dequantize_per_tensor_default_380 = dequantize_per_tensor_default_84 = None\n",
      "    quantize_per_tensor_default_85 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_12, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_12 = None\n",
      "    dequantize_per_tensor_default_85 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_381 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_85 = None\n",
      "    _param_constant84 = self.features_denseblock2_denselayer8_layers_norm1_weight\n",
      "    _param_constant85 = self.features_denseblock2_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant56 = self.features_denseblock2_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant57 = self.features_denseblock2_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_85, _param_constant84, _param_constant85, _tensor_constant56, _tensor_constant57, 0.1, 1e-05);  dequantize_per_tensor_default_85 = _param_constant84 = _param_constant85 = _tensor_constant56 = _tensor_constant57 = None\n",
      "    getitem_84 = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
      "    relu__28 = torch.ops.aten.relu_.default(getitem_84);  getitem_84 = None\n",
      "    quantize_per_tensor_default_86 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__28, 0.026374759152531624, -128, -128, 127, torch.int8);  relu__28 = None\n",
      "    dequantize_per_tensor_default_86 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_86, 0.026374759152531624, -128, -128, 127, torch.int8);  quantize_per_tensor_default_86 = None\n",
      "    _frozen_param28 = self._frozen_param28\n",
      "    dequantize_per_tensor_default_87 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param28, 0.007590748369693756, 0, -127, 127, torch.int8);  _frozen_param28 = None\n",
      "    features_denseblock2_denselayer8_layers_conv1_weight_bias = self.features_denseblock2_denselayer8_layers_conv1_weight_bias\n",
      "    conv2d_28 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_86, dequantize_per_tensor_default_87, features_denseblock2_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_default_86 = dequantize_per_tensor_default_87 = features_denseblock2_denselayer8_layers_conv1_weight_bias = None\n",
      "    relu__29 = torch.ops.aten.relu_.default(conv2d_28);  conv2d_28 = None\n",
      "    quantize_per_tensor_default_88 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__29, 0.01001269556581974, -128, -128, 127, torch.int8);  relu__29 = None\n",
      "    dequantize_per_tensor_default_88 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_88, 0.01001269556581974, -128, -128, 127, torch.int8);  quantize_per_tensor_default_88 = None\n",
      "    _frozen_param29 = self._frozen_param29\n",
      "    dequantize_per_tensor_default_89 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param29, 0.0018703668611124158, 0, -127, 127, torch.int8);  _frozen_param29 = None\n",
      "    conv2d_29 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_88, dequantize_per_tensor_default_89, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_88 = dequantize_per_tensor_default_89 = None\n",
      "    quantize_per_tensor_default_90 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_29, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_29 = None\n",
      "    dequantize_per_tensor_default_90 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_90, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_90 = None\n",
      "    cat_13 = torch.ops.aten.cat.default([dequantize_per_tensor_default_381, dequantize_per_tensor_default_90], 1);  dequantize_per_tensor_default_381 = dequantize_per_tensor_default_90 = None\n",
      "    quantize_per_tensor_default_91 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_13, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_13 = None\n",
      "    dequantize_per_tensor_default_91 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_382 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_91 = None\n",
      "    _param_constant90 = self.features_denseblock2_denselayer9_layers_norm1_weight\n",
      "    _param_constant91 = self.features_denseblock2_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant60 = self.features_denseblock2_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant61 = self.features_denseblock2_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_91, _param_constant90, _param_constant91, _tensor_constant60, _tensor_constant61, 0.1, 1e-05);  dequantize_per_tensor_default_91 = _param_constant90 = _param_constant91 = _tensor_constant60 = _tensor_constant61 = None\n",
      "    getitem_90 = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
      "    relu__30 = torch.ops.aten.relu_.default(getitem_90);  getitem_90 = None\n",
      "    quantize_per_tensor_default_92 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__30, 0.026048051193356514, -128, -128, 127, torch.int8);  relu__30 = None\n",
      "    dequantize_per_tensor_default_92 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_92, 0.026048051193356514, -128, -128, 127, torch.int8);  quantize_per_tensor_default_92 = None\n",
      "    _frozen_param30 = self._frozen_param30\n",
      "    dequantize_per_tensor_default_93 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param30, 0.010624253191053867, 0, -127, 127, torch.int8);  _frozen_param30 = None\n",
      "    features_denseblock2_denselayer9_layers_conv1_weight_bias = self.features_denseblock2_denselayer9_layers_conv1_weight_bias\n",
      "    conv2d_30 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_92, dequantize_per_tensor_default_93, features_denseblock2_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_default_92 = dequantize_per_tensor_default_93 = features_denseblock2_denselayer9_layers_conv1_weight_bias = None\n",
      "    relu__31 = torch.ops.aten.relu_.default(conv2d_30);  conv2d_30 = None\n",
      "    quantize_per_tensor_default_94 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__31, 0.014488347806036472, -128, -128, 127, torch.int8);  relu__31 = None\n",
      "    dequantize_per_tensor_default_94 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_94, 0.014488347806036472, -128, -128, 127, torch.int8);  quantize_per_tensor_default_94 = None\n",
      "    _frozen_param31 = self._frozen_param31\n",
      "    dequantize_per_tensor_default_95 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param31, 0.0022182774264365435, 0, -127, 127, torch.int8);  _frozen_param31 = None\n",
      "    conv2d_31 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_94, dequantize_per_tensor_default_95, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_94 = dequantize_per_tensor_default_95 = None\n",
      "    quantize_per_tensor_default_96 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_31, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_31 = None\n",
      "    dequantize_per_tensor_default_96 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_96, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_96 = None\n",
      "    cat_14 = torch.ops.aten.cat.default([dequantize_per_tensor_default_382, dequantize_per_tensor_default_96], 1);  dequantize_per_tensor_default_382 = dequantize_per_tensor_default_96 = None\n",
      "    quantize_per_tensor_default_97 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_14, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_14 = None\n",
      "    dequantize_per_tensor_default_97 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_383 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_97 = None\n",
      "    _param_constant96 = self.features_denseblock2_denselayer10_layers_norm1_weight\n",
      "    _param_constant97 = self.features_denseblock2_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant64 = self.features_denseblock2_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant65 = self.features_denseblock2_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_97, _param_constant96, _param_constant97, _tensor_constant64, _tensor_constant65, 0.1, 1e-05);  dequantize_per_tensor_default_97 = _param_constant96 = _param_constant97 = _tensor_constant64 = _tensor_constant65 = None\n",
      "    getitem_96 = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
      "    relu__32 = torch.ops.aten.relu_.default(getitem_96);  getitem_96 = None\n",
      "    quantize_per_tensor_default_98 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__32, 0.03876306489109993, -128, -128, 127, torch.int8);  relu__32 = None\n",
      "    dequantize_per_tensor_default_98 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_98, 0.03876306489109993, -128, -128, 127, torch.int8);  quantize_per_tensor_default_98 = None\n",
      "    _frozen_param32 = self._frozen_param32\n",
      "    dequantize_per_tensor_default_99 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param32, 0.012093828991055489, 0, -127, 127, torch.int8);  _frozen_param32 = None\n",
      "    features_denseblock2_denselayer10_layers_conv1_weight_bias = self.features_denseblock2_denselayer10_layers_conv1_weight_bias\n",
      "    conv2d_32 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_98, dequantize_per_tensor_default_99, features_denseblock2_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_default_98 = dequantize_per_tensor_default_99 = features_denseblock2_denselayer10_layers_conv1_weight_bias = None\n",
      "    relu__33 = torch.ops.aten.relu_.default(conv2d_32);  conv2d_32 = None\n",
      "    quantize_per_tensor_default_100 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__33, 0.02278151921927929, -128, -128, 127, torch.int8);  relu__33 = None\n",
      "    dequantize_per_tensor_default_100 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_100, 0.02278151921927929, -128, -128, 127, torch.int8);  quantize_per_tensor_default_100 = None\n",
      "    _frozen_param33 = self._frozen_param33\n",
      "    dequantize_per_tensor_default_101 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param33, 0.0017407116247341037, 0, -127, 127, torch.int8);  _frozen_param33 = None\n",
      "    conv2d_33 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_100, dequantize_per_tensor_default_101, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_100 = dequantize_per_tensor_default_101 = None\n",
      "    quantize_per_tensor_default_102 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_33, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_33 = None\n",
      "    dequantize_per_tensor_default_102 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_102, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_102 = None\n",
      "    cat_15 = torch.ops.aten.cat.default([dequantize_per_tensor_default_383, dequantize_per_tensor_default_102], 1);  dequantize_per_tensor_default_383 = dequantize_per_tensor_default_102 = None\n",
      "    quantize_per_tensor_default_103 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_15, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_15 = None\n",
      "    dequantize_per_tensor_default_103 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_384 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_103 = None\n",
      "    _param_constant102 = self.features_denseblock2_denselayer11_layers_norm1_weight\n",
      "    _param_constant103 = self.features_denseblock2_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant68 = self.features_denseblock2_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant69 = self.features_denseblock2_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_103, _param_constant102, _param_constant103, _tensor_constant68, _tensor_constant69, 0.1, 1e-05);  dequantize_per_tensor_default_103 = _param_constant102 = _param_constant103 = _tensor_constant68 = _tensor_constant69 = None\n",
      "    getitem_102 = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
      "    relu__34 = torch.ops.aten.relu_.default(getitem_102);  getitem_102 = None\n",
      "    quantize_per_tensor_default_104 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__34, 0.037703581154346466, -128, -128, 127, torch.int8);  relu__34 = None\n",
      "    dequantize_per_tensor_default_104 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_104, 0.037703581154346466, -128, -128, 127, torch.int8);  quantize_per_tensor_default_104 = None\n",
      "    _frozen_param34 = self._frozen_param34\n",
      "    dequantize_per_tensor_default_105 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param34, 0.009763662703335285, 0, -127, 127, torch.int8);  _frozen_param34 = None\n",
      "    features_denseblock2_denselayer11_layers_conv1_weight_bias = self.features_denseblock2_denselayer11_layers_conv1_weight_bias\n",
      "    conv2d_34 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_104, dequantize_per_tensor_default_105, features_denseblock2_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_default_104 = dequantize_per_tensor_default_105 = features_denseblock2_denselayer11_layers_conv1_weight_bias = None\n",
      "    relu__35 = torch.ops.aten.relu_.default(conv2d_34);  conv2d_34 = None\n",
      "    quantize_per_tensor_default_106 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__35, 0.019625337794423103, -128, -128, 127, torch.int8);  relu__35 = None\n",
      "    dequantize_per_tensor_default_106 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_106, 0.019625337794423103, -128, -128, 127, torch.int8);  quantize_per_tensor_default_106 = None\n",
      "    _frozen_param35 = self._frozen_param35\n",
      "    dequantize_per_tensor_default_107 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param35, 0.0017583960434421897, 0, -127, 127, torch.int8);  _frozen_param35 = None\n",
      "    conv2d_35 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_106, dequantize_per_tensor_default_107, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_106 = dequantize_per_tensor_default_107 = None\n",
      "    quantize_per_tensor_default_108 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_35, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_35 = None\n",
      "    dequantize_per_tensor_default_108 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_108, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_108 = None\n",
      "    cat_16 = torch.ops.aten.cat.default([dequantize_per_tensor_default_384, dequantize_per_tensor_default_108], 1);  dequantize_per_tensor_default_384 = dequantize_per_tensor_default_108 = None\n",
      "    quantize_per_tensor_default_109 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_16, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_16 = None\n",
      "    dequantize_per_tensor_default_109 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_109, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_385 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_109, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_109 = None\n",
      "    _param_constant108 = self.features_denseblock2_denselayer12_layers_norm1_weight\n",
      "    _param_constant109 = self.features_denseblock2_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant72 = self.features_denseblock2_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant73 = self.features_denseblock2_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_109, _param_constant108, _param_constant109, _tensor_constant72, _tensor_constant73, 0.1, 1e-05);  dequantize_per_tensor_default_109 = _param_constant108 = _param_constant109 = _tensor_constant72 = _tensor_constant73 = None\n",
      "    getitem_108 = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
      "    relu__36 = torch.ops.aten.relu_.default(getitem_108);  getitem_108 = None\n",
      "    quantize_per_tensor_default_110 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__36, 0.04547126591205597, -128, -128, 127, torch.int8);  relu__36 = None\n",
      "    dequantize_per_tensor_default_110 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_110, 0.04547126591205597, -128, -128, 127, torch.int8);  quantize_per_tensor_default_110 = None\n",
      "    _frozen_param36 = self._frozen_param36\n",
      "    dequantize_per_tensor_default_111 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param36, 0.009439360350370407, 0, -127, 127, torch.int8);  _frozen_param36 = None\n",
      "    features_denseblock2_denselayer12_layers_conv1_weight_bias = self.features_denseblock2_denselayer12_layers_conv1_weight_bias\n",
      "    conv2d_36 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_110, dequantize_per_tensor_default_111, features_denseblock2_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_default_110 = dequantize_per_tensor_default_111 = features_denseblock2_denselayer12_layers_conv1_weight_bias = None\n",
      "    relu__37 = torch.ops.aten.relu_.default(conv2d_36);  conv2d_36 = None\n",
      "    quantize_per_tensor_default_112 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__37, 0.012600935995578766, -128, -128, 127, torch.int8);  relu__37 = None\n",
      "    dequantize_per_tensor_default_112 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_112, 0.012600935995578766, -128, -128, 127, torch.int8);  quantize_per_tensor_default_112 = None\n",
      "    _frozen_param37 = self._frozen_param37\n",
      "    dequantize_per_tensor_default_113 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param37, 0.00235523353330791, 0, -127, 127, torch.int8);  _frozen_param37 = None\n",
      "    conv2d_37 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_112, dequantize_per_tensor_default_113, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_112 = dequantize_per_tensor_default_113 = None\n",
      "    quantize_per_tensor_default_114 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_37, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_37 = None\n",
      "    dequantize_per_tensor_default_114 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_114, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_114 = None\n",
      "    cat_17 = torch.ops.aten.cat.default([dequantize_per_tensor_default_385, dequantize_per_tensor_default_114], 1);  dequantize_per_tensor_default_385 = dequantize_per_tensor_default_114 = None\n",
      "    quantize_per_tensor_default_115 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_17, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_17 = None\n",
      "    dequantize_per_tensor_default_115 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_115, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_115 = None\n",
      "    _param_constant114 = self.features_transition2_norm_weight\n",
      "    _param_constant115 = self.features_transition2_norm_bias\n",
      "    _tensor_constant76 = self.features_transition2_norm_running_mean\n",
      "    _tensor_constant77 = self.features_transition2_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_115, _param_constant114, _param_constant115, _tensor_constant76, _tensor_constant77, 0.1, 1e-05);  dequantize_per_tensor_default_115 = _param_constant114 = _param_constant115 = _tensor_constant76 = _tensor_constant77 = None\n",
      "    getitem_114 = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
      "    relu__38 = torch.ops.aten.relu_.default(getitem_114);  getitem_114 = None\n",
      "    quantize_per_tensor_default_116 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__38, 0.04991768300533295, -128, -128, 127, torch.int8);  relu__38 = None\n",
      "    dequantize_per_tensor_default_116 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_116, 0.04991768300533295, -128, -128, 127, torch.int8);  quantize_per_tensor_default_116 = None\n",
      "    _frozen_param38 = self._frozen_param38\n",
      "    dequantize_per_tensor_default_117 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param38, 0.005248184781521559, 0, -127, 127, torch.int8);  _frozen_param38 = None\n",
      "    conv2d_38 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_116, dequantize_per_tensor_default_117);  dequantize_per_tensor_default_116 = dequantize_per_tensor_default_117 = None\n",
      "    quantize_per_tensor_default_118 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_38, 0.08149266242980957, 8, -128, 127, torch.int8);  conv2d_38 = None\n",
      "    dequantize_per_tensor_default_118 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_118, 0.08149266242980957, 8, -128, 127, torch.int8);  quantize_per_tensor_default_118 = None\n",
      "    avg_pool2d_1 = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_default_118, [2, 2], [2, 2]);  dequantize_per_tensor_default_118 = None\n",
      "    quantize_per_tensor_default_119 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_1, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_119 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_119, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_119 = None\n",
      "    _param_constant117 = self.features_denseblock3_denselayer1_layers_norm1_weight\n",
      "    _param_constant118 = self.features_denseblock3_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant78 = self.features_denseblock3_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant79 = self.features_denseblock3_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_1, _param_constant117, _param_constant118, _tensor_constant78, _tensor_constant79, 0.1, 1e-05);  avg_pool2d_1 = _param_constant117 = _param_constant118 = _tensor_constant78 = _tensor_constant79 = None\n",
      "    getitem_117 = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
      "    relu__39 = torch.ops.aten.relu_.default(getitem_117);  getitem_117 = None\n",
      "    quantize_per_tensor_default_120 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__39, 0.019499758258461952, -128, -128, 127, torch.int8);  relu__39 = None\n",
      "    dequantize_per_tensor_default_120 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_120, 0.019499758258461952, -128, -128, 127, torch.int8);  quantize_per_tensor_default_120 = None\n",
      "    _frozen_param39 = self._frozen_param39\n",
      "    dequantize_per_tensor_default_121 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param39, 0.006735334172844887, 0, -127, 127, torch.int8);  _frozen_param39 = None\n",
      "    features_denseblock3_denselayer1_layers_conv1_weight_bias = self.features_denseblock3_denselayer1_layers_conv1_weight_bias\n",
      "    conv2d_39 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_120, dequantize_per_tensor_default_121, features_denseblock3_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_default_120 = dequantize_per_tensor_default_121 = features_denseblock3_denselayer1_layers_conv1_weight_bias = None\n",
      "    relu__40 = torch.ops.aten.relu_.default(conv2d_39);  conv2d_39 = None\n",
      "    quantize_per_tensor_default_122 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__40, 0.018092796206474304, -128, -128, 127, torch.int8);  relu__40 = None\n",
      "    dequantize_per_tensor_default_122 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_122, 0.018092796206474304, -128, -128, 127, torch.int8);  quantize_per_tensor_default_122 = None\n",
      "    _frozen_param40 = self._frozen_param40\n",
      "    dequantize_per_tensor_default_123 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param40, 0.0019048936665058136, 0, -127, 127, torch.int8);  _frozen_param40 = None\n",
      "    conv2d_40 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_122, dequantize_per_tensor_default_123, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_122 = dequantize_per_tensor_default_123 = None\n",
      "    quantize_per_tensor_default_124 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_40, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_40 = None\n",
      "    dequantize_per_tensor_default_124 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_124, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_124 = None\n",
      "    cat_18 = torch.ops.aten.cat.default([dequantize_per_tensor_default_119, dequantize_per_tensor_default_124], 1);  dequantize_per_tensor_default_119 = dequantize_per_tensor_default_124 = None\n",
      "    quantize_per_tensor_default_125 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_18, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_18 = None\n",
      "    dequantize_per_tensor_default_125 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_386 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_125 = None\n",
      "    _param_constant123 = self.features_denseblock3_denselayer2_layers_norm1_weight\n",
      "    _param_constant124 = self.features_denseblock3_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant82 = self.features_denseblock3_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant83 = self.features_denseblock3_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_125, _param_constant123, _param_constant124, _tensor_constant82, _tensor_constant83, 0.1, 1e-05);  dequantize_per_tensor_default_125 = _param_constant123 = _param_constant124 = _tensor_constant82 = _tensor_constant83 = None\n",
      "    getitem_123 = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
      "    relu__41 = torch.ops.aten.relu_.default(getitem_123);  getitem_123 = None\n",
      "    quantize_per_tensor_default_126 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__41, 0.024419553577899933, -128, -128, 127, torch.int8);  relu__41 = None\n",
      "    dequantize_per_tensor_default_126 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_126, 0.024419553577899933, -128, -128, 127, torch.int8);  quantize_per_tensor_default_126 = None\n",
      "    _frozen_param41 = self._frozen_param41\n",
      "    dequantize_per_tensor_default_127 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param41, 0.007588740438222885, 0, -127, 127, torch.int8);  _frozen_param41 = None\n",
      "    features_denseblock3_denselayer2_layers_conv1_weight_bias = self.features_denseblock3_denselayer2_layers_conv1_weight_bias\n",
      "    conv2d_41 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_126, dequantize_per_tensor_default_127, features_denseblock3_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_default_126 = dequantize_per_tensor_default_127 = features_denseblock3_denselayer2_layers_conv1_weight_bias = None\n",
      "    relu__42 = torch.ops.aten.relu_.default(conv2d_41);  conv2d_41 = None\n",
      "    quantize_per_tensor_default_128 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__42, 0.022614017128944397, -128, -128, 127, torch.int8);  relu__42 = None\n",
      "    dequantize_per_tensor_default_128 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_128, 0.022614017128944397, -128, -128, 127, torch.int8);  quantize_per_tensor_default_128 = None\n",
      "    _frozen_param42 = self._frozen_param42\n",
      "    dequantize_per_tensor_default_129 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param42, 0.0023393514566123486, 0, -127, 127, torch.int8);  _frozen_param42 = None\n",
      "    conv2d_42 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_128, dequantize_per_tensor_default_129, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_128 = dequantize_per_tensor_default_129 = None\n",
      "    quantize_per_tensor_default_130 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_42, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_42 = None\n",
      "    dequantize_per_tensor_default_130 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_130, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_130 = None\n",
      "    cat_19 = torch.ops.aten.cat.default([dequantize_per_tensor_default_386, dequantize_per_tensor_default_130], 1);  dequantize_per_tensor_default_386 = dequantize_per_tensor_default_130 = None\n",
      "    quantize_per_tensor_default_131 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_19, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_19 = None\n",
      "    dequantize_per_tensor_default_131 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_387 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_131 = None\n",
      "    _param_constant129 = self.features_denseblock3_denselayer3_layers_norm1_weight\n",
      "    _param_constant130 = self.features_denseblock3_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant86 = self.features_denseblock3_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant87 = self.features_denseblock3_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_131, _param_constant129, _param_constant130, _tensor_constant86, _tensor_constant87, 0.1, 1e-05);  dequantize_per_tensor_default_131 = _param_constant129 = _param_constant130 = _tensor_constant86 = _tensor_constant87 = None\n",
      "    getitem_129 = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
      "    relu__43 = torch.ops.aten.relu_.default(getitem_129);  getitem_129 = None\n",
      "    quantize_per_tensor_default_132 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__43, 0.023411856964230537, -128, -128, 127, torch.int8);  relu__43 = None\n",
      "    dequantize_per_tensor_default_132 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_132, 0.023411856964230537, -128, -128, 127, torch.int8);  quantize_per_tensor_default_132 = None\n",
      "    _frozen_param43 = self._frozen_param43\n",
      "    dequantize_per_tensor_default_133 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param43, 0.008429267443716526, 0, -127, 127, torch.int8);  _frozen_param43 = None\n",
      "    features_denseblock3_denselayer3_layers_conv1_weight_bias = self.features_denseblock3_denselayer3_layers_conv1_weight_bias\n",
      "    conv2d_43 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_132, dequantize_per_tensor_default_133, features_denseblock3_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_default_132 = dequantize_per_tensor_default_133 = features_denseblock3_denselayer3_layers_conv1_weight_bias = None\n",
      "    relu__44 = torch.ops.aten.relu_.default(conv2d_43);  conv2d_43 = None\n",
      "    quantize_per_tensor_default_134 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__44, 0.01815163902938366, -128, -128, 127, torch.int8);  relu__44 = None\n",
      "    dequantize_per_tensor_default_134 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_134, 0.01815163902938366, -128, -128, 127, torch.int8);  quantize_per_tensor_default_134 = None\n",
      "    _frozen_param44 = self._frozen_param44\n",
      "    dequantize_per_tensor_default_135 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param44, 0.0022762438748031855, 0, -127, 127, torch.int8);  _frozen_param44 = None\n",
      "    conv2d_44 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_134, dequantize_per_tensor_default_135, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_134 = dequantize_per_tensor_default_135 = None\n",
      "    quantize_per_tensor_default_136 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_44, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_44 = None\n",
      "    dequantize_per_tensor_default_136 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_136, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_136 = None\n",
      "    cat_20 = torch.ops.aten.cat.default([dequantize_per_tensor_default_387, dequantize_per_tensor_default_136], 1);  dequantize_per_tensor_default_387 = dequantize_per_tensor_default_136 = None\n",
      "    quantize_per_tensor_default_137 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_20, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_20 = None\n",
      "    dequantize_per_tensor_default_137 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_388 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_137 = None\n",
      "    _param_constant135 = self.features_denseblock3_denselayer4_layers_norm1_weight\n",
      "    _param_constant136 = self.features_denseblock3_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant90 = self.features_denseblock3_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant91 = self.features_denseblock3_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_137, _param_constant135, _param_constant136, _tensor_constant90, _tensor_constant91, 0.1, 1e-05);  dequantize_per_tensor_default_137 = _param_constant135 = _param_constant136 = _tensor_constant90 = _tensor_constant91 = None\n",
      "    getitem_135 = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
      "    relu__45 = torch.ops.aten.relu_.default(getitem_135);  getitem_135 = None\n",
      "    quantize_per_tensor_default_138 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__45, 0.013636472634971142, -128, -128, 127, torch.int8);  relu__45 = None\n",
      "    dequantize_per_tensor_default_138 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_138, 0.013636472634971142, -128, -128, 127, torch.int8);  quantize_per_tensor_default_138 = None\n",
      "    _frozen_param45 = self._frozen_param45\n",
      "    dequantize_per_tensor_default_139 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param45, 0.008664802648127079, 0, -127, 127, torch.int8);  _frozen_param45 = None\n",
      "    features_denseblock3_denselayer4_layers_conv1_weight_bias = self.features_denseblock3_denselayer4_layers_conv1_weight_bias\n",
      "    conv2d_45 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_138, dequantize_per_tensor_default_139, features_denseblock3_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_default_138 = dequantize_per_tensor_default_139 = features_denseblock3_denselayer4_layers_conv1_weight_bias = None\n",
      "    relu__46 = torch.ops.aten.relu_.default(conv2d_45);  conv2d_45 = None\n",
      "    quantize_per_tensor_default_140 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__46, 0.0397607758641243, -128, -128, 127, torch.int8);  relu__46 = None\n",
      "    dequantize_per_tensor_default_140 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_140, 0.0397607758641243, -128, -128, 127, torch.int8);  quantize_per_tensor_default_140 = None\n",
      "    _frozen_param46 = self._frozen_param46\n",
      "    dequantize_per_tensor_default_141 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param46, 0.0032824354711920023, 0, -127, 127, torch.int8);  _frozen_param46 = None\n",
      "    conv2d_46 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_140, dequantize_per_tensor_default_141, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_140 = dequantize_per_tensor_default_141 = None\n",
      "    quantize_per_tensor_default_142 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_46, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_46 = None\n",
      "    dequantize_per_tensor_default_142 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_142, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_142 = None\n",
      "    cat_21 = torch.ops.aten.cat.default([dequantize_per_tensor_default_388, dequantize_per_tensor_default_142], 1);  dequantize_per_tensor_default_388 = dequantize_per_tensor_default_142 = None\n",
      "    quantize_per_tensor_default_143 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_21, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_21 = None\n",
      "    dequantize_per_tensor_default_143 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_389 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_143 = None\n",
      "    _param_constant141 = self.features_denseblock3_denselayer5_layers_norm1_weight\n",
      "    _param_constant142 = self.features_denseblock3_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant94 = self.features_denseblock3_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant95 = self.features_denseblock3_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_143, _param_constant141, _param_constant142, _tensor_constant94, _tensor_constant95, 0.1, 1e-05);  dequantize_per_tensor_default_143 = _param_constant141 = _param_constant142 = _tensor_constant94 = _tensor_constant95 = None\n",
      "    getitem_141 = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
      "    relu__47 = torch.ops.aten.relu_.default(getitem_141);  getitem_141 = None\n",
      "    quantize_per_tensor_default_144 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__47, 0.020244944840669632, -128, -128, 127, torch.int8);  relu__47 = None\n",
      "    dequantize_per_tensor_default_144 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_144, 0.020244944840669632, -128, -128, 127, torch.int8);  quantize_per_tensor_default_144 = None\n",
      "    _frozen_param47 = self._frozen_param47\n",
      "    dequantize_per_tensor_default_145 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param47, 0.011617506854236126, 0, -127, 127, torch.int8);  _frozen_param47 = None\n",
      "    features_denseblock3_denselayer5_layers_conv1_weight_bias = self.features_denseblock3_denselayer5_layers_conv1_weight_bias\n",
      "    conv2d_47 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_144, dequantize_per_tensor_default_145, features_denseblock3_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_default_144 = dequantize_per_tensor_default_145 = features_denseblock3_denselayer5_layers_conv1_weight_bias = None\n",
      "    relu__48 = torch.ops.aten.relu_.default(conv2d_47);  conv2d_47 = None\n",
      "    quantize_per_tensor_default_146 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__48, 0.04136771708726883, -128, -128, 127, torch.int8);  relu__48 = None\n",
      "    dequantize_per_tensor_default_146 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_146, 0.04136771708726883, -128, -128, 127, torch.int8);  quantize_per_tensor_default_146 = None\n",
      "    _frozen_param48 = self._frozen_param48\n",
      "    dequantize_per_tensor_default_147 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param48, 0.002854603109881282, 0, -127, 127, torch.int8);  _frozen_param48 = None\n",
      "    conv2d_48 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_146, dequantize_per_tensor_default_147, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_146 = dequantize_per_tensor_default_147 = None\n",
      "    quantize_per_tensor_default_148 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_48, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_48 = None\n",
      "    dequantize_per_tensor_default_148 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_148, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_148 = None\n",
      "    cat_22 = torch.ops.aten.cat.default([dequantize_per_tensor_default_389, dequantize_per_tensor_default_148], 1);  dequantize_per_tensor_default_389 = dequantize_per_tensor_default_148 = None\n",
      "    quantize_per_tensor_default_149 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_22, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_22 = None\n",
      "    dequantize_per_tensor_default_149 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_390 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_149 = None\n",
      "    _param_constant147 = self.features_denseblock3_denselayer6_layers_norm1_weight\n",
      "    _param_constant148 = self.features_denseblock3_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant98 = self.features_denseblock3_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant99 = self.features_denseblock3_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_149, _param_constant147, _param_constant148, _tensor_constant98, _tensor_constant99, 0.1, 1e-05);  dequantize_per_tensor_default_149 = _param_constant147 = _param_constant148 = _tensor_constant98 = _tensor_constant99 = None\n",
      "    getitem_147 = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
      "    relu__49 = torch.ops.aten.relu_.default(getitem_147);  getitem_147 = None\n",
      "    quantize_per_tensor_default_150 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__49, 0.015321011655032635, -128, -128, 127, torch.int8);  relu__49 = None\n",
      "    dequantize_per_tensor_default_150 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_150, 0.015321011655032635, -128, -128, 127, torch.int8);  quantize_per_tensor_default_150 = None\n",
      "    _frozen_param49 = self._frozen_param49\n",
      "    dequantize_per_tensor_default_151 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param49, 0.007336599286645651, 0, -127, 127, torch.int8);  _frozen_param49 = None\n",
      "    features_denseblock3_denselayer6_layers_conv1_weight_bias = self.features_denseblock3_denselayer6_layers_conv1_weight_bias\n",
      "    conv2d_49 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_150, dequantize_per_tensor_default_151, features_denseblock3_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_default_150 = dequantize_per_tensor_default_151 = features_denseblock3_denselayer6_layers_conv1_weight_bias = None\n",
      "    relu__50 = torch.ops.aten.relu_.default(conv2d_49);  conv2d_49 = None\n",
      "    quantize_per_tensor_default_152 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__50, 0.019793372601270676, -128, -128, 127, torch.int8);  relu__50 = None\n",
      "    dequantize_per_tensor_default_152 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_152, 0.019793372601270676, -128, -128, 127, torch.int8);  quantize_per_tensor_default_152 = None\n",
      "    _frozen_param50 = self._frozen_param50\n",
      "    dequantize_per_tensor_default_153 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param50, 0.0018314721528440714, 0, -127, 127, torch.int8);  _frozen_param50 = None\n",
      "    conv2d_50 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_152, dequantize_per_tensor_default_153, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_152 = dequantize_per_tensor_default_153 = None\n",
      "    quantize_per_tensor_default_154 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_50, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_50 = None\n",
      "    dequantize_per_tensor_default_154 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_154, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_154 = None\n",
      "    cat_23 = torch.ops.aten.cat.default([dequantize_per_tensor_default_390, dequantize_per_tensor_default_154], 1);  dequantize_per_tensor_default_390 = dequantize_per_tensor_default_154 = None\n",
      "    quantize_per_tensor_default_155 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_23, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_23 = None\n",
      "    dequantize_per_tensor_default_155 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_155, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_391 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_155, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_155 = None\n",
      "    _param_constant153 = self.features_denseblock3_denselayer7_layers_norm1_weight\n",
      "    _param_constant154 = self.features_denseblock3_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant102 = self.features_denseblock3_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant103 = self.features_denseblock3_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_155, _param_constant153, _param_constant154, _tensor_constant102, _tensor_constant103, 0.1, 1e-05);  dequantize_per_tensor_default_155 = _param_constant153 = _param_constant154 = _tensor_constant102 = _tensor_constant103 = None\n",
      "    getitem_153 = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
      "    relu__51 = torch.ops.aten.relu_.default(getitem_153);  getitem_153 = None\n",
      "    quantize_per_tensor_default_156 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__51, 0.013829131610691547, -128, -128, 127, torch.int8);  relu__51 = None\n",
      "    dequantize_per_tensor_default_156 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_156, 0.013829131610691547, -128, -128, 127, torch.int8);  quantize_per_tensor_default_156 = None\n",
      "    _frozen_param51 = self._frozen_param51\n",
      "    dequantize_per_tensor_default_157 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param51, 0.008493652567267418, 0, -127, 127, torch.int8);  _frozen_param51 = None\n",
      "    features_denseblock3_denselayer7_layers_conv1_weight_bias = self.features_denseblock3_denselayer7_layers_conv1_weight_bias\n",
      "    conv2d_51 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_156, dequantize_per_tensor_default_157, features_denseblock3_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_default_156 = dequantize_per_tensor_default_157 = features_denseblock3_denselayer7_layers_conv1_weight_bias = None\n",
      "    relu__52 = torch.ops.aten.relu_.default(conv2d_51);  conv2d_51 = None\n",
      "    quantize_per_tensor_default_158 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__52, 0.015886062756180763, -128, -128, 127, torch.int8);  relu__52 = None\n",
      "    dequantize_per_tensor_default_158 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_158, 0.015886062756180763, -128, -128, 127, torch.int8);  quantize_per_tensor_default_158 = None\n",
      "    _frozen_param52 = self._frozen_param52\n",
      "    dequantize_per_tensor_default_159 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param52, 0.0016737671103328466, 0, -127, 127, torch.int8);  _frozen_param52 = None\n",
      "    conv2d_52 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_158, dequantize_per_tensor_default_159, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_158 = dequantize_per_tensor_default_159 = None\n",
      "    quantize_per_tensor_default_160 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_52, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_52 = None\n",
      "    dequantize_per_tensor_default_160 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_160, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_160 = None\n",
      "    cat_24 = torch.ops.aten.cat.default([dequantize_per_tensor_default_391, dequantize_per_tensor_default_160], 1);  dequantize_per_tensor_default_391 = dequantize_per_tensor_default_160 = None\n",
      "    quantize_per_tensor_default_161 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_24, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_24 = None\n",
      "    dequantize_per_tensor_default_161 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_161, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_392 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_161, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_161 = None\n",
      "    _param_constant159 = self.features_denseblock3_denselayer8_layers_norm1_weight\n",
      "    _param_constant160 = self.features_denseblock3_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant106 = self.features_denseblock3_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant107 = self.features_denseblock3_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_53 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_161, _param_constant159, _param_constant160, _tensor_constant106, _tensor_constant107, 0.1, 1e-05);  dequantize_per_tensor_default_161 = _param_constant159 = _param_constant160 = _tensor_constant106 = _tensor_constant107 = None\n",
      "    getitem_159 = _native_batch_norm_legit_no_training_53[0];  _native_batch_norm_legit_no_training_53 = None\n",
      "    relu__53 = torch.ops.aten.relu_.default(getitem_159);  getitem_159 = None\n",
      "    quantize_per_tensor_default_162 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__53, 0.018496839329600334, -128, -128, 127, torch.int8);  relu__53 = None\n",
      "    dequantize_per_tensor_default_162 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_162, 0.018496839329600334, -128, -128, 127, torch.int8);  quantize_per_tensor_default_162 = None\n",
      "    _frozen_param53 = self._frozen_param53\n",
      "    dequantize_per_tensor_default_163 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param53, 0.00611856346949935, 0, -127, 127, torch.int8);  _frozen_param53 = None\n",
      "    features_denseblock3_denselayer8_layers_conv1_weight_bias = self.features_denseblock3_denselayer8_layers_conv1_weight_bias\n",
      "    conv2d_53 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_162, dequantize_per_tensor_default_163, features_denseblock3_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_default_162 = dequantize_per_tensor_default_163 = features_denseblock3_denselayer8_layers_conv1_weight_bias = None\n",
      "    relu__54 = torch.ops.aten.relu_.default(conv2d_53);  conv2d_53 = None\n",
      "    quantize_per_tensor_default_164 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__54, 0.03790067881345749, -128, -128, 127, torch.int8);  relu__54 = None\n",
      "    dequantize_per_tensor_default_164 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_164, 0.03790067881345749, -128, -128, 127, torch.int8);  quantize_per_tensor_default_164 = None\n",
      "    _frozen_param54 = self._frozen_param54\n",
      "    dequantize_per_tensor_default_165 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param54, 0.002246270654723048, 0, -127, 127, torch.int8);  _frozen_param54 = None\n",
      "    conv2d_54 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_164, dequantize_per_tensor_default_165, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_164 = dequantize_per_tensor_default_165 = None\n",
      "    quantize_per_tensor_default_166 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_54, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_54 = None\n",
      "    dequantize_per_tensor_default_166 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_166, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_166 = None\n",
      "    cat_25 = torch.ops.aten.cat.default([dequantize_per_tensor_default_392, dequantize_per_tensor_default_166], 1);  dequantize_per_tensor_default_392 = dequantize_per_tensor_default_166 = None\n",
      "    quantize_per_tensor_default_167 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_25, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_25 = None\n",
      "    dequantize_per_tensor_default_167 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_167, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_393 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_167, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_167 = None\n",
      "    _param_constant165 = self.features_denseblock3_denselayer9_layers_norm1_weight\n",
      "    _param_constant166 = self.features_denseblock3_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant110 = self.features_denseblock3_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant111 = self.features_denseblock3_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_55 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_167, _param_constant165, _param_constant166, _tensor_constant110, _tensor_constant111, 0.1, 1e-05);  dequantize_per_tensor_default_167 = _param_constant165 = _param_constant166 = _tensor_constant110 = _tensor_constant111 = None\n",
      "    getitem_165 = _native_batch_norm_legit_no_training_55[0];  _native_batch_norm_legit_no_training_55 = None\n",
      "    relu__55 = torch.ops.aten.relu_.default(getitem_165);  getitem_165 = None\n",
      "    quantize_per_tensor_default_168 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__55, 0.03274882957339287, -128, -128, 127, torch.int8);  relu__55 = None\n",
      "    dequantize_per_tensor_default_168 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_168, 0.03274882957339287, -128, -128, 127, torch.int8);  quantize_per_tensor_default_168 = None\n",
      "    _frozen_param55 = self._frozen_param55\n",
      "    dequantize_per_tensor_default_169 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param55, 0.00956618133932352, 0, -127, 127, torch.int8);  _frozen_param55 = None\n",
      "    features_denseblock3_denselayer9_layers_conv1_weight_bias = self.features_denseblock3_denselayer9_layers_conv1_weight_bias\n",
      "    conv2d_55 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_168, dequantize_per_tensor_default_169, features_denseblock3_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_default_168 = dequantize_per_tensor_default_169 = features_denseblock3_denselayer9_layers_conv1_weight_bias = None\n",
      "    relu__56 = torch.ops.aten.relu_.default(conv2d_55);  conv2d_55 = None\n",
      "    quantize_per_tensor_default_170 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__56, 0.044811878353357315, -128, -128, 127, torch.int8);  relu__56 = None\n",
      "    dequantize_per_tensor_default_170 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_170, 0.044811878353357315, -128, -128, 127, torch.int8);  quantize_per_tensor_default_170 = None\n",
      "    _frozen_param56 = self._frozen_param56\n",
      "    dequantize_per_tensor_default_171 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param56, 0.003327038837596774, 0, -127, 127, torch.int8);  _frozen_param56 = None\n",
      "    conv2d_56 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_170, dequantize_per_tensor_default_171, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_170 = dequantize_per_tensor_default_171 = None\n",
      "    quantize_per_tensor_default_172 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_56, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_56 = None\n",
      "    dequantize_per_tensor_default_172 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_172, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_172 = None\n",
      "    cat_26 = torch.ops.aten.cat.default([dequantize_per_tensor_default_393, dequantize_per_tensor_default_172], 1);  dequantize_per_tensor_default_393 = dequantize_per_tensor_default_172 = None\n",
      "    quantize_per_tensor_default_173 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_26, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_26 = None\n",
      "    dequantize_per_tensor_default_173 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_173, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_394 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_173, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_173 = None\n",
      "    _param_constant171 = self.features_denseblock3_denselayer10_layers_norm1_weight\n",
      "    _param_constant172 = self.features_denseblock3_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant114 = self.features_denseblock3_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant115 = self.features_denseblock3_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_57 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_173, _param_constant171, _param_constant172, _tensor_constant114, _tensor_constant115, 0.1, 1e-05);  dequantize_per_tensor_default_173 = _param_constant171 = _param_constant172 = _tensor_constant114 = _tensor_constant115 = None\n",
      "    getitem_171 = _native_batch_norm_legit_no_training_57[0];  _native_batch_norm_legit_no_training_57 = None\n",
      "    relu__57 = torch.ops.aten.relu_.default(getitem_171);  getitem_171 = None\n",
      "    quantize_per_tensor_default_174 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__57, 0.022092843428254128, -128, -128, 127, torch.int8);  relu__57 = None\n",
      "    dequantize_per_tensor_default_174 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_174, 0.022092843428254128, -128, -128, 127, torch.int8);  quantize_per_tensor_default_174 = None\n",
      "    _frozen_param57 = self._frozen_param57\n",
      "    dequantize_per_tensor_default_175 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param57, 0.009288808330893517, 0, -127, 127, torch.int8);  _frozen_param57 = None\n",
      "    features_denseblock3_denselayer10_layers_conv1_weight_bias = self.features_denseblock3_denselayer10_layers_conv1_weight_bias\n",
      "    conv2d_57 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_174, dequantize_per_tensor_default_175, features_denseblock3_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_default_174 = dequantize_per_tensor_default_175 = features_denseblock3_denselayer10_layers_conv1_weight_bias = None\n",
      "    relu__58 = torch.ops.aten.relu_.default(conv2d_57);  conv2d_57 = None\n",
      "    quantize_per_tensor_default_176 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__58, 0.03146630525588989, -128, -128, 127, torch.int8);  relu__58 = None\n",
      "    dequantize_per_tensor_default_176 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_176, 0.03146630525588989, -128, -128, 127, torch.int8);  quantize_per_tensor_default_176 = None\n",
      "    _frozen_param58 = self._frozen_param58\n",
      "    dequantize_per_tensor_default_177 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param58, 0.0017977693350985646, 0, -127, 127, torch.int8);  _frozen_param58 = None\n",
      "    conv2d_58 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_176, dequantize_per_tensor_default_177, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_176 = dequantize_per_tensor_default_177 = None\n",
      "    quantize_per_tensor_default_178 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_58, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_58 = None\n",
      "    dequantize_per_tensor_default_178 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_178, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_178 = None\n",
      "    cat_27 = torch.ops.aten.cat.default([dequantize_per_tensor_default_394, dequantize_per_tensor_default_178], 1);  dequantize_per_tensor_default_394 = dequantize_per_tensor_default_178 = None\n",
      "    quantize_per_tensor_default_179 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_27, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_27 = None\n",
      "    dequantize_per_tensor_default_179 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_179, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_395 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_179, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_179 = None\n",
      "    _param_constant177 = self.features_denseblock3_denselayer11_layers_norm1_weight\n",
      "    _param_constant178 = self.features_denseblock3_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant118 = self.features_denseblock3_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant119 = self.features_denseblock3_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_59 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_179, _param_constant177, _param_constant178, _tensor_constant118, _tensor_constant119, 0.1, 1e-05);  dequantize_per_tensor_default_179 = _param_constant177 = _param_constant178 = _tensor_constant118 = _tensor_constant119 = None\n",
      "    getitem_177 = _native_batch_norm_legit_no_training_59[0];  _native_batch_norm_legit_no_training_59 = None\n",
      "    relu__59 = torch.ops.aten.relu_.default(getitem_177);  getitem_177 = None\n",
      "    quantize_per_tensor_default_180 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__59, 0.019942691549658775, -128, -128, 127, torch.int8);  relu__59 = None\n",
      "    dequantize_per_tensor_default_180 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_180, 0.019942691549658775, -128, -128, 127, torch.int8);  quantize_per_tensor_default_180 = None\n",
      "    _frozen_param59 = self._frozen_param59\n",
      "    dequantize_per_tensor_default_181 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param59, 0.007619891781359911, 0, -127, 127, torch.int8);  _frozen_param59 = None\n",
      "    features_denseblock3_denselayer11_layers_conv1_weight_bias = self.features_denseblock3_denselayer11_layers_conv1_weight_bias\n",
      "    conv2d_59 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_180, dequantize_per_tensor_default_181, features_denseblock3_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_default_180 = dequantize_per_tensor_default_181 = features_denseblock3_denselayer11_layers_conv1_weight_bias = None\n",
      "    relu__60 = torch.ops.aten.relu_.default(conv2d_59);  conv2d_59 = None\n",
      "    quantize_per_tensor_default_182 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__60, 0.028196442872285843, -128, -128, 127, torch.int8);  relu__60 = None\n",
      "    dequantize_per_tensor_default_182 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_182, 0.028196442872285843, -128, -128, 127, torch.int8);  quantize_per_tensor_default_182 = None\n",
      "    _frozen_param60 = self._frozen_param60\n",
      "    dequantize_per_tensor_default_183 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param60, 0.001737820217385888, 0, -127, 127, torch.int8);  _frozen_param60 = None\n",
      "    conv2d_60 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_182, dequantize_per_tensor_default_183, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_182 = dequantize_per_tensor_default_183 = None\n",
      "    quantize_per_tensor_default_184 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_60, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_60 = None\n",
      "    dequantize_per_tensor_default_184 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_184, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_184 = None\n",
      "    cat_28 = torch.ops.aten.cat.default([dequantize_per_tensor_default_395, dequantize_per_tensor_default_184], 1);  dequantize_per_tensor_default_395 = dequantize_per_tensor_default_184 = None\n",
      "    quantize_per_tensor_default_185 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_28, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_28 = None\n",
      "    dequantize_per_tensor_default_185 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_185, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_396 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_185, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_185 = None\n",
      "    _param_constant183 = self.features_denseblock3_denselayer12_layers_norm1_weight\n",
      "    _param_constant184 = self.features_denseblock3_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant122 = self.features_denseblock3_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant123 = self.features_denseblock3_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_61 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_185, _param_constant183, _param_constant184, _tensor_constant122, _tensor_constant123, 0.1, 1e-05);  dequantize_per_tensor_default_185 = _param_constant183 = _param_constant184 = _tensor_constant122 = _tensor_constant123 = None\n",
      "    getitem_183 = _native_batch_norm_legit_no_training_61[0];  _native_batch_norm_legit_no_training_61 = None\n",
      "    relu__61 = torch.ops.aten.relu_.default(getitem_183);  getitem_183 = None\n",
      "    quantize_per_tensor_default_186 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__61, 0.026162266731262207, -128, -128, 127, torch.int8);  relu__61 = None\n",
      "    dequantize_per_tensor_default_186 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_186, 0.026162266731262207, -128, -128, 127, torch.int8);  quantize_per_tensor_default_186 = None\n",
      "    _frozen_param61 = self._frozen_param61\n",
      "    dequantize_per_tensor_default_187 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param61, 0.008822259493172169, 0, -127, 127, torch.int8);  _frozen_param61 = None\n",
      "    features_denseblock3_denselayer12_layers_conv1_weight_bias = self.features_denseblock3_denselayer12_layers_conv1_weight_bias\n",
      "    conv2d_61 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_186, dequantize_per_tensor_default_187, features_denseblock3_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_default_186 = dequantize_per_tensor_default_187 = features_denseblock3_denselayer12_layers_conv1_weight_bias = None\n",
      "    relu__62 = torch.ops.aten.relu_.default(conv2d_61);  conv2d_61 = None\n",
      "    quantize_per_tensor_default_188 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__62, 0.023787932470440865, -128, -128, 127, torch.int8);  relu__62 = None\n",
      "    dequantize_per_tensor_default_188 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_188, 0.023787932470440865, -128, -128, 127, torch.int8);  quantize_per_tensor_default_188 = None\n",
      "    _frozen_param62 = self._frozen_param62\n",
      "    dequantize_per_tensor_default_189 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param62, 0.0027496202383190393, 0, -127, 127, torch.int8);  _frozen_param62 = None\n",
      "    conv2d_62 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_188, dequantize_per_tensor_default_189, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_188 = dequantize_per_tensor_default_189 = None\n",
      "    quantize_per_tensor_default_190 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_62, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_62 = None\n",
      "    dequantize_per_tensor_default_190 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_190, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_190 = None\n",
      "    cat_29 = torch.ops.aten.cat.default([dequantize_per_tensor_default_396, dequantize_per_tensor_default_190], 1);  dequantize_per_tensor_default_396 = dequantize_per_tensor_default_190 = None\n",
      "    quantize_per_tensor_default_191 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_29, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_29 = None\n",
      "    dequantize_per_tensor_default_191 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_191, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_397 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_191, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_191 = None\n",
      "    _param_constant189 = self.features_denseblock3_denselayer13_layers_norm1_weight\n",
      "    _param_constant190 = self.features_denseblock3_denselayer13_layers_norm1_bias\n",
      "    _tensor_constant126 = self.features_denseblock3_denselayer13_layers_norm1_running_mean\n",
      "    _tensor_constant127 = self.features_denseblock3_denselayer13_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_63 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_191, _param_constant189, _param_constant190, _tensor_constant126, _tensor_constant127, 0.1, 1e-05);  dequantize_per_tensor_default_191 = _param_constant189 = _param_constant190 = _tensor_constant126 = _tensor_constant127 = None\n",
      "    getitem_189 = _native_batch_norm_legit_no_training_63[0];  _native_batch_norm_legit_no_training_63 = None\n",
      "    relu__63 = torch.ops.aten.relu_.default(getitem_189);  getitem_189 = None\n",
      "    quantize_per_tensor_default_192 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__63, 0.017810774967074394, -128, -128, 127, torch.int8);  relu__63 = None\n",
      "    dequantize_per_tensor_default_192 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_192, 0.017810774967074394, -128, -128, 127, torch.int8);  quantize_per_tensor_default_192 = None\n",
      "    _frozen_param63 = self._frozen_param63\n",
      "    dequantize_per_tensor_default_193 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param63, 0.006329011637717485, 0, -127, 127, torch.int8);  _frozen_param63 = None\n",
      "    features_denseblock3_denselayer13_layers_conv1_weight_bias = self.features_denseblock3_denselayer13_layers_conv1_weight_bias\n",
      "    conv2d_63 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_192, dequantize_per_tensor_default_193, features_denseblock3_denselayer13_layers_conv1_weight_bias);  dequantize_per_tensor_default_192 = dequantize_per_tensor_default_193 = features_denseblock3_denselayer13_layers_conv1_weight_bias = None\n",
      "    relu__64 = torch.ops.aten.relu_.default(conv2d_63);  conv2d_63 = None\n",
      "    quantize_per_tensor_default_194 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__64, 0.015317624434828758, -128, -128, 127, torch.int8);  relu__64 = None\n",
      "    dequantize_per_tensor_default_194 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_194, 0.015317624434828758, -128, -128, 127, torch.int8);  quantize_per_tensor_default_194 = None\n",
      "    _frozen_param64 = self._frozen_param64\n",
      "    dequantize_per_tensor_default_195 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param64, 0.0022162192035466433, 0, -127, 127, torch.int8);  _frozen_param64 = None\n",
      "    conv2d_64 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_194, dequantize_per_tensor_default_195, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_194 = dequantize_per_tensor_default_195 = None\n",
      "    quantize_per_tensor_default_196 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_64, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_64 = None\n",
      "    dequantize_per_tensor_default_196 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_196, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_196 = None\n",
      "    cat_30 = torch.ops.aten.cat.default([dequantize_per_tensor_default_397, dequantize_per_tensor_default_196], 1);  dequantize_per_tensor_default_397 = dequantize_per_tensor_default_196 = None\n",
      "    quantize_per_tensor_default_197 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_30, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_30 = None\n",
      "    dequantize_per_tensor_default_197 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_197, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_398 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_197, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_197 = None\n",
      "    _param_constant195 = self.features_denseblock3_denselayer14_layers_norm1_weight\n",
      "    _param_constant196 = self.features_denseblock3_denselayer14_layers_norm1_bias\n",
      "    _tensor_constant130 = self.features_denseblock3_denselayer14_layers_norm1_running_mean\n",
      "    _tensor_constant131 = self.features_denseblock3_denselayer14_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_65 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_197, _param_constant195, _param_constant196, _tensor_constant130, _tensor_constant131, 0.1, 1e-05);  dequantize_per_tensor_default_197 = _param_constant195 = _param_constant196 = _tensor_constant130 = _tensor_constant131 = None\n",
      "    getitem_195 = _native_batch_norm_legit_no_training_65[0];  _native_batch_norm_legit_no_training_65 = None\n",
      "    relu__65 = torch.ops.aten.relu_.default(getitem_195);  getitem_195 = None\n",
      "    quantize_per_tensor_default_198 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__65, 0.019032306969165802, -128, -128, 127, torch.int8);  relu__65 = None\n",
      "    dequantize_per_tensor_default_198 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_198, 0.019032306969165802, -128, -128, 127, torch.int8);  quantize_per_tensor_default_198 = None\n",
      "    _frozen_param65 = self._frozen_param65\n",
      "    dequantize_per_tensor_default_199 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param65, 0.007711241953074932, 0, -127, 127, torch.int8);  _frozen_param65 = None\n",
      "    features_denseblock3_denselayer14_layers_conv1_weight_bias = self.features_denseblock3_denselayer14_layers_conv1_weight_bias\n",
      "    conv2d_65 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_198, dequantize_per_tensor_default_199, features_denseblock3_denselayer14_layers_conv1_weight_bias);  dequantize_per_tensor_default_198 = dequantize_per_tensor_default_199 = features_denseblock3_denselayer14_layers_conv1_weight_bias = None\n",
      "    relu__66 = torch.ops.aten.relu_.default(conv2d_65);  conv2d_65 = None\n",
      "    quantize_per_tensor_default_200 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__66, 0.015506373718380928, -128, -128, 127, torch.int8);  relu__66 = None\n",
      "    dequantize_per_tensor_default_200 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_200, 0.015506373718380928, -128, -128, 127, torch.int8);  quantize_per_tensor_default_200 = None\n",
      "    _frozen_param66 = self._frozen_param66\n",
      "    dequantize_per_tensor_default_201 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param66, 0.0019943343941122293, 0, -127, 127, torch.int8);  _frozen_param66 = None\n",
      "    conv2d_66 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_200, dequantize_per_tensor_default_201, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_200 = dequantize_per_tensor_default_201 = None\n",
      "    quantize_per_tensor_default_202 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_66, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_66 = None\n",
      "    dequantize_per_tensor_default_202 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_202, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_202 = None\n",
      "    cat_31 = torch.ops.aten.cat.default([dequantize_per_tensor_default_398, dequantize_per_tensor_default_202], 1);  dequantize_per_tensor_default_398 = dequantize_per_tensor_default_202 = None\n",
      "    quantize_per_tensor_default_203 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_31, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_31 = None\n",
      "    dequantize_per_tensor_default_203 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_203, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_399 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_203, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_203 = None\n",
      "    _param_constant201 = self.features_denseblock3_denselayer15_layers_norm1_weight\n",
      "    _param_constant202 = self.features_denseblock3_denselayer15_layers_norm1_bias\n",
      "    _tensor_constant134 = self.features_denseblock3_denselayer15_layers_norm1_running_mean\n",
      "    _tensor_constant135 = self.features_denseblock3_denselayer15_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_67 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_203, _param_constant201, _param_constant202, _tensor_constant134, _tensor_constant135, 0.1, 1e-05);  dequantize_per_tensor_default_203 = _param_constant201 = _param_constant202 = _tensor_constant134 = _tensor_constant135 = None\n",
      "    getitem_201 = _native_batch_norm_legit_no_training_67[0];  _native_batch_norm_legit_no_training_67 = None\n",
      "    relu__67 = torch.ops.aten.relu_.default(getitem_201);  getitem_201 = None\n",
      "    quantize_per_tensor_default_204 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__67, 0.018883991986513138, -128, -128, 127, torch.int8);  relu__67 = None\n",
      "    dequantize_per_tensor_default_204 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_204, 0.018883991986513138, -128, -128, 127, torch.int8);  quantize_per_tensor_default_204 = None\n",
      "    _frozen_param67 = self._frozen_param67\n",
      "    dequantize_per_tensor_default_205 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param67, 0.0059023452922701836, 0, -127, 127, torch.int8);  _frozen_param67 = None\n",
      "    features_denseblock3_denselayer15_layers_conv1_weight_bias = self.features_denseblock3_denselayer15_layers_conv1_weight_bias\n",
      "    conv2d_67 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_204, dequantize_per_tensor_default_205, features_denseblock3_denselayer15_layers_conv1_weight_bias);  dequantize_per_tensor_default_204 = dequantize_per_tensor_default_205 = features_denseblock3_denselayer15_layers_conv1_weight_bias = None\n",
      "    relu__68 = torch.ops.aten.relu_.default(conv2d_67);  conv2d_67 = None\n",
      "    quantize_per_tensor_default_206 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__68, 0.017909351736307144, -128, -128, 127, torch.int8);  relu__68 = None\n",
      "    dequantize_per_tensor_default_206 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_206, 0.017909351736307144, -128, -128, 127, torch.int8);  quantize_per_tensor_default_206 = None\n",
      "    _frozen_param68 = self._frozen_param68\n",
      "    dequantize_per_tensor_default_207 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param68, 0.002152183325961232, 0, -127, 127, torch.int8);  _frozen_param68 = None\n",
      "    conv2d_68 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_206, dequantize_per_tensor_default_207, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_206 = dequantize_per_tensor_default_207 = None\n",
      "    quantize_per_tensor_default_208 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_68, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_68 = None\n",
      "    dequantize_per_tensor_default_208 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_208, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_208 = None\n",
      "    cat_32 = torch.ops.aten.cat.default([dequantize_per_tensor_default_399, dequantize_per_tensor_default_208], 1);  dequantize_per_tensor_default_399 = dequantize_per_tensor_default_208 = None\n",
      "    quantize_per_tensor_default_209 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_32, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_32 = None\n",
      "    dequantize_per_tensor_default_209 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_209, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_400 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_209, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_209 = None\n",
      "    _param_constant207 = self.features_denseblock3_denselayer16_layers_norm1_weight\n",
      "    _param_constant208 = self.features_denseblock3_denselayer16_layers_norm1_bias\n",
      "    _tensor_constant138 = self.features_denseblock3_denselayer16_layers_norm1_running_mean\n",
      "    _tensor_constant139 = self.features_denseblock3_denselayer16_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_69 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_209, _param_constant207, _param_constant208, _tensor_constant138, _tensor_constant139, 0.1, 1e-05);  dequantize_per_tensor_default_209 = _param_constant207 = _param_constant208 = _tensor_constant138 = _tensor_constant139 = None\n",
      "    getitem_207 = _native_batch_norm_legit_no_training_69[0];  _native_batch_norm_legit_no_training_69 = None\n",
      "    relu__69 = torch.ops.aten.relu_.default(getitem_207);  getitem_207 = None\n",
      "    quantize_per_tensor_default_210 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__69, 0.020595984533429146, -128, -128, 127, torch.int8);  relu__69 = None\n",
      "    dequantize_per_tensor_default_210 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_210, 0.020595984533429146, -128, -128, 127, torch.int8);  quantize_per_tensor_default_210 = None\n",
      "    _frozen_param69 = self._frozen_param69\n",
      "    dequantize_per_tensor_default_211 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param69, 0.007651130668818951, 0, -127, 127, torch.int8);  _frozen_param69 = None\n",
      "    features_denseblock3_denselayer16_layers_conv1_weight_bias = self.features_denseblock3_denselayer16_layers_conv1_weight_bias\n",
      "    conv2d_69 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_210, dequantize_per_tensor_default_211, features_denseblock3_denselayer16_layers_conv1_weight_bias);  dequantize_per_tensor_default_210 = dequantize_per_tensor_default_211 = features_denseblock3_denselayer16_layers_conv1_weight_bias = None\n",
      "    relu__70 = torch.ops.aten.relu_.default(conv2d_69);  conv2d_69 = None\n",
      "    quantize_per_tensor_default_212 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__70, 0.017967142164707184, -128, -128, 127, torch.int8);  relu__70 = None\n",
      "    dequantize_per_tensor_default_212 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_212, 0.017967142164707184, -128, -128, 127, torch.int8);  quantize_per_tensor_default_212 = None\n",
      "    _frozen_param70 = self._frozen_param70\n",
      "    dequantize_per_tensor_default_213 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param70, 0.002101373625919223, 0, -127, 127, torch.int8);  _frozen_param70 = None\n",
      "    conv2d_70 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_212, dequantize_per_tensor_default_213, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_212 = dequantize_per_tensor_default_213 = None\n",
      "    quantize_per_tensor_default_214 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_70, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_70 = None\n",
      "    dequantize_per_tensor_default_214 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_214, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_214 = None\n",
      "    cat_33 = torch.ops.aten.cat.default([dequantize_per_tensor_default_400, dequantize_per_tensor_default_214], 1);  dequantize_per_tensor_default_400 = dequantize_per_tensor_default_214 = None\n",
      "    quantize_per_tensor_default_215 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_33, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_33 = None\n",
      "    dequantize_per_tensor_default_215 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_215, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_401 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_215, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_215 = None\n",
      "    _param_constant213 = self.features_denseblock3_denselayer17_layers_norm1_weight\n",
      "    _param_constant214 = self.features_denseblock3_denselayer17_layers_norm1_bias\n",
      "    _tensor_constant142 = self.features_denseblock3_denselayer17_layers_norm1_running_mean\n",
      "    _tensor_constant143 = self.features_denseblock3_denselayer17_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_71 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_215, _param_constant213, _param_constant214, _tensor_constant142, _tensor_constant143, 0.1, 1e-05);  dequantize_per_tensor_default_215 = _param_constant213 = _param_constant214 = _tensor_constant142 = _tensor_constant143 = None\n",
      "    getitem_213 = _native_batch_norm_legit_no_training_71[0];  _native_batch_norm_legit_no_training_71 = None\n",
      "    relu__71 = torch.ops.aten.relu_.default(getitem_213);  getitem_213 = None\n",
      "    quantize_per_tensor_default_216 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__71, 0.01922297291457653, -128, -128, 127, torch.int8);  relu__71 = None\n",
      "    dequantize_per_tensor_default_216 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_216, 0.01922297291457653, -128, -128, 127, torch.int8);  quantize_per_tensor_default_216 = None\n",
      "    _frozen_param71 = self._frozen_param71\n",
      "    dequantize_per_tensor_default_217 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param71, 0.007255369797348976, 0, -127, 127, torch.int8);  _frozen_param71 = None\n",
      "    features_denseblock3_denselayer17_layers_conv1_weight_bias = self.features_denseblock3_denselayer17_layers_conv1_weight_bias\n",
      "    conv2d_71 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_216, dequantize_per_tensor_default_217, features_denseblock3_denselayer17_layers_conv1_weight_bias);  dequantize_per_tensor_default_216 = dequantize_per_tensor_default_217 = features_denseblock3_denselayer17_layers_conv1_weight_bias = None\n",
      "    relu__72 = torch.ops.aten.relu_.default(conv2d_71);  conv2d_71 = None\n",
      "    quantize_per_tensor_default_218 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__72, 0.022512536495923996, -128, -128, 127, torch.int8);  relu__72 = None\n",
      "    dequantize_per_tensor_default_218 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_218, 0.022512536495923996, -128, -128, 127, torch.int8);  quantize_per_tensor_default_218 = None\n",
      "    _frozen_param72 = self._frozen_param72\n",
      "    dequantize_per_tensor_default_219 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param72, 0.0034767789766192436, 0, -127, 127, torch.int8);  _frozen_param72 = None\n",
      "    conv2d_72 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_218, dequantize_per_tensor_default_219, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_218 = dequantize_per_tensor_default_219 = None\n",
      "    quantize_per_tensor_default_220 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_72, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_72 = None\n",
      "    dequantize_per_tensor_default_220 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_220, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_220 = None\n",
      "    cat_34 = torch.ops.aten.cat.default([dequantize_per_tensor_default_401, dequantize_per_tensor_default_220], 1);  dequantize_per_tensor_default_401 = dequantize_per_tensor_default_220 = None\n",
      "    quantize_per_tensor_default_221 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_34, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_34 = None\n",
      "    dequantize_per_tensor_default_221 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_221, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_402 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_221, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_221 = None\n",
      "    _param_constant219 = self.features_denseblock3_denselayer18_layers_norm1_weight\n",
      "    _param_constant220 = self.features_denseblock3_denselayer18_layers_norm1_bias\n",
      "    _tensor_constant146 = self.features_denseblock3_denselayer18_layers_norm1_running_mean\n",
      "    _tensor_constant147 = self.features_denseblock3_denselayer18_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_73 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_221, _param_constant219, _param_constant220, _tensor_constant146, _tensor_constant147, 0.1, 1e-05);  dequantize_per_tensor_default_221 = _param_constant219 = _param_constant220 = _tensor_constant146 = _tensor_constant147 = None\n",
      "    getitem_219 = _native_batch_norm_legit_no_training_73[0];  _native_batch_norm_legit_no_training_73 = None\n",
      "    relu__73 = torch.ops.aten.relu_.default(getitem_219);  getitem_219 = None\n",
      "    quantize_per_tensor_default_222 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__73, 0.016622869297862053, -128, -128, 127, torch.int8);  relu__73 = None\n",
      "    dequantize_per_tensor_default_222 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_222, 0.016622869297862053, -128, -128, 127, torch.int8);  quantize_per_tensor_default_222 = None\n",
      "    _frozen_param73 = self._frozen_param73\n",
      "    dequantize_per_tensor_default_223 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param73, 0.010191931389272213, 0, -127, 127, torch.int8);  _frozen_param73 = None\n",
      "    features_denseblock3_denselayer18_layers_conv1_weight_bias = self.features_denseblock3_denselayer18_layers_conv1_weight_bias\n",
      "    conv2d_73 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_222, dequantize_per_tensor_default_223, features_denseblock3_denselayer18_layers_conv1_weight_bias);  dequantize_per_tensor_default_222 = dequantize_per_tensor_default_223 = features_denseblock3_denselayer18_layers_conv1_weight_bias = None\n",
      "    relu__74 = torch.ops.aten.relu_.default(conv2d_73);  conv2d_73 = None\n",
      "    quantize_per_tensor_default_224 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__74, 0.027026360854506493, -128, -128, 127, torch.int8);  relu__74 = None\n",
      "    dequantize_per_tensor_default_224 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_224, 0.027026360854506493, -128, -128, 127, torch.int8);  quantize_per_tensor_default_224 = None\n",
      "    _frozen_param74 = self._frozen_param74\n",
      "    dequantize_per_tensor_default_225 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param74, 0.002713581779971719, 0, -127, 127, torch.int8);  _frozen_param74 = None\n",
      "    conv2d_74 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_224, dequantize_per_tensor_default_225, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_224 = dequantize_per_tensor_default_225 = None\n",
      "    quantize_per_tensor_default_226 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_74, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_74 = None\n",
      "    dequantize_per_tensor_default_226 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_226, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_226 = None\n",
      "    cat_35 = torch.ops.aten.cat.default([dequantize_per_tensor_default_402, dequantize_per_tensor_default_226], 1);  dequantize_per_tensor_default_402 = dequantize_per_tensor_default_226 = None\n",
      "    quantize_per_tensor_default_227 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_35, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_35 = None\n",
      "    dequantize_per_tensor_default_227 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_227, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_403 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_227, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_227 = None\n",
      "    _param_constant225 = self.features_denseblock3_denselayer19_layers_norm1_weight\n",
      "    _param_constant226 = self.features_denseblock3_denselayer19_layers_norm1_bias\n",
      "    _tensor_constant150 = self.features_denseblock3_denselayer19_layers_norm1_running_mean\n",
      "    _tensor_constant151 = self.features_denseblock3_denselayer19_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_75 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_227, _param_constant225, _param_constant226, _tensor_constant150, _tensor_constant151, 0.1, 1e-05);  dequantize_per_tensor_default_227 = _param_constant225 = _param_constant226 = _tensor_constant150 = _tensor_constant151 = None\n",
      "    getitem_225 = _native_batch_norm_legit_no_training_75[0];  _native_batch_norm_legit_no_training_75 = None\n",
      "    relu__75 = torch.ops.aten.relu_.default(getitem_225);  getitem_225 = None\n",
      "    quantize_per_tensor_default_228 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__75, 0.023014681413769722, -128, -128, 127, torch.int8);  relu__75 = None\n",
      "    dequantize_per_tensor_default_228 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_228, 0.023014681413769722, -128, -128, 127, torch.int8);  quantize_per_tensor_default_228 = None\n",
      "    _frozen_param75 = self._frozen_param75\n",
      "    dequantize_per_tensor_default_229 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param75, 0.007876643911004066, 0, -127, 127, torch.int8);  _frozen_param75 = None\n",
      "    features_denseblock3_denselayer19_layers_conv1_weight_bias = self.features_denseblock3_denselayer19_layers_conv1_weight_bias\n",
      "    conv2d_75 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_228, dequantize_per_tensor_default_229, features_denseblock3_denselayer19_layers_conv1_weight_bias);  dequantize_per_tensor_default_228 = dequantize_per_tensor_default_229 = features_denseblock3_denselayer19_layers_conv1_weight_bias = None\n",
      "    relu__76 = torch.ops.aten.relu_.default(conv2d_75);  conv2d_75 = None\n",
      "    quantize_per_tensor_default_230 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__76, 0.028720280155539513, -128, -128, 127, torch.int8);  relu__76 = None\n",
      "    dequantize_per_tensor_default_230 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_230, 0.028720280155539513, -128, -128, 127, torch.int8);  quantize_per_tensor_default_230 = None\n",
      "    _frozen_param76 = self._frozen_param76\n",
      "    dequantize_per_tensor_default_231 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param76, 0.001983033725991845, 0, -127, 127, torch.int8);  _frozen_param76 = None\n",
      "    conv2d_76 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_230, dequantize_per_tensor_default_231, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_230 = dequantize_per_tensor_default_231 = None\n",
      "    quantize_per_tensor_default_232 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_76, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_76 = None\n",
      "    dequantize_per_tensor_default_232 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_232, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_232 = None\n",
      "    cat_36 = torch.ops.aten.cat.default([dequantize_per_tensor_default_403, dequantize_per_tensor_default_232], 1);  dequantize_per_tensor_default_403 = dequantize_per_tensor_default_232 = None\n",
      "    quantize_per_tensor_default_233 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_36, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_36 = None\n",
      "    dequantize_per_tensor_default_233 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_233, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_404 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_233, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_233 = None\n",
      "    _param_constant231 = self.features_denseblock3_denselayer20_layers_norm1_weight\n",
      "    _param_constant232 = self.features_denseblock3_denselayer20_layers_norm1_bias\n",
      "    _tensor_constant154 = self.features_denseblock3_denselayer20_layers_norm1_running_mean\n",
      "    _tensor_constant155 = self.features_denseblock3_denselayer20_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_77 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_233, _param_constant231, _param_constant232, _tensor_constant154, _tensor_constant155, 0.1, 1e-05);  dequantize_per_tensor_default_233 = _param_constant231 = _param_constant232 = _tensor_constant154 = _tensor_constant155 = None\n",
      "    getitem_231 = _native_batch_norm_legit_no_training_77[0];  _native_batch_norm_legit_no_training_77 = None\n",
      "    relu__77 = torch.ops.aten.relu_.default(getitem_231);  getitem_231 = None\n",
      "    quantize_per_tensor_default_234 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__77, 0.02052520401775837, -128, -128, 127, torch.int8);  relu__77 = None\n",
      "    dequantize_per_tensor_default_234 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_234, 0.02052520401775837, -128, -128, 127, torch.int8);  quantize_per_tensor_default_234 = None\n",
      "    _frozen_param77 = self._frozen_param77\n",
      "    dequantize_per_tensor_default_235 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param77, 0.005435098893940449, 0, -127, 127, torch.int8);  _frozen_param77 = None\n",
      "    features_denseblock3_denselayer20_layers_conv1_weight_bias = self.features_denseblock3_denselayer20_layers_conv1_weight_bias\n",
      "    conv2d_77 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_234, dequantize_per_tensor_default_235, features_denseblock3_denselayer20_layers_conv1_weight_bias);  dequantize_per_tensor_default_234 = dequantize_per_tensor_default_235 = features_denseblock3_denselayer20_layers_conv1_weight_bias = None\n",
      "    relu__78 = torch.ops.aten.relu_.default(conv2d_77);  conv2d_77 = None\n",
      "    quantize_per_tensor_default_236 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__78, 0.0212941225618124, -128, -128, 127, torch.int8);  relu__78 = None\n",
      "    dequantize_per_tensor_default_236 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_236, 0.0212941225618124, -128, -128, 127, torch.int8);  quantize_per_tensor_default_236 = None\n",
      "    _frozen_param78 = self._frozen_param78\n",
      "    dequantize_per_tensor_default_237 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param78, 0.0013692936627194285, 0, -127, 127, torch.int8);  _frozen_param78 = None\n",
      "    conv2d_78 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_236, dequantize_per_tensor_default_237, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_236 = dequantize_per_tensor_default_237 = None\n",
      "    quantize_per_tensor_default_238 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_78, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_78 = None\n",
      "    dequantize_per_tensor_default_238 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_238, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_238 = None\n",
      "    cat_37 = torch.ops.aten.cat.default([dequantize_per_tensor_default_404, dequantize_per_tensor_default_238], 1);  dequantize_per_tensor_default_404 = dequantize_per_tensor_default_238 = None\n",
      "    quantize_per_tensor_default_239 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_37, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_37 = None\n",
      "    dequantize_per_tensor_default_239 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_239, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_405 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_239, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_239 = None\n",
      "    _param_constant237 = self.features_denseblock3_denselayer21_layers_norm1_weight\n",
      "    _param_constant238 = self.features_denseblock3_denselayer21_layers_norm1_bias\n",
      "    _tensor_constant158 = self.features_denseblock3_denselayer21_layers_norm1_running_mean\n",
      "    _tensor_constant159 = self.features_denseblock3_denselayer21_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_79 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_239, _param_constant237, _param_constant238, _tensor_constant158, _tensor_constant159, 0.1, 1e-05);  dequantize_per_tensor_default_239 = _param_constant237 = _param_constant238 = _tensor_constant158 = _tensor_constant159 = None\n",
      "    getitem_237 = _native_batch_norm_legit_no_training_79[0];  _native_batch_norm_legit_no_training_79 = None\n",
      "    relu__79 = torch.ops.aten.relu_.default(getitem_237);  getitem_237 = None\n",
      "    quantize_per_tensor_default_240 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__79, 0.023304402828216553, -128, -128, 127, torch.int8);  relu__79 = None\n",
      "    dequantize_per_tensor_default_240 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_240, 0.023304402828216553, -128, -128, 127, torch.int8);  quantize_per_tensor_default_240 = None\n",
      "    _frozen_param79 = self._frozen_param79\n",
      "    dequantize_per_tensor_default_241 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param79, 0.007689815480262041, 0, -127, 127, torch.int8);  _frozen_param79 = None\n",
      "    features_denseblock3_denselayer21_layers_conv1_weight_bias = self.features_denseblock3_denselayer21_layers_conv1_weight_bias\n",
      "    conv2d_79 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_240, dequantize_per_tensor_default_241, features_denseblock3_denselayer21_layers_conv1_weight_bias);  dequantize_per_tensor_default_240 = dequantize_per_tensor_default_241 = features_denseblock3_denselayer21_layers_conv1_weight_bias = None\n",
      "    relu__80 = torch.ops.aten.relu_.default(conv2d_79);  conv2d_79 = None\n",
      "    quantize_per_tensor_default_242 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__80, 0.02554982341825962, -128, -128, 127, torch.int8);  relu__80 = None\n",
      "    dequantize_per_tensor_default_242 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_242, 0.02554982341825962, -128, -128, 127, torch.int8);  quantize_per_tensor_default_242 = None\n",
      "    _frozen_param80 = self._frozen_param80\n",
      "    dequantize_per_tensor_default_243 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param80, 0.0014898556983098388, 0, -127, 127, torch.int8);  _frozen_param80 = None\n",
      "    conv2d_80 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_242, dequantize_per_tensor_default_243, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_242 = dequantize_per_tensor_default_243 = None\n",
      "    quantize_per_tensor_default_244 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_80, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_80 = None\n",
      "    dequantize_per_tensor_default_244 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_244, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_244 = None\n",
      "    cat_38 = torch.ops.aten.cat.default([dequantize_per_tensor_default_405, dequantize_per_tensor_default_244], 1);  dequantize_per_tensor_default_405 = dequantize_per_tensor_default_244 = None\n",
      "    quantize_per_tensor_default_245 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_38, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_38 = None\n",
      "    dequantize_per_tensor_default_245 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_245, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_406 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_245, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_245 = None\n",
      "    _param_constant243 = self.features_denseblock3_denselayer22_layers_norm1_weight\n",
      "    _param_constant244 = self.features_denseblock3_denselayer22_layers_norm1_bias\n",
      "    _tensor_constant162 = self.features_denseblock3_denselayer22_layers_norm1_running_mean\n",
      "    _tensor_constant163 = self.features_denseblock3_denselayer22_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_81 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_245, _param_constant243, _param_constant244, _tensor_constant162, _tensor_constant163, 0.1, 1e-05);  dequantize_per_tensor_default_245 = _param_constant243 = _param_constant244 = _tensor_constant162 = _tensor_constant163 = None\n",
      "    getitem_243 = _native_batch_norm_legit_no_training_81[0];  _native_batch_norm_legit_no_training_81 = None\n",
      "    relu__81 = torch.ops.aten.relu_.default(getitem_243);  getitem_243 = None\n",
      "    quantize_per_tensor_default_246 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__81, 0.013866767287254333, -128, -128, 127, torch.int8);  relu__81 = None\n",
      "    dequantize_per_tensor_default_246 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_246, 0.013866767287254333, -128, -128, 127, torch.int8);  quantize_per_tensor_default_246 = None\n",
      "    _frozen_param81 = self._frozen_param81\n",
      "    dequantize_per_tensor_default_247 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param81, 0.010334867052733898, 0, -127, 127, torch.int8);  _frozen_param81 = None\n",
      "    features_denseblock3_denselayer22_layers_conv1_weight_bias = self.features_denseblock3_denselayer22_layers_conv1_weight_bias\n",
      "    conv2d_81 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_246, dequantize_per_tensor_default_247, features_denseblock3_denselayer22_layers_conv1_weight_bias);  dequantize_per_tensor_default_246 = dequantize_per_tensor_default_247 = features_denseblock3_denselayer22_layers_conv1_weight_bias = None\n",
      "    relu__82 = torch.ops.aten.relu_.default(conv2d_81);  conv2d_81 = None\n",
      "    quantize_per_tensor_default_248 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__82, 0.022194935008883476, -128, -128, 127, torch.int8);  relu__82 = None\n",
      "    dequantize_per_tensor_default_248 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_248, 0.022194935008883476, -128, -128, 127, torch.int8);  quantize_per_tensor_default_248 = None\n",
      "    _frozen_param82 = self._frozen_param82\n",
      "    dequantize_per_tensor_default_249 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param82, 0.001793096074834466, 0, -127, 127, torch.int8);  _frozen_param82 = None\n",
      "    conv2d_82 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_248, dequantize_per_tensor_default_249, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_248 = dequantize_per_tensor_default_249 = None\n",
      "    quantize_per_tensor_default_250 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_82, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_82 = None\n",
      "    dequantize_per_tensor_default_250 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_250, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_250 = None\n",
      "    cat_39 = torch.ops.aten.cat.default([dequantize_per_tensor_default_406, dequantize_per_tensor_default_250], 1);  dequantize_per_tensor_default_406 = dequantize_per_tensor_default_250 = None\n",
      "    quantize_per_tensor_default_251 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_39, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_39 = None\n",
      "    dequantize_per_tensor_default_251 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_251, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_407 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_251, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_251 = None\n",
      "    _param_constant249 = self.features_denseblock3_denselayer23_layers_norm1_weight\n",
      "    _param_constant250 = self.features_denseblock3_denselayer23_layers_norm1_bias\n",
      "    _tensor_constant166 = self.features_denseblock3_denselayer23_layers_norm1_running_mean\n",
      "    _tensor_constant167 = self.features_denseblock3_denselayer23_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_83 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_251, _param_constant249, _param_constant250, _tensor_constant166, _tensor_constant167, 0.1, 1e-05);  dequantize_per_tensor_default_251 = _param_constant249 = _param_constant250 = _tensor_constant166 = _tensor_constant167 = None\n",
      "    getitem_249 = _native_batch_norm_legit_no_training_83[0];  _native_batch_norm_legit_no_training_83 = None\n",
      "    relu__83 = torch.ops.aten.relu_.default(getitem_249);  getitem_249 = None\n",
      "    quantize_per_tensor_default_252 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__83, 0.02189573459327221, -128, -128, 127, torch.int8);  relu__83 = None\n",
      "    dequantize_per_tensor_default_252 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_252, 0.02189573459327221, -128, -128, 127, torch.int8);  quantize_per_tensor_default_252 = None\n",
      "    _frozen_param83 = self._frozen_param83\n",
      "    dequantize_per_tensor_default_253 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param83, 0.008317476138472557, 0, -127, 127, torch.int8);  _frozen_param83 = None\n",
      "    features_denseblock3_denselayer23_layers_conv1_weight_bias = self.features_denseblock3_denselayer23_layers_conv1_weight_bias\n",
      "    conv2d_83 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_252, dequantize_per_tensor_default_253, features_denseblock3_denselayer23_layers_conv1_weight_bias);  dequantize_per_tensor_default_252 = dequantize_per_tensor_default_253 = features_denseblock3_denselayer23_layers_conv1_weight_bias = None\n",
      "    relu__84 = torch.ops.aten.relu_.default(conv2d_83);  conv2d_83 = None\n",
      "    quantize_per_tensor_default_254 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__84, 0.01919465884566307, -128, -128, 127, torch.int8);  relu__84 = None\n",
      "    dequantize_per_tensor_default_254 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_254, 0.01919465884566307, -128, -128, 127, torch.int8);  quantize_per_tensor_default_254 = None\n",
      "    _frozen_param84 = self._frozen_param84\n",
      "    dequantize_per_tensor_default_255 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param84, 0.0017358582699671388, 0, -127, 127, torch.int8);  _frozen_param84 = None\n",
      "    conv2d_84 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_254, dequantize_per_tensor_default_255, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_254 = dequantize_per_tensor_default_255 = None\n",
      "    quantize_per_tensor_default_256 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_84, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_84 = None\n",
      "    dequantize_per_tensor_default_256 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_256, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_256 = None\n",
      "    cat_40 = torch.ops.aten.cat.default([dequantize_per_tensor_default_407, dequantize_per_tensor_default_256], 1);  dequantize_per_tensor_default_407 = dequantize_per_tensor_default_256 = None\n",
      "    quantize_per_tensor_default_257 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_40, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_40 = None\n",
      "    dequantize_per_tensor_default_257 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_257, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_408 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_257, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_257 = None\n",
      "    _param_constant255 = self.features_denseblock3_denselayer24_layers_norm1_weight\n",
      "    _param_constant256 = self.features_denseblock3_denselayer24_layers_norm1_bias\n",
      "    _tensor_constant170 = self.features_denseblock3_denselayer24_layers_norm1_running_mean\n",
      "    _tensor_constant171 = self.features_denseblock3_denselayer24_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_85 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_257, _param_constant255, _param_constant256, _tensor_constant170, _tensor_constant171, 0.1, 1e-05);  dequantize_per_tensor_default_257 = _param_constant255 = _param_constant256 = _tensor_constant170 = _tensor_constant171 = None\n",
      "    getitem_255 = _native_batch_norm_legit_no_training_85[0];  _native_batch_norm_legit_no_training_85 = None\n",
      "    relu__85 = torch.ops.aten.relu_.default(getitem_255);  getitem_255 = None\n",
      "    quantize_per_tensor_default_258 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__85, 0.022350188344717026, -128, -128, 127, torch.int8);  relu__85 = None\n",
      "    dequantize_per_tensor_default_258 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_258, 0.022350188344717026, -128, -128, 127, torch.int8);  quantize_per_tensor_default_258 = None\n",
      "    _frozen_param85 = self._frozen_param85\n",
      "    dequantize_per_tensor_default_259 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param85, 0.0063673402182757854, 0, -127, 127, torch.int8);  _frozen_param85 = None\n",
      "    features_denseblock3_denselayer24_layers_conv1_weight_bias = self.features_denseblock3_denselayer24_layers_conv1_weight_bias\n",
      "    conv2d_85 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_258, dequantize_per_tensor_default_259, features_denseblock3_denselayer24_layers_conv1_weight_bias);  dequantize_per_tensor_default_258 = dequantize_per_tensor_default_259 = features_denseblock3_denselayer24_layers_conv1_weight_bias = None\n",
      "    relu__86 = torch.ops.aten.relu_.default(conv2d_85);  conv2d_85 = None\n",
      "    quantize_per_tensor_default_260 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__86, 0.016037991270422935, -128, -128, 127, torch.int8);  relu__86 = None\n",
      "    dequantize_per_tensor_default_260 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_260, 0.016037991270422935, -128, -128, 127, torch.int8);  quantize_per_tensor_default_260 = None\n",
      "    _frozen_param86 = self._frozen_param86\n",
      "    dequantize_per_tensor_default_261 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param86, 0.0013281713472679257, 0, -127, 127, torch.int8);  _frozen_param86 = None\n",
      "    conv2d_86 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_260, dequantize_per_tensor_default_261, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_260 = dequantize_per_tensor_default_261 = None\n",
      "    quantize_per_tensor_default_262 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_86, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_86 = None\n",
      "    dequantize_per_tensor_default_262 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_262, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_262 = None\n",
      "    cat_41 = torch.ops.aten.cat.default([dequantize_per_tensor_default_408, dequantize_per_tensor_default_262], 1);  dequantize_per_tensor_default_408 = dequantize_per_tensor_default_262 = None\n",
      "    quantize_per_tensor_default_263 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_41, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_41 = None\n",
      "    dequantize_per_tensor_default_263 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_263, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_263 = None\n",
      "    _param_constant261 = self.features_transition3_norm_weight\n",
      "    _param_constant262 = self.features_transition3_norm_bias\n",
      "    _tensor_constant174 = self.features_transition3_norm_running_mean\n",
      "    _tensor_constant175 = self.features_transition3_norm_running_var\n",
      "    _native_batch_norm_legit_no_training_87 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_263, _param_constant261, _param_constant262, _tensor_constant174, _tensor_constant175, 0.1, 1e-05);  dequantize_per_tensor_default_263 = _param_constant261 = _param_constant262 = _tensor_constant174 = _tensor_constant175 = None\n",
      "    getitem_261 = _native_batch_norm_legit_no_training_87[0];  _native_batch_norm_legit_no_training_87 = None\n",
      "    relu__87 = torch.ops.aten.relu_.default(getitem_261);  getitem_261 = None\n",
      "    quantize_per_tensor_default_264 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__87, 0.041730694472789764, -128, -128, 127, torch.int8);  relu__87 = None\n",
      "    dequantize_per_tensor_default_264 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_264, 0.041730694472789764, -128, -128, 127, torch.int8);  quantize_per_tensor_default_264 = None\n",
      "    _frozen_param87 = self._frozen_param87\n",
      "    dequantize_per_tensor_default_265 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param87, 0.005728257820010185, 0, -127, 127, torch.int8);  _frozen_param87 = None\n",
      "    conv2d_87 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_264, dequantize_per_tensor_default_265);  dequantize_per_tensor_default_264 = dequantize_per_tensor_default_265 = None\n",
      "    quantize_per_tensor_default_266 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_87, 0.049894753843545914, -6, -128, 127, torch.int8);  conv2d_87 = None\n",
      "    dequantize_per_tensor_default_266 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_266, 0.049894753843545914, -6, -128, 127, torch.int8);  quantize_per_tensor_default_266 = None\n",
      "    avg_pool2d_2 = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_default_266, [2, 2], [2, 2]);  dequantize_per_tensor_default_266 = None\n",
      "    quantize_per_tensor_default_267 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_2, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_267 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_267, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_267 = None\n",
      "    _param_constant264 = self.features_denseblock4_denselayer1_layers_norm1_weight\n",
      "    _param_constant265 = self.features_denseblock4_denselayer1_layers_norm1_bias\n",
      "    _tensor_constant176 = self.features_denseblock4_denselayer1_layers_norm1_running_mean\n",
      "    _tensor_constant177 = self.features_denseblock4_denselayer1_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_88 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_2, _param_constant264, _param_constant265, _tensor_constant176, _tensor_constant177, 0.1, 1e-05);  avg_pool2d_2 = _param_constant264 = _param_constant265 = _tensor_constant176 = _tensor_constant177 = None\n",
      "    getitem_264 = _native_batch_norm_legit_no_training_88[0];  _native_batch_norm_legit_no_training_88 = None\n",
      "    relu__88 = torch.ops.aten.relu_.default(getitem_264);  getitem_264 = None\n",
      "    quantize_per_tensor_default_268 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__88, 0.024571435526013374, -128, -128, 127, torch.int8);  relu__88 = None\n",
      "    dequantize_per_tensor_default_268 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_268, 0.024571435526013374, -128, -128, 127, torch.int8);  quantize_per_tensor_default_268 = None\n",
      "    _frozen_param88 = self._frozen_param88\n",
      "    dequantize_per_tensor_default_269 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param88, 0.006350560113787651, 0, -127, 127, torch.int8);  _frozen_param88 = None\n",
      "    features_denseblock4_denselayer1_layers_conv1_weight_bias = self.features_denseblock4_denselayer1_layers_conv1_weight_bias\n",
      "    conv2d_88 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_268, dequantize_per_tensor_default_269, features_denseblock4_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_default_268 = dequantize_per_tensor_default_269 = features_denseblock4_denselayer1_layers_conv1_weight_bias = None\n",
      "    relu__89 = torch.ops.aten.relu_.default(conv2d_88);  conv2d_88 = None\n",
      "    quantize_per_tensor_default_270 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__89, 0.016578614711761475, -128, -128, 127, torch.int8);  relu__89 = None\n",
      "    dequantize_per_tensor_default_270 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_270, 0.016578614711761475, -128, -128, 127, torch.int8);  quantize_per_tensor_default_270 = None\n",
      "    _frozen_param89 = self._frozen_param89\n",
      "    dequantize_per_tensor_default_271 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param89, 0.001437353203073144, 0, -127, 127, torch.int8);  _frozen_param89 = None\n",
      "    conv2d_89 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_270, dequantize_per_tensor_default_271, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_270 = dequantize_per_tensor_default_271 = None\n",
      "    quantize_per_tensor_default_272 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_89, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_89 = None\n",
      "    dequantize_per_tensor_default_272 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_272, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_272 = None\n",
      "    cat_42 = torch.ops.aten.cat.default([dequantize_per_tensor_default_267, dequantize_per_tensor_default_272], 1);  dequantize_per_tensor_default_267 = dequantize_per_tensor_default_272 = None\n",
      "    quantize_per_tensor_default_273 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_42, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_42 = None\n",
      "    dequantize_per_tensor_default_273 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_273, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_409 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_273, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_273 = None\n",
      "    _param_constant270 = self.features_denseblock4_denselayer2_layers_norm1_weight\n",
      "    _param_constant271 = self.features_denseblock4_denselayer2_layers_norm1_bias\n",
      "    _tensor_constant180 = self.features_denseblock4_denselayer2_layers_norm1_running_mean\n",
      "    _tensor_constant181 = self.features_denseblock4_denselayer2_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_90 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_273, _param_constant270, _param_constant271, _tensor_constant180, _tensor_constant181, 0.1, 1e-05);  dequantize_per_tensor_default_273 = _param_constant270 = _param_constant271 = _tensor_constant180 = _tensor_constant181 = None\n",
      "    getitem_270 = _native_batch_norm_legit_no_training_90[0];  _native_batch_norm_legit_no_training_90 = None\n",
      "    relu__90 = torch.ops.aten.relu_.default(getitem_270);  getitem_270 = None\n",
      "    quantize_per_tensor_default_274 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__90, 0.028671227395534515, -128, -128, 127, torch.int8);  relu__90 = None\n",
      "    dequantize_per_tensor_default_274 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_274, 0.028671227395534515, -128, -128, 127, torch.int8);  quantize_per_tensor_default_274 = None\n",
      "    _frozen_param90 = self._frozen_param90\n",
      "    dequantize_per_tensor_default_275 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param90, 0.006311160512268543, 0, -127, 127, torch.int8);  _frozen_param90 = None\n",
      "    features_denseblock4_denselayer2_layers_conv1_weight_bias = self.features_denseblock4_denselayer2_layers_conv1_weight_bias\n",
      "    conv2d_90 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_274, dequantize_per_tensor_default_275, features_denseblock4_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_default_274 = dequantize_per_tensor_default_275 = features_denseblock4_denselayer2_layers_conv1_weight_bias = None\n",
      "    relu__91 = torch.ops.aten.relu_.default(conv2d_90);  conv2d_90 = None\n",
      "    quantize_per_tensor_default_276 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__91, 0.02069302648305893, -128, -128, 127, torch.int8);  relu__91 = None\n",
      "    dequantize_per_tensor_default_276 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_276, 0.02069302648305893, -128, -128, 127, torch.int8);  quantize_per_tensor_default_276 = None\n",
      "    _frozen_param91 = self._frozen_param91\n",
      "    dequantize_per_tensor_default_277 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param91, 0.0016781366430222988, 0, -127, 127, torch.int8);  _frozen_param91 = None\n",
      "    conv2d_91 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_276, dequantize_per_tensor_default_277, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_276 = dequantize_per_tensor_default_277 = None\n",
      "    quantize_per_tensor_default_278 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_91, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_91 = None\n",
      "    dequantize_per_tensor_default_278 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_278, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_278 = None\n",
      "    cat_43 = torch.ops.aten.cat.default([dequantize_per_tensor_default_409, dequantize_per_tensor_default_278], 1);  dequantize_per_tensor_default_409 = dequantize_per_tensor_default_278 = None\n",
      "    quantize_per_tensor_default_279 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_43, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_43 = None\n",
      "    dequantize_per_tensor_default_279 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_279, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_410 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_279, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_279 = None\n",
      "    _param_constant276 = self.features_denseblock4_denselayer3_layers_norm1_weight\n",
      "    _param_constant277 = self.features_denseblock4_denselayer3_layers_norm1_bias\n",
      "    _tensor_constant184 = self.features_denseblock4_denselayer3_layers_norm1_running_mean\n",
      "    _tensor_constant185 = self.features_denseblock4_denselayer3_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_92 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_279, _param_constant276, _param_constant277, _tensor_constant184, _tensor_constant185, 0.1, 1e-05);  dequantize_per_tensor_default_279 = _param_constant276 = _param_constant277 = _tensor_constant184 = _tensor_constant185 = None\n",
      "    getitem_276 = _native_batch_norm_legit_no_training_92[0];  _native_batch_norm_legit_no_training_92 = None\n",
      "    relu__92 = torch.ops.aten.relu_.default(getitem_276);  getitem_276 = None\n",
      "    quantize_per_tensor_default_280 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__92, 0.025901002809405327, -128, -128, 127, torch.int8);  relu__92 = None\n",
      "    dequantize_per_tensor_default_280 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_280, 0.025901002809405327, -128, -128, 127, torch.int8);  quantize_per_tensor_default_280 = None\n",
      "    _frozen_param92 = self._frozen_param92\n",
      "    dequantize_per_tensor_default_281 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param92, 0.00706758676096797, 0, -127, 127, torch.int8);  _frozen_param92 = None\n",
      "    features_denseblock4_denselayer3_layers_conv1_weight_bias = self.features_denseblock4_denselayer3_layers_conv1_weight_bias\n",
      "    conv2d_92 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_280, dequantize_per_tensor_default_281, features_denseblock4_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_default_280 = dequantize_per_tensor_default_281 = features_denseblock4_denselayer3_layers_conv1_weight_bias = None\n",
      "    relu__93 = torch.ops.aten.relu_.default(conv2d_92);  conv2d_92 = None\n",
      "    quantize_per_tensor_default_282 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__93, 0.029033469036221504, -128, -128, 127, torch.int8);  relu__93 = None\n",
      "    dequantize_per_tensor_default_282 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_282, 0.029033469036221504, -128, -128, 127, torch.int8);  quantize_per_tensor_default_282 = None\n",
      "    _frozen_param93 = self._frozen_param93\n",
      "    dequantize_per_tensor_default_283 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param93, 0.0025906572118401527, 0, -127, 127, torch.int8);  _frozen_param93 = None\n",
      "    conv2d_93 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_282, dequantize_per_tensor_default_283, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_282 = dequantize_per_tensor_default_283 = None\n",
      "    quantize_per_tensor_default_284 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_93, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_93 = None\n",
      "    dequantize_per_tensor_default_284 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_284, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_284 = None\n",
      "    cat_44 = torch.ops.aten.cat.default([dequantize_per_tensor_default_410, dequantize_per_tensor_default_284], 1);  dequantize_per_tensor_default_410 = dequantize_per_tensor_default_284 = None\n",
      "    quantize_per_tensor_default_285 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_44, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_44 = None\n",
      "    dequantize_per_tensor_default_285 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_285, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_411 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_285, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_285 = None\n",
      "    _param_constant282 = self.features_denseblock4_denselayer4_layers_norm1_weight\n",
      "    _param_constant283 = self.features_denseblock4_denselayer4_layers_norm1_bias\n",
      "    _tensor_constant188 = self.features_denseblock4_denselayer4_layers_norm1_running_mean\n",
      "    _tensor_constant189 = self.features_denseblock4_denselayer4_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_94 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_285, _param_constant282, _param_constant283, _tensor_constant188, _tensor_constant189, 0.1, 1e-05);  dequantize_per_tensor_default_285 = _param_constant282 = _param_constant283 = _tensor_constant188 = _tensor_constant189 = None\n",
      "    getitem_282 = _native_batch_norm_legit_no_training_94[0];  _native_batch_norm_legit_no_training_94 = None\n",
      "    relu__94 = torch.ops.aten.relu_.default(getitem_282);  getitem_282 = None\n",
      "    quantize_per_tensor_default_286 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__94, 0.02989189326763153, -128, -128, 127, torch.int8);  relu__94 = None\n",
      "    dequantize_per_tensor_default_286 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_286, 0.02989189326763153, -128, -128, 127, torch.int8);  quantize_per_tensor_default_286 = None\n",
      "    _frozen_param94 = self._frozen_param94\n",
      "    dequantize_per_tensor_default_287 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param94, 0.00636905524879694, 0, -127, 127, torch.int8);  _frozen_param94 = None\n",
      "    features_denseblock4_denselayer4_layers_conv1_weight_bias = self.features_denseblock4_denselayer4_layers_conv1_weight_bias\n",
      "    conv2d_94 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_286, dequantize_per_tensor_default_287, features_denseblock4_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_default_286 = dequantize_per_tensor_default_287 = features_denseblock4_denselayer4_layers_conv1_weight_bias = None\n",
      "    relu__95 = torch.ops.aten.relu_.default(conv2d_94);  conv2d_94 = None\n",
      "    quantize_per_tensor_default_288 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__95, 0.01768406666815281, -128, -128, 127, torch.int8);  relu__95 = None\n",
      "    dequantize_per_tensor_default_288 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_288, 0.01768406666815281, -128, -128, 127, torch.int8);  quantize_per_tensor_default_288 = None\n",
      "    _frozen_param95 = self._frozen_param95\n",
      "    dequantize_per_tensor_default_289 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param95, 0.002960711717605591, 0, -127, 127, torch.int8);  _frozen_param95 = None\n",
      "    conv2d_95 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_288, dequantize_per_tensor_default_289, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_288 = dequantize_per_tensor_default_289 = None\n",
      "    quantize_per_tensor_default_290 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_95, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_95 = None\n",
      "    dequantize_per_tensor_default_290 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_290, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_290 = None\n",
      "    cat_45 = torch.ops.aten.cat.default([dequantize_per_tensor_default_411, dequantize_per_tensor_default_290], 1);  dequantize_per_tensor_default_411 = dequantize_per_tensor_default_290 = None\n",
      "    quantize_per_tensor_default_291 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_45, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_45 = None\n",
      "    dequantize_per_tensor_default_291 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_291, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_412 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_291, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_291 = None\n",
      "    _param_constant288 = self.features_denseblock4_denselayer5_layers_norm1_weight\n",
      "    _param_constant289 = self.features_denseblock4_denselayer5_layers_norm1_bias\n",
      "    _tensor_constant192 = self.features_denseblock4_denselayer5_layers_norm1_running_mean\n",
      "    _tensor_constant193 = self.features_denseblock4_denselayer5_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_96 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_291, _param_constant288, _param_constant289, _tensor_constant192, _tensor_constant193, 0.1, 1e-05);  dequantize_per_tensor_default_291 = _param_constant288 = _param_constant289 = _tensor_constant192 = _tensor_constant193 = None\n",
      "    getitem_288 = _native_batch_norm_legit_no_training_96[0];  _native_batch_norm_legit_no_training_96 = None\n",
      "    relu__96 = torch.ops.aten.relu_.default(getitem_288);  getitem_288 = None\n",
      "    quantize_per_tensor_default_292 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__96, 0.02547215297818184, -128, -128, 127, torch.int8);  relu__96 = None\n",
      "    dequantize_per_tensor_default_292 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_292, 0.02547215297818184, -128, -128, 127, torch.int8);  quantize_per_tensor_default_292 = None\n",
      "    _frozen_param96 = self._frozen_param96\n",
      "    dequantize_per_tensor_default_293 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param96, 0.004713223781436682, 0, -127, 127, torch.int8);  _frozen_param96 = None\n",
      "    features_denseblock4_denselayer5_layers_conv1_weight_bias = self.features_denseblock4_denselayer5_layers_conv1_weight_bias\n",
      "    conv2d_96 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_292, dequantize_per_tensor_default_293, features_denseblock4_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_default_292 = dequantize_per_tensor_default_293 = features_denseblock4_denselayer5_layers_conv1_weight_bias = None\n",
      "    relu__97 = torch.ops.aten.relu_.default(conv2d_96);  conv2d_96 = None\n",
      "    quantize_per_tensor_default_294 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__97, 0.01152466144412756, -128, -128, 127, torch.int8);  relu__97 = None\n",
      "    dequantize_per_tensor_default_294 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_294, 0.01152466144412756, -128, -128, 127, torch.int8);  quantize_per_tensor_default_294 = None\n",
      "    _frozen_param97 = self._frozen_param97\n",
      "    dequantize_per_tensor_default_295 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param97, 0.0012787734158337116, 0, -127, 127, torch.int8);  _frozen_param97 = None\n",
      "    conv2d_97 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_294, dequantize_per_tensor_default_295, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_294 = dequantize_per_tensor_default_295 = None\n",
      "    quantize_per_tensor_default_296 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_97, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_97 = None\n",
      "    dequantize_per_tensor_default_296 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_296, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_296 = None\n",
      "    cat_46 = torch.ops.aten.cat.default([dequantize_per_tensor_default_412, dequantize_per_tensor_default_296], 1);  dequantize_per_tensor_default_412 = dequantize_per_tensor_default_296 = None\n",
      "    quantize_per_tensor_default_297 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_46, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_46 = None\n",
      "    dequantize_per_tensor_default_297 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_297, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_413 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_297, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_297 = None\n",
      "    _param_constant294 = self.features_denseblock4_denselayer6_layers_norm1_weight\n",
      "    _param_constant295 = self.features_denseblock4_denselayer6_layers_norm1_bias\n",
      "    _tensor_constant196 = self.features_denseblock4_denselayer6_layers_norm1_running_mean\n",
      "    _tensor_constant197 = self.features_denseblock4_denselayer6_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_98 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_297, _param_constant294, _param_constant295, _tensor_constant196, _tensor_constant197, 0.1, 1e-05);  dequantize_per_tensor_default_297 = _param_constant294 = _param_constant295 = _tensor_constant196 = _tensor_constant197 = None\n",
      "    getitem_294 = _native_batch_norm_legit_no_training_98[0];  _native_batch_norm_legit_no_training_98 = None\n",
      "    relu__98 = torch.ops.aten.relu_.default(getitem_294);  getitem_294 = None\n",
      "    quantize_per_tensor_default_298 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__98, 0.02813451737165451, -128, -128, 127, torch.int8);  relu__98 = None\n",
      "    dequantize_per_tensor_default_298 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_298, 0.02813451737165451, -128, -128, 127, torch.int8);  quantize_per_tensor_default_298 = None\n",
      "    _frozen_param98 = self._frozen_param98\n",
      "    dequantize_per_tensor_default_299 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param98, 0.009045382030308247, 0, -127, 127, torch.int8);  _frozen_param98 = None\n",
      "    features_denseblock4_denselayer6_layers_conv1_weight_bias = self.features_denseblock4_denselayer6_layers_conv1_weight_bias\n",
      "    conv2d_98 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_298, dequantize_per_tensor_default_299, features_denseblock4_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_default_298 = dequantize_per_tensor_default_299 = features_denseblock4_denselayer6_layers_conv1_weight_bias = None\n",
      "    relu__99 = torch.ops.aten.relu_.default(conv2d_98);  conv2d_98 = None\n",
      "    quantize_per_tensor_default_300 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__99, 0.0340961329638958, -128, -128, 127, torch.int8);  relu__99 = None\n",
      "    dequantize_per_tensor_default_300 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_300, 0.0340961329638958, -128, -128, 127, torch.int8);  quantize_per_tensor_default_300 = None\n",
      "    _frozen_param99 = self._frozen_param99\n",
      "    dequantize_per_tensor_default_301 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param99, 0.0038567937444895506, 0, -127, 127, torch.int8);  _frozen_param99 = None\n",
      "    conv2d_99 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_300, dequantize_per_tensor_default_301, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_300 = dequantize_per_tensor_default_301 = None\n",
      "    quantize_per_tensor_default_302 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_99, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_99 = None\n",
      "    dequantize_per_tensor_default_302 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_302, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_302 = None\n",
      "    cat_47 = torch.ops.aten.cat.default([dequantize_per_tensor_default_413, dequantize_per_tensor_default_302], 1);  dequantize_per_tensor_default_413 = dequantize_per_tensor_default_302 = None\n",
      "    quantize_per_tensor_default_303 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_47, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_47 = None\n",
      "    dequantize_per_tensor_default_303 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_303, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_414 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_303, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_303 = None\n",
      "    _param_constant300 = self.features_denseblock4_denselayer7_layers_norm1_weight\n",
      "    _param_constant301 = self.features_denseblock4_denselayer7_layers_norm1_bias\n",
      "    _tensor_constant200 = self.features_denseblock4_denselayer7_layers_norm1_running_mean\n",
      "    _tensor_constant201 = self.features_denseblock4_denselayer7_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_100 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_303, _param_constant300, _param_constant301, _tensor_constant200, _tensor_constant201, 0.1, 1e-05);  dequantize_per_tensor_default_303 = _param_constant300 = _param_constant301 = _tensor_constant200 = _tensor_constant201 = None\n",
      "    getitem_300 = _native_batch_norm_legit_no_training_100[0];  _native_batch_norm_legit_no_training_100 = None\n",
      "    relu__100 = torch.ops.aten.relu_.default(getitem_300);  getitem_300 = None\n",
      "    quantize_per_tensor_default_304 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__100, 0.030158739537000656, -128, -128, 127, torch.int8);  relu__100 = None\n",
      "    dequantize_per_tensor_default_304 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_304, 0.030158739537000656, -128, -128, 127, torch.int8);  quantize_per_tensor_default_304 = None\n",
      "    _frozen_param100 = self._frozen_param100\n",
      "    dequantize_per_tensor_default_305 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param100, 0.005891221575438976, 0, -127, 127, torch.int8);  _frozen_param100 = None\n",
      "    features_denseblock4_denselayer7_layers_conv1_weight_bias = self.features_denseblock4_denselayer7_layers_conv1_weight_bias\n",
      "    conv2d_100 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_304, dequantize_per_tensor_default_305, features_denseblock4_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_default_304 = dequantize_per_tensor_default_305 = features_denseblock4_denselayer7_layers_conv1_weight_bias = None\n",
      "    relu__101 = torch.ops.aten.relu_.default(conv2d_100);  conv2d_100 = None\n",
      "    quantize_per_tensor_default_306 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__101, 0.01584067940711975, -128, -128, 127, torch.int8);  relu__101 = None\n",
      "    dequantize_per_tensor_default_306 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_306, 0.01584067940711975, -128, -128, 127, torch.int8);  quantize_per_tensor_default_306 = None\n",
      "    _frozen_param101 = self._frozen_param101\n",
      "    dequantize_per_tensor_default_307 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param101, 0.0014143078587949276, 0, -127, 127, torch.int8);  _frozen_param101 = None\n",
      "    conv2d_101 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_306, dequantize_per_tensor_default_307, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_306 = dequantize_per_tensor_default_307 = None\n",
      "    quantize_per_tensor_default_308 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_101, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_101 = None\n",
      "    dequantize_per_tensor_default_308 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_308, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_308 = None\n",
      "    cat_48 = torch.ops.aten.cat.default([dequantize_per_tensor_default_414, dequantize_per_tensor_default_308], 1);  dequantize_per_tensor_default_414 = dequantize_per_tensor_default_308 = None\n",
      "    quantize_per_tensor_default_309 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_48, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_48 = None\n",
      "    dequantize_per_tensor_default_309 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_309, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_415 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_309, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_309 = None\n",
      "    _param_constant306 = self.features_denseblock4_denselayer8_layers_norm1_weight\n",
      "    _param_constant307 = self.features_denseblock4_denselayer8_layers_norm1_bias\n",
      "    _tensor_constant204 = self.features_denseblock4_denselayer8_layers_norm1_running_mean\n",
      "    _tensor_constant205 = self.features_denseblock4_denselayer8_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_102 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_309, _param_constant306, _param_constant307, _tensor_constant204, _tensor_constant205, 0.1, 1e-05);  dequantize_per_tensor_default_309 = _param_constant306 = _param_constant307 = _tensor_constant204 = _tensor_constant205 = None\n",
      "    getitem_306 = _native_batch_norm_legit_no_training_102[0];  _native_batch_norm_legit_no_training_102 = None\n",
      "    relu__102 = torch.ops.aten.relu_.default(getitem_306);  getitem_306 = None\n",
      "    quantize_per_tensor_default_310 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__102, 0.03208186477422714, -128, -128, 127, torch.int8);  relu__102 = None\n",
      "    dequantize_per_tensor_default_310 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_310, 0.03208186477422714, -128, -128, 127, torch.int8);  quantize_per_tensor_default_310 = None\n",
      "    _frozen_param102 = self._frozen_param102\n",
      "    dequantize_per_tensor_default_311 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param102, 0.005860139150172472, 0, -127, 127, torch.int8);  _frozen_param102 = None\n",
      "    features_denseblock4_denselayer8_layers_conv1_weight_bias = self.features_denseblock4_denselayer8_layers_conv1_weight_bias\n",
      "    conv2d_102 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_310, dequantize_per_tensor_default_311, features_denseblock4_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_default_310 = dequantize_per_tensor_default_311 = features_denseblock4_denselayer8_layers_conv1_weight_bias = None\n",
      "    relu__103 = torch.ops.aten.relu_.default(conv2d_102);  conv2d_102 = None\n",
      "    quantize_per_tensor_default_312 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__103, 0.014829743653535843, -128, -128, 127, torch.int8);  relu__103 = None\n",
      "    dequantize_per_tensor_default_312 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_312, 0.014829743653535843, -128, -128, 127, torch.int8);  quantize_per_tensor_default_312 = None\n",
      "    _frozen_param103 = self._frozen_param103\n",
      "    dequantize_per_tensor_default_313 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param103, 0.002665165113285184, 0, -127, 127, torch.int8);  _frozen_param103 = None\n",
      "    conv2d_103 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_312, dequantize_per_tensor_default_313, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_312 = dequantize_per_tensor_default_313 = None\n",
      "    quantize_per_tensor_default_314 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_103, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_103 = None\n",
      "    dequantize_per_tensor_default_314 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_314, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_314 = None\n",
      "    cat_49 = torch.ops.aten.cat.default([dequantize_per_tensor_default_415, dequantize_per_tensor_default_314], 1);  dequantize_per_tensor_default_415 = dequantize_per_tensor_default_314 = None\n",
      "    quantize_per_tensor_default_315 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_49, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_49 = None\n",
      "    dequantize_per_tensor_default_315 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_315, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_416 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_315, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_315 = None\n",
      "    _param_constant312 = self.features_denseblock4_denselayer9_layers_norm1_weight\n",
      "    _param_constant313 = self.features_denseblock4_denselayer9_layers_norm1_bias\n",
      "    _tensor_constant208 = self.features_denseblock4_denselayer9_layers_norm1_running_mean\n",
      "    _tensor_constant209 = self.features_denseblock4_denselayer9_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_104 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_315, _param_constant312, _param_constant313, _tensor_constant208, _tensor_constant209, 0.1, 1e-05);  dequantize_per_tensor_default_315 = _param_constant312 = _param_constant313 = _tensor_constant208 = _tensor_constant209 = None\n",
      "    getitem_312 = _native_batch_norm_legit_no_training_104[0];  _native_batch_norm_legit_no_training_104 = None\n",
      "    relu__104 = torch.ops.aten.relu_.default(getitem_312);  getitem_312 = None\n",
      "    quantize_per_tensor_default_316 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__104, 0.02786254696547985, -128, -128, 127, torch.int8);  relu__104 = None\n",
      "    dequantize_per_tensor_default_316 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_316, 0.02786254696547985, -128, -128, 127, torch.int8);  quantize_per_tensor_default_316 = None\n",
      "    _frozen_param104 = self._frozen_param104\n",
      "    dequantize_per_tensor_default_317 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param104, 0.00571509450674057, 0, -127, 127, torch.int8);  _frozen_param104 = None\n",
      "    features_denseblock4_denselayer9_layers_conv1_weight_bias = self.features_denseblock4_denselayer9_layers_conv1_weight_bias\n",
      "    conv2d_104 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_316, dequantize_per_tensor_default_317, features_denseblock4_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_default_316 = dequantize_per_tensor_default_317 = features_denseblock4_denselayer9_layers_conv1_weight_bias = None\n",
      "    relu__105 = torch.ops.aten.relu_.default(conv2d_104);  conv2d_104 = None\n",
      "    quantize_per_tensor_default_318 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__105, 0.005122145172208548, -128, -128, 127, torch.int8);  relu__105 = None\n",
      "    dequantize_per_tensor_default_318 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_318, 0.005122145172208548, -128, -128, 127, torch.int8);  quantize_per_tensor_default_318 = None\n",
      "    _frozen_param105 = self._frozen_param105\n",
      "    dequantize_per_tensor_default_319 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param105, 0.0013437048764899373, 0, -127, 127, torch.int8);  _frozen_param105 = None\n",
      "    conv2d_105 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_318, dequantize_per_tensor_default_319, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_318 = dequantize_per_tensor_default_319 = None\n",
      "    quantize_per_tensor_default_320 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_105, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_105 = None\n",
      "    dequantize_per_tensor_default_320 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_320, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_320 = None\n",
      "    cat_50 = torch.ops.aten.cat.default([dequantize_per_tensor_default_416, dequantize_per_tensor_default_320], 1);  dequantize_per_tensor_default_416 = dequantize_per_tensor_default_320 = None\n",
      "    quantize_per_tensor_default_321 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_50, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_50 = None\n",
      "    dequantize_per_tensor_default_321 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_321, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_417 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_321, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_321 = None\n",
      "    _param_constant318 = self.features_denseblock4_denselayer10_layers_norm1_weight\n",
      "    _param_constant319 = self.features_denseblock4_denselayer10_layers_norm1_bias\n",
      "    _tensor_constant212 = self.features_denseblock4_denselayer10_layers_norm1_running_mean\n",
      "    _tensor_constant213 = self.features_denseblock4_denselayer10_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_106 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_321, _param_constant318, _param_constant319, _tensor_constant212, _tensor_constant213, 0.1, 1e-05);  dequantize_per_tensor_default_321 = _param_constant318 = _param_constant319 = _tensor_constant212 = _tensor_constant213 = None\n",
      "    getitem_318 = _native_batch_norm_legit_no_training_106[0];  _native_batch_norm_legit_no_training_106 = None\n",
      "    relu__106 = torch.ops.aten.relu_.default(getitem_318);  getitem_318 = None\n",
      "    quantize_per_tensor_default_322 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__106, 0.026937687769532204, -128, -128, 127, torch.int8);  relu__106 = None\n",
      "    dequantize_per_tensor_default_322 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_322, 0.026937687769532204, -128, -128, 127, torch.int8);  quantize_per_tensor_default_322 = None\n",
      "    _frozen_param106 = self._frozen_param106\n",
      "    dequantize_per_tensor_default_323 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param106, 0.004579649772495031, 0, -127, 127, torch.int8);  _frozen_param106 = None\n",
      "    features_denseblock4_denselayer10_layers_conv1_weight_bias = self.features_denseblock4_denselayer10_layers_conv1_weight_bias\n",
      "    conv2d_106 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_322, dequantize_per_tensor_default_323, features_denseblock4_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_default_322 = dequantize_per_tensor_default_323 = features_denseblock4_denselayer10_layers_conv1_weight_bias = None\n",
      "    relu__107 = torch.ops.aten.relu_.default(conv2d_106);  conv2d_106 = None\n",
      "    quantize_per_tensor_default_324 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__107, 0.0021511942613869905, -128, -128, 127, torch.int8);  relu__107 = None\n",
      "    dequantize_per_tensor_default_324 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_324, 0.0021511942613869905, -128, -128, 127, torch.int8);  quantize_per_tensor_default_324 = None\n",
      "    _frozen_param107 = self._frozen_param107\n",
      "    dequantize_per_tensor_default_325 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param107, 0.0012768249725922942, 0, -127, 127, torch.int8);  _frozen_param107 = None\n",
      "    conv2d_107 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_324, dequantize_per_tensor_default_325, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_324 = dequantize_per_tensor_default_325 = None\n",
      "    quantize_per_tensor_default_326 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_107, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_107 = None\n",
      "    dequantize_per_tensor_default_326 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_326, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_326 = None\n",
      "    cat_51 = torch.ops.aten.cat.default([dequantize_per_tensor_default_417, dequantize_per_tensor_default_326], 1);  dequantize_per_tensor_default_417 = dequantize_per_tensor_default_326 = None\n",
      "    quantize_per_tensor_default_327 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_51, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_51 = None\n",
      "    dequantize_per_tensor_default_327 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_327, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_418 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_327, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_327 = None\n",
      "    _param_constant324 = self.features_denseblock4_denselayer11_layers_norm1_weight\n",
      "    _param_constant325 = self.features_denseblock4_denselayer11_layers_norm1_bias\n",
      "    _tensor_constant216 = self.features_denseblock4_denselayer11_layers_norm1_running_mean\n",
      "    _tensor_constant217 = self.features_denseblock4_denselayer11_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_108 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_327, _param_constant324, _param_constant325, _tensor_constant216, _tensor_constant217, 0.1, 1e-05);  dequantize_per_tensor_default_327 = _param_constant324 = _param_constant325 = _tensor_constant216 = _tensor_constant217 = None\n",
      "    getitem_324 = _native_batch_norm_legit_no_training_108[0];  _native_batch_norm_legit_no_training_108 = None\n",
      "    relu__108 = torch.ops.aten.relu_.default(getitem_324);  getitem_324 = None\n",
      "    quantize_per_tensor_default_328 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__108, 0.026668384671211243, -128, -128, 127, torch.int8);  relu__108 = None\n",
      "    dequantize_per_tensor_default_328 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_328, 0.026668384671211243, -128, -128, 127, torch.int8);  quantize_per_tensor_default_328 = None\n",
      "    _frozen_param108 = self._frozen_param108\n",
      "    dequantize_per_tensor_default_329 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param108, 0.004289968404918909, 0, -127, 127, torch.int8);  _frozen_param108 = None\n",
      "    features_denseblock4_denselayer11_layers_conv1_weight_bias = self.features_denseblock4_denselayer11_layers_conv1_weight_bias\n",
      "    conv2d_108 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_328, dequantize_per_tensor_default_329, features_denseblock4_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_default_328 = dequantize_per_tensor_default_329 = features_denseblock4_denselayer11_layers_conv1_weight_bias = None\n",
      "    relu__109 = torch.ops.aten.relu_.default(conv2d_108);  conv2d_108 = None\n",
      "    quantize_per_tensor_default_330 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__109, 0.004541976843029261, -128, -128, 127, torch.int8);  relu__109 = None\n",
      "    dequantize_per_tensor_default_330 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_330, 0.004541976843029261, -128, -128, 127, torch.int8);  quantize_per_tensor_default_330 = None\n",
      "    _frozen_param109 = self._frozen_param109\n",
      "    dequantize_per_tensor_default_331 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param109, 0.001174488803371787, 0, -127, 127, torch.int8);  _frozen_param109 = None\n",
      "    conv2d_109 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_330, dequantize_per_tensor_default_331, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_330 = dequantize_per_tensor_default_331 = None\n",
      "    quantize_per_tensor_default_332 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_109, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_109 = None\n",
      "    dequantize_per_tensor_default_332 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_332, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_332 = None\n",
      "    cat_52 = torch.ops.aten.cat.default([dequantize_per_tensor_default_418, dequantize_per_tensor_default_332], 1);  dequantize_per_tensor_default_418 = dequantize_per_tensor_default_332 = None\n",
      "    quantize_per_tensor_default_333 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_52, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_52 = None\n",
      "    dequantize_per_tensor_default_333 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_333, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_419 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_333, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_333 = None\n",
      "    _param_constant330 = self.features_denseblock4_denselayer12_layers_norm1_weight\n",
      "    _param_constant331 = self.features_denseblock4_denselayer12_layers_norm1_bias\n",
      "    _tensor_constant220 = self.features_denseblock4_denselayer12_layers_norm1_running_mean\n",
      "    _tensor_constant221 = self.features_denseblock4_denselayer12_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_110 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_333, _param_constant330, _param_constant331, _tensor_constant220, _tensor_constant221, 0.1, 1e-05);  dequantize_per_tensor_default_333 = _param_constant330 = _param_constant331 = _tensor_constant220 = _tensor_constant221 = None\n",
      "    getitem_330 = _native_batch_norm_legit_no_training_110[0];  _native_batch_norm_legit_no_training_110 = None\n",
      "    relu__110 = torch.ops.aten.relu_.default(getitem_330);  getitem_330 = None\n",
      "    quantize_per_tensor_default_334 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__110, 0.02633899636566639, -128, -128, 127, torch.int8);  relu__110 = None\n",
      "    dequantize_per_tensor_default_334 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_334, 0.02633899636566639, -128, -128, 127, torch.int8);  quantize_per_tensor_default_334 = None\n",
      "    _frozen_param110 = self._frozen_param110\n",
      "    dequantize_per_tensor_default_335 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param110, 0.004873822443187237, 0, -127, 127, torch.int8);  _frozen_param110 = None\n",
      "    features_denseblock4_denselayer12_layers_conv1_weight_bias = self.features_denseblock4_denselayer12_layers_conv1_weight_bias\n",
      "    conv2d_110 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_334, dequantize_per_tensor_default_335, features_denseblock4_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_default_334 = dequantize_per_tensor_default_335 = features_denseblock4_denselayer12_layers_conv1_weight_bias = None\n",
      "    relu__111 = torch.ops.aten.relu_.default(conv2d_110);  conv2d_110 = None\n",
      "    quantize_per_tensor_default_336 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__111, 0.00443444075062871, -128, -128, 127, torch.int8);  relu__111 = None\n",
      "    dequantize_per_tensor_default_336 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_336, 0.00443444075062871, -128, -128, 127, torch.int8);  quantize_per_tensor_default_336 = None\n",
      "    _frozen_param111 = self._frozen_param111\n",
      "    dequantize_per_tensor_default_337 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param111, 0.0012900737347081304, 0, -127, 127, torch.int8);  _frozen_param111 = None\n",
      "    conv2d_111 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_336, dequantize_per_tensor_default_337, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_336 = dequantize_per_tensor_default_337 = None\n",
      "    quantize_per_tensor_default_338 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_111, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_111 = None\n",
      "    dequantize_per_tensor_default_338 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_338, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_338 = None\n",
      "    cat_53 = torch.ops.aten.cat.default([dequantize_per_tensor_default_419, dequantize_per_tensor_default_338], 1);  dequantize_per_tensor_default_419 = dequantize_per_tensor_default_338 = None\n",
      "    quantize_per_tensor_default_339 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_53, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_53 = None\n",
      "    dequantize_per_tensor_default_339 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_339, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_420 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_339, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_339 = None\n",
      "    _param_constant336 = self.features_denseblock4_denselayer13_layers_norm1_weight\n",
      "    _param_constant337 = self.features_denseblock4_denselayer13_layers_norm1_bias\n",
      "    _tensor_constant224 = self.features_denseblock4_denselayer13_layers_norm1_running_mean\n",
      "    _tensor_constant225 = self.features_denseblock4_denselayer13_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_112 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_339, _param_constant336, _param_constant337, _tensor_constant224, _tensor_constant225, 0.1, 1e-05);  dequantize_per_tensor_default_339 = _param_constant336 = _param_constant337 = _tensor_constant224 = _tensor_constant225 = None\n",
      "    getitem_336 = _native_batch_norm_legit_no_training_112[0];  _native_batch_norm_legit_no_training_112 = None\n",
      "    relu__112 = torch.ops.aten.relu_.default(getitem_336);  getitem_336 = None\n",
      "    quantize_per_tensor_default_340 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__112, 0.023481573909521103, -128, -128, 127, torch.int8);  relu__112 = None\n",
      "    dequantize_per_tensor_default_340 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_340, 0.023481573909521103, -128, -128, 127, torch.int8);  quantize_per_tensor_default_340 = None\n",
      "    _frozen_param112 = self._frozen_param112\n",
      "    dequantize_per_tensor_default_341 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param112, 0.004650074522942305, 0, -127, 127, torch.int8);  _frozen_param112 = None\n",
      "    features_denseblock4_denselayer13_layers_conv1_weight_bias = self.features_denseblock4_denselayer13_layers_conv1_weight_bias\n",
      "    conv2d_112 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_340, dequantize_per_tensor_default_341, features_denseblock4_denselayer13_layers_conv1_weight_bias);  dequantize_per_tensor_default_340 = dequantize_per_tensor_default_341 = features_denseblock4_denselayer13_layers_conv1_weight_bias = None\n",
      "    relu__113 = torch.ops.aten.relu_.default(conv2d_112);  conv2d_112 = None\n",
      "    quantize_per_tensor_default_342 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__113, 0.00782014150172472, -128, -128, 127, torch.int8);  relu__113 = None\n",
      "    dequantize_per_tensor_default_342 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_342, 0.00782014150172472, -128, -128, 127, torch.int8);  quantize_per_tensor_default_342 = None\n",
      "    _frozen_param113 = self._frozen_param113\n",
      "    dequantize_per_tensor_default_343 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param113, 0.0012907893396914005, 0, -127, 127, torch.int8);  _frozen_param113 = None\n",
      "    conv2d_113 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_342, dequantize_per_tensor_default_343, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_342 = dequantize_per_tensor_default_343 = None\n",
      "    quantize_per_tensor_default_344 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_113, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_113 = None\n",
      "    dequantize_per_tensor_default_344 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_344, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_344 = None\n",
      "    cat_54 = torch.ops.aten.cat.default([dequantize_per_tensor_default_420, dequantize_per_tensor_default_344], 1);  dequantize_per_tensor_default_420 = dequantize_per_tensor_default_344 = None\n",
      "    quantize_per_tensor_default_345 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_54, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_54 = None\n",
      "    dequantize_per_tensor_default_345 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_345, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_421 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_345, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_345 = None\n",
      "    _param_constant342 = self.features_denseblock4_denselayer14_layers_norm1_weight\n",
      "    _param_constant343 = self.features_denseblock4_denselayer14_layers_norm1_bias\n",
      "    _tensor_constant228 = self.features_denseblock4_denselayer14_layers_norm1_running_mean\n",
      "    _tensor_constant229 = self.features_denseblock4_denselayer14_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_114 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_345, _param_constant342, _param_constant343, _tensor_constant228, _tensor_constant229, 0.1, 1e-05);  dequantize_per_tensor_default_345 = _param_constant342 = _param_constant343 = _tensor_constant228 = _tensor_constant229 = None\n",
      "    getitem_342 = _native_batch_norm_legit_no_training_114[0];  _native_batch_norm_legit_no_training_114 = None\n",
      "    relu__114 = torch.ops.aten.relu_.default(getitem_342);  getitem_342 = None\n",
      "    quantize_per_tensor_default_346 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__114, 0.023704107850790024, -128, -128, 127, torch.int8);  relu__114 = None\n",
      "    dequantize_per_tensor_default_346 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_346, 0.023704107850790024, -128, -128, 127, torch.int8);  quantize_per_tensor_default_346 = None\n",
      "    _frozen_param114 = self._frozen_param114\n",
      "    dequantize_per_tensor_default_347 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param114, 0.004829755984246731, 0, -127, 127, torch.int8);  _frozen_param114 = None\n",
      "    features_denseblock4_denselayer14_layers_conv1_weight_bias = self.features_denseblock4_denselayer14_layers_conv1_weight_bias\n",
      "    conv2d_114 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_346, dequantize_per_tensor_default_347, features_denseblock4_denselayer14_layers_conv1_weight_bias);  dequantize_per_tensor_default_346 = dequantize_per_tensor_default_347 = features_denseblock4_denselayer14_layers_conv1_weight_bias = None\n",
      "    relu__115 = torch.ops.aten.relu_.default(conv2d_114);  conv2d_114 = None\n",
      "    quantize_per_tensor_default_348 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__115, 0.005172167904675007, -128, -128, 127, torch.int8);  relu__115 = None\n",
      "    dequantize_per_tensor_default_348 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_348, 0.005172167904675007, -128, -128, 127, torch.int8);  quantize_per_tensor_default_348 = None\n",
      "    _frozen_param115 = self._frozen_param115\n",
      "    dequantize_per_tensor_default_349 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param115, 0.0012164926156401634, 0, -127, 127, torch.int8);  _frozen_param115 = None\n",
      "    conv2d_115 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_348, dequantize_per_tensor_default_349, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_348 = dequantize_per_tensor_default_349 = None\n",
      "    quantize_per_tensor_default_350 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_115, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_115 = None\n",
      "    dequantize_per_tensor_default_350 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_350, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_350 = None\n",
      "    cat_55 = torch.ops.aten.cat.default([dequantize_per_tensor_default_421, dequantize_per_tensor_default_350], 1);  dequantize_per_tensor_default_421 = dequantize_per_tensor_default_350 = None\n",
      "    quantize_per_tensor_default_351 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_55, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_55 = None\n",
      "    dequantize_per_tensor_default_351 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_351, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_422 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_351, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_351 = None\n",
      "    _param_constant348 = self.features_denseblock4_denselayer15_layers_norm1_weight\n",
      "    _param_constant349 = self.features_denseblock4_denselayer15_layers_norm1_bias\n",
      "    _tensor_constant232 = self.features_denseblock4_denselayer15_layers_norm1_running_mean\n",
      "    _tensor_constant233 = self.features_denseblock4_denselayer15_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_116 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_351, _param_constant348, _param_constant349, _tensor_constant232, _tensor_constant233, 0.1, 1e-05);  dequantize_per_tensor_default_351 = _param_constant348 = _param_constant349 = _tensor_constant232 = _tensor_constant233 = None\n",
      "    getitem_348 = _native_batch_norm_legit_no_training_116[0];  _native_batch_norm_legit_no_training_116 = None\n",
      "    relu__116 = torch.ops.aten.relu_.default(getitem_348);  getitem_348 = None\n",
      "    quantize_per_tensor_default_352 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__116, 0.02477584220468998, -128, -128, 127, torch.int8);  relu__116 = None\n",
      "    dequantize_per_tensor_default_352 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_352, 0.02477584220468998, -128, -128, 127, torch.int8);  quantize_per_tensor_default_352 = None\n",
      "    _frozen_param116 = self._frozen_param116\n",
      "    dequantize_per_tensor_default_353 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param116, 0.004786992911249399, 0, -127, 127, torch.int8);  _frozen_param116 = None\n",
      "    features_denseblock4_denselayer15_layers_conv1_weight_bias = self.features_denseblock4_denselayer15_layers_conv1_weight_bias\n",
      "    conv2d_116 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_352, dequantize_per_tensor_default_353, features_denseblock4_denselayer15_layers_conv1_weight_bias);  dequantize_per_tensor_default_352 = dequantize_per_tensor_default_353 = features_denseblock4_denselayer15_layers_conv1_weight_bias = None\n",
      "    relu__117 = torch.ops.aten.relu_.default(conv2d_116);  conv2d_116 = None\n",
      "    quantize_per_tensor_default_354 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__117, 0.009676340967416763, -128, -128, 127, torch.int8);  relu__117 = None\n",
      "    dequantize_per_tensor_default_354 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_354, 0.009676340967416763, -128, -128, 127, torch.int8);  quantize_per_tensor_default_354 = None\n",
      "    _frozen_param117 = self._frozen_param117\n",
      "    dequantize_per_tensor_default_355 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param117, 0.001245377934537828, 0, -127, 127, torch.int8);  _frozen_param117 = None\n",
      "    conv2d_117 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_354, dequantize_per_tensor_default_355, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_354 = dequantize_per_tensor_default_355 = None\n",
      "    quantize_per_tensor_default_356 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_117, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_117 = None\n",
      "    dequantize_per_tensor_default_356 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_356, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_356 = None\n",
      "    cat_56 = torch.ops.aten.cat.default([dequantize_per_tensor_default_422, dequantize_per_tensor_default_356], 1);  dequantize_per_tensor_default_422 = dequantize_per_tensor_default_356 = None\n",
      "    quantize_per_tensor_default_357 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_56, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_56 = None\n",
      "    dequantize_per_tensor_default_357 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_357, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "    dequantize_per_tensor_default_423 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_357, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_357 = None\n",
      "    _param_constant354 = self.features_denseblock4_denselayer16_layers_norm1_weight\n",
      "    _param_constant355 = self.features_denseblock4_denselayer16_layers_norm1_bias\n",
      "    _tensor_constant236 = self.features_denseblock4_denselayer16_layers_norm1_running_mean\n",
      "    _tensor_constant237 = self.features_denseblock4_denselayer16_layers_norm1_running_var\n",
      "    _native_batch_norm_legit_no_training_118 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_357, _param_constant354, _param_constant355, _tensor_constant236, _tensor_constant237, 0.1, 1e-05);  dequantize_per_tensor_default_357 = _param_constant354 = _param_constant355 = _tensor_constant236 = _tensor_constant237 = None\n",
      "    getitem_354 = _native_batch_norm_legit_no_training_118[0];  _native_batch_norm_legit_no_training_118 = None\n",
      "    relu__118 = torch.ops.aten.relu_.default(getitem_354);  getitem_354 = None\n",
      "    quantize_per_tensor_default_358 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__118, 0.02714269794523716, -128, -128, 127, torch.int8);  relu__118 = None\n",
      "    dequantize_per_tensor_default_358 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_358, 0.02714269794523716, -128, -128, 127, torch.int8);  quantize_per_tensor_default_358 = None\n",
      "    _frozen_param118 = self._frozen_param118\n",
      "    dequantize_per_tensor_default_359 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param118, 0.0052767787128686905, 0, -127, 127, torch.int8);  _frozen_param118 = None\n",
      "    features_denseblock4_denselayer16_layers_conv1_weight_bias = self.features_denseblock4_denselayer16_layers_conv1_weight_bias\n",
      "    conv2d_118 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_358, dequantize_per_tensor_default_359, features_denseblock4_denselayer16_layers_conv1_weight_bias);  dequantize_per_tensor_default_358 = dequantize_per_tensor_default_359 = features_denseblock4_denselayer16_layers_conv1_weight_bias = None\n",
      "    relu__119 = torch.ops.aten.relu_.default(conv2d_118);  conv2d_118 = None\n",
      "    quantize_per_tensor_default_360 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__119, 0.016764948144555092, -128, -128, 127, torch.int8);  relu__119 = None\n",
      "    dequantize_per_tensor_default_360 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_360, 0.016764948144555092, -128, -128, 127, torch.int8);  quantize_per_tensor_default_360 = None\n",
      "    _frozen_param119 = self._frozen_param119\n",
      "    dequantize_per_tensor_default_361 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param119, 0.0013234312646090984, 0, -127, 127, torch.int8);  _frozen_param119 = None\n",
      "    conv2d_119 = torch.ops.aten.conv2d.default(dequantize_per_tensor_default_360, dequantize_per_tensor_default_361, None, [1, 1], [1, 1]);  dequantize_per_tensor_default_360 = dequantize_per_tensor_default_361 = None\n",
      "    quantize_per_tensor_default_362 = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_119, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_119 = None\n",
      "    dequantize_per_tensor_default_362 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_362, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_362 = None\n",
      "    cat_57 = torch.ops.aten.cat.default([dequantize_per_tensor_default_423, dequantize_per_tensor_default_362], 1);  dequantize_per_tensor_default_423 = dequantize_per_tensor_default_362 = None\n",
      "    quantize_per_tensor_default_363 = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_57, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_57 = None\n",
      "    dequantize_per_tensor_default_363 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_363, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_363 = None\n",
      "    _param_constant360 = self.features_norm5_weight\n",
      "    _param_constant361 = self.features_norm5_bias\n",
      "    _tensor_constant240 = self.features_norm5_running_mean\n",
      "    _tensor_constant241 = self.features_norm5_running_var\n",
      "    _native_batch_norm_legit_no_training_120 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_default_363, _param_constant360, _param_constant361, _tensor_constant240, _tensor_constant241, 0.1, 1e-05);  dequantize_per_tensor_default_363 = _param_constant360 = _param_constant361 = _tensor_constant240 = _tensor_constant241 = None\n",
      "    getitem_360 = _native_batch_norm_legit_no_training_120[0];  _native_batch_norm_legit_no_training_120 = None\n",
      "    relu__120 = torch.ops.aten.relu_.default(getitem_360);  getitem_360 = None\n",
      "    quantize_per_tensor_default_364 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__120, 0.5310883522033691, -128, -128, 127, torch.int8);  relu__120 = None\n",
      "    dequantize_per_tensor_default_364 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_364, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_default_364 = None\n",
      "    adaptive_avg_pool2d = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_default_364, [1, 1]);  dequantize_per_tensor_default_364 = None\n",
      "    quantize_per_tensor_default_365 = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 0.5310883522033691, -128, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
      "    dequantize_per_tensor_default_365 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_365, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_default_365 = None\n",
      "    flatten = torch.ops.aten.flatten.using_ints(dequantize_per_tensor_default_365, 1);  dequantize_per_tensor_default_365 = None\n",
      "    quantize_per_tensor_default_366 = torch.ops.quantized_decomposed.quantize_per_tensor.default(flatten, 0.5310883522033691, -128, -128, 127, torch.int8);  flatten = None\n",
      "    dequantize_per_tensor_default_366 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_366, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_default_366 = None\n",
      "    _frozen_param120 = self._frozen_param120\n",
      "    dequantize_per_tensor_default_367 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(_frozen_param120, 0.000355078955180943, 0, -127, 127, torch.int8);  _frozen_param120 = None\n",
      "    _param_constant363 = self.class_layers_out_bias\n",
      "    linear = torch.ops.aten.linear.default(dequantize_per_tensor_default_366, dequantize_per_tensor_default_367, _param_constant363);  dequantize_per_tensor_default_366 = dequantize_per_tensor_default_367 = _param_constant363 = None\n",
      "    quantize_per_tensor_default_368 = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 0.02458547241985798, -128, -128, 127, torch.int8);  linear = None\n",
      "    dequantize_per_tensor_default_368 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_368, 0.02458547241985798, -128, -128, 127, torch.int8);  quantize_per_tensor_default_368 = None\n",
      "    return pytree.tree_unflatten([dequantize_per_tensor_default_368], self._out_spec)\n",
      "    \n",
      "# To see more debug info, please use `graph_module.print_readable()`\n"
     ]
    }
   ],
   "source": [
    "print(\"Quantized Graph\")\n",
    "print(converted_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aten_dialect: ExportedProgram = export(converted_graph, example_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen Dialect Graph\n",
      "ExportedProgram:\n",
      "    class GraphModule(torch.nn.Module):\n",
      "        def forward(self, p_features_conv0_weight_bias: \"f32[64]\", p_features_denseblock1_denselayer1_layers_norm1_weight: \"f32[64]\", p_features_denseblock1_denselayer1_layers_norm1_bias: \"f32[64]\", p_features_denseblock1_denselayer1_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock1_denselayer2_layers_norm1_weight: \"f32[96]\", p_features_denseblock1_denselayer2_layers_norm1_bias: \"f32[96]\", p_features_denseblock1_denselayer2_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock1_denselayer3_layers_norm1_weight: \"f32[128]\", p_features_denseblock1_denselayer3_layers_norm1_bias: \"f32[128]\", p_features_denseblock1_denselayer3_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock1_denselayer4_layers_norm1_weight: \"f32[160]\", p_features_denseblock1_denselayer4_layers_norm1_bias: \"f32[160]\", p_features_denseblock1_denselayer4_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock1_denselayer5_layers_norm1_weight: \"f32[192]\", p_features_denseblock1_denselayer5_layers_norm1_bias: \"f32[192]\", p_features_denseblock1_denselayer5_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock1_denselayer6_layers_norm1_weight: \"f32[224]\", p_features_denseblock1_denselayer6_layers_norm1_bias: \"f32[224]\", p_features_denseblock1_denselayer6_layers_conv1_weight_bias: \"f32[128]\", p_features_transition1_norm_weight: \"f32[256]\", p_features_transition1_norm_bias: \"f32[256]\", p_features_denseblock2_denselayer1_layers_norm1_weight: \"f32[128]\", p_features_denseblock2_denselayer1_layers_norm1_bias: \"f32[128]\", p_features_denseblock2_denselayer1_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer2_layers_norm1_weight: \"f32[160]\", p_features_denseblock2_denselayer2_layers_norm1_bias: \"f32[160]\", p_features_denseblock2_denselayer2_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer3_layers_norm1_weight: \"f32[192]\", p_features_denseblock2_denselayer3_layers_norm1_bias: \"f32[192]\", p_features_denseblock2_denselayer3_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer4_layers_norm1_weight: \"f32[224]\", p_features_denseblock2_denselayer4_layers_norm1_bias: \"f32[224]\", p_features_denseblock2_denselayer4_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer5_layers_norm1_weight: \"f32[256]\", p_features_denseblock2_denselayer5_layers_norm1_bias: \"f32[256]\", p_features_denseblock2_denselayer5_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer6_layers_norm1_weight: \"f32[288]\", p_features_denseblock2_denselayer6_layers_norm1_bias: \"f32[288]\", p_features_denseblock2_denselayer6_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer7_layers_norm1_weight: \"f32[320]\", p_features_denseblock2_denselayer7_layers_norm1_bias: \"f32[320]\", p_features_denseblock2_denselayer7_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer8_layers_norm1_weight: \"f32[352]\", p_features_denseblock2_denselayer8_layers_norm1_bias: \"f32[352]\", p_features_denseblock2_denselayer8_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer9_layers_norm1_weight: \"f32[384]\", p_features_denseblock2_denselayer9_layers_norm1_bias: \"f32[384]\", p_features_denseblock2_denselayer9_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer10_layers_norm1_weight: \"f32[416]\", p_features_denseblock2_denselayer10_layers_norm1_bias: \"f32[416]\", p_features_denseblock2_denselayer10_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer11_layers_norm1_weight: \"f32[448]\", p_features_denseblock2_denselayer11_layers_norm1_bias: \"f32[448]\", p_features_denseblock2_denselayer11_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock2_denselayer12_layers_norm1_weight: \"f32[480]\", p_features_denseblock2_denselayer12_layers_norm1_bias: \"f32[480]\", p_features_denseblock2_denselayer12_layers_conv1_weight_bias: \"f32[128]\", p_features_transition2_norm_weight: \"f32[512]\", p_features_transition2_norm_bias: \"f32[512]\", p_features_denseblock3_denselayer1_layers_norm1_weight: \"f32[256]\", p_features_denseblock3_denselayer1_layers_norm1_bias: \"f32[256]\", p_features_denseblock3_denselayer1_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer2_layers_norm1_weight: \"f32[288]\", p_features_denseblock3_denselayer2_layers_norm1_bias: \"f32[288]\", p_features_denseblock3_denselayer2_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer3_layers_norm1_weight: \"f32[320]\", p_features_denseblock3_denselayer3_layers_norm1_bias: \"f32[320]\", p_features_denseblock3_denselayer3_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer4_layers_norm1_weight: \"f32[352]\", p_features_denseblock3_denselayer4_layers_norm1_bias: \"f32[352]\", p_features_denseblock3_denselayer4_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer5_layers_norm1_weight: \"f32[384]\", p_features_denseblock3_denselayer5_layers_norm1_bias: \"f32[384]\", p_features_denseblock3_denselayer5_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer6_layers_norm1_weight: \"f32[416]\", p_features_denseblock3_denselayer6_layers_norm1_bias: \"f32[416]\", p_features_denseblock3_denselayer6_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer7_layers_norm1_weight: \"f32[448]\", p_features_denseblock3_denselayer7_layers_norm1_bias: \"f32[448]\", p_features_denseblock3_denselayer7_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer8_layers_norm1_weight: \"f32[480]\", p_features_denseblock3_denselayer8_layers_norm1_bias: \"f32[480]\", p_features_denseblock3_denselayer8_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer9_layers_norm1_weight: \"f32[512]\", p_features_denseblock3_denselayer9_layers_norm1_bias: \"f32[512]\", p_features_denseblock3_denselayer9_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer10_layers_norm1_weight: \"f32[544]\", p_features_denseblock3_denselayer10_layers_norm1_bias: \"f32[544]\", p_features_denseblock3_denselayer10_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer11_layers_norm1_weight: \"f32[576]\", p_features_denseblock3_denselayer11_layers_norm1_bias: \"f32[576]\", p_features_denseblock3_denselayer11_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer12_layers_norm1_weight: \"f32[608]\", p_features_denseblock3_denselayer12_layers_norm1_bias: \"f32[608]\", p_features_denseblock3_denselayer12_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer13_layers_norm1_weight: \"f32[640]\", p_features_denseblock3_denselayer13_layers_norm1_bias: \"f32[640]\", p_features_denseblock3_denselayer13_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer14_layers_norm1_weight: \"f32[672]\", p_features_denseblock3_denselayer14_layers_norm1_bias: \"f32[672]\", p_features_denseblock3_denselayer14_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer15_layers_norm1_weight: \"f32[704]\", p_features_denseblock3_denselayer15_layers_norm1_bias: \"f32[704]\", p_features_denseblock3_denselayer15_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer16_layers_norm1_weight: \"f32[736]\", p_features_denseblock3_denselayer16_layers_norm1_bias: \"f32[736]\", p_features_denseblock3_denselayer16_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer17_layers_norm1_weight: \"f32[768]\", p_features_denseblock3_denselayer17_layers_norm1_bias: \"f32[768]\", p_features_denseblock3_denselayer17_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer18_layers_norm1_weight: \"f32[800]\", p_features_denseblock3_denselayer18_layers_norm1_bias: \"f32[800]\", p_features_denseblock3_denselayer18_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer19_layers_norm1_weight: \"f32[832]\", p_features_denseblock3_denselayer19_layers_norm1_bias: \"f32[832]\", p_features_denseblock3_denselayer19_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer20_layers_norm1_weight: \"f32[864]\", p_features_denseblock3_denselayer20_layers_norm1_bias: \"f32[864]\", p_features_denseblock3_denselayer20_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer21_layers_norm1_weight: \"f32[896]\", p_features_denseblock3_denselayer21_layers_norm1_bias: \"f32[896]\", p_features_denseblock3_denselayer21_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer22_layers_norm1_weight: \"f32[928]\", p_features_denseblock3_denselayer22_layers_norm1_bias: \"f32[928]\", p_features_denseblock3_denselayer22_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer23_layers_norm1_weight: \"f32[960]\", p_features_denseblock3_denselayer23_layers_norm1_bias: \"f32[960]\", p_features_denseblock3_denselayer23_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock3_denselayer24_layers_norm1_weight: \"f32[992]\", p_features_denseblock3_denselayer24_layers_norm1_bias: \"f32[992]\", p_features_denseblock3_denselayer24_layers_conv1_weight_bias: \"f32[128]\", p_features_transition3_norm_weight: \"f32[1024]\", p_features_transition3_norm_bias: \"f32[1024]\", p_features_denseblock4_denselayer1_layers_norm1_weight: \"f32[512]\", p_features_denseblock4_denselayer1_layers_norm1_bias: \"f32[512]\", p_features_denseblock4_denselayer1_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer2_layers_norm1_weight: \"f32[544]\", p_features_denseblock4_denselayer2_layers_norm1_bias: \"f32[544]\", p_features_denseblock4_denselayer2_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer3_layers_norm1_weight: \"f32[576]\", p_features_denseblock4_denselayer3_layers_norm1_bias: \"f32[576]\", p_features_denseblock4_denselayer3_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer4_layers_norm1_weight: \"f32[608]\", p_features_denseblock4_denselayer4_layers_norm1_bias: \"f32[608]\", p_features_denseblock4_denselayer4_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer5_layers_norm1_weight: \"f32[640]\", p_features_denseblock4_denselayer5_layers_norm1_bias: \"f32[640]\", p_features_denseblock4_denselayer5_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer6_layers_norm1_weight: \"f32[672]\", p_features_denseblock4_denselayer6_layers_norm1_bias: \"f32[672]\", p_features_denseblock4_denselayer6_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer7_layers_norm1_weight: \"f32[704]\", p_features_denseblock4_denselayer7_layers_norm1_bias: \"f32[704]\", p_features_denseblock4_denselayer7_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer8_layers_norm1_weight: \"f32[736]\", p_features_denseblock4_denselayer8_layers_norm1_bias: \"f32[736]\", p_features_denseblock4_denselayer8_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer9_layers_norm1_weight: \"f32[768]\", p_features_denseblock4_denselayer9_layers_norm1_bias: \"f32[768]\", p_features_denseblock4_denselayer9_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer10_layers_norm1_weight: \"f32[800]\", p_features_denseblock4_denselayer10_layers_norm1_bias: \"f32[800]\", p_features_denseblock4_denselayer10_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer11_layers_norm1_weight: \"f32[832]\", p_features_denseblock4_denselayer11_layers_norm1_bias: \"f32[832]\", p_features_denseblock4_denselayer11_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer12_layers_norm1_weight: \"f32[864]\", p_features_denseblock4_denselayer12_layers_norm1_bias: \"f32[864]\", p_features_denseblock4_denselayer12_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer13_layers_norm1_weight: \"f32[896]\", p_features_denseblock4_denselayer13_layers_norm1_bias: \"f32[896]\", p_features_denseblock4_denselayer13_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer14_layers_norm1_weight: \"f32[928]\", p_features_denseblock4_denselayer14_layers_norm1_bias: \"f32[928]\", p_features_denseblock4_denselayer14_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer15_layers_norm1_weight: \"f32[960]\", p_features_denseblock4_denselayer15_layers_norm1_bias: \"f32[960]\", p_features_denseblock4_denselayer15_layers_conv1_weight_bias: \"f32[128]\", p_features_denseblock4_denselayer16_layers_norm1_weight: \"f32[992]\", p_features_denseblock4_denselayer16_layers_norm1_bias: \"f32[992]\", p_features_denseblock4_denselayer16_layers_conv1_weight_bias: \"f32[128]\", p_features_norm5_weight: \"f32[1024]\", p_features_norm5_bias: \"f32[1024]\", p_class_layers_out_bias: \"f32[3]\", b__frozen_param0: \"i8[64, 3, 7, 7]\", b_features_denseblock1_denselayer1_layers_norm1_running_mean: \"f32[64]\", b_features_denseblock1_denselayer1_layers_norm1_running_var: \"f32[64]\", b__frozen_param1: \"i8[128, 64, 1, 1]\", b__frozen_param2: \"i8[32, 128, 3, 3]\", b_features_denseblock1_denselayer2_layers_norm1_running_mean: \"f32[96]\", b_features_denseblock1_denselayer2_layers_norm1_running_var: \"f32[96]\", b__frozen_param3: \"i8[128, 96, 1, 1]\", b__frozen_param4: \"i8[32, 128, 3, 3]\", b_features_denseblock1_denselayer3_layers_norm1_running_mean: \"f32[128]\", b_features_denseblock1_denselayer3_layers_norm1_running_var: \"f32[128]\", b__frozen_param5: \"i8[128, 128, 1, 1]\", b__frozen_param6: \"i8[32, 128, 3, 3]\", b_features_denseblock1_denselayer4_layers_norm1_running_mean: \"f32[160]\", b_features_denseblock1_denselayer4_layers_norm1_running_var: \"f32[160]\", b__frozen_param7: \"i8[128, 160, 1, 1]\", b__frozen_param8: \"i8[32, 128, 3, 3]\", b_features_denseblock1_denselayer5_layers_norm1_running_mean: \"f32[192]\", b_features_denseblock1_denselayer5_layers_norm1_running_var: \"f32[192]\", b__frozen_param9: \"i8[128, 192, 1, 1]\", b__frozen_param10: \"i8[32, 128, 3, 3]\", b_features_denseblock1_denselayer6_layers_norm1_running_mean: \"f32[224]\", b_features_denseblock1_denselayer6_layers_norm1_running_var: \"f32[224]\", b__frozen_param11: \"i8[128, 224, 1, 1]\", b__frozen_param12: \"i8[32, 128, 3, 3]\", b_features_transition1_norm_running_mean: \"f32[256]\", b_features_transition1_norm_running_var: \"f32[256]\", b__frozen_param13: \"i8[128, 256, 1, 1]\", b_features_denseblock2_denselayer1_layers_norm1_running_mean: \"f32[128]\", b_features_denseblock2_denselayer1_layers_norm1_running_var: \"f32[128]\", b__frozen_param14: \"i8[128, 128, 1, 1]\", b__frozen_param15: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer2_layers_norm1_running_mean: \"f32[160]\", b_features_denseblock2_denselayer2_layers_norm1_running_var: \"f32[160]\", b__frozen_param16: \"i8[128, 160, 1, 1]\", b__frozen_param17: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer3_layers_norm1_running_mean: \"f32[192]\", b_features_denseblock2_denselayer3_layers_norm1_running_var: \"f32[192]\", b__frozen_param18: \"i8[128, 192, 1, 1]\", b__frozen_param19: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer4_layers_norm1_running_mean: \"f32[224]\", b_features_denseblock2_denselayer4_layers_norm1_running_var: \"f32[224]\", b__frozen_param20: \"i8[128, 224, 1, 1]\", b__frozen_param21: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer5_layers_norm1_running_mean: \"f32[256]\", b_features_denseblock2_denselayer5_layers_norm1_running_var: \"f32[256]\", b__frozen_param22: \"i8[128, 256, 1, 1]\", b__frozen_param23: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer6_layers_norm1_running_mean: \"f32[288]\", b_features_denseblock2_denselayer6_layers_norm1_running_var: \"f32[288]\", b__frozen_param24: \"i8[128, 288, 1, 1]\", b__frozen_param25: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer7_layers_norm1_running_mean: \"f32[320]\", b_features_denseblock2_denselayer7_layers_norm1_running_var: \"f32[320]\", b__frozen_param26: \"i8[128, 320, 1, 1]\", b__frozen_param27: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer8_layers_norm1_running_mean: \"f32[352]\", b_features_denseblock2_denselayer8_layers_norm1_running_var: \"f32[352]\", b__frozen_param28: \"i8[128, 352, 1, 1]\", b__frozen_param29: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer9_layers_norm1_running_mean: \"f32[384]\", b_features_denseblock2_denselayer9_layers_norm1_running_var: \"f32[384]\", b__frozen_param30: \"i8[128, 384, 1, 1]\", b__frozen_param31: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer10_layers_norm1_running_mean: \"f32[416]\", b_features_denseblock2_denselayer10_layers_norm1_running_var: \"f32[416]\", b__frozen_param32: \"i8[128, 416, 1, 1]\", b__frozen_param33: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer11_layers_norm1_running_mean: \"f32[448]\", b_features_denseblock2_denselayer11_layers_norm1_running_var: \"f32[448]\", b__frozen_param34: \"i8[128, 448, 1, 1]\", b__frozen_param35: \"i8[32, 128, 3, 3]\", b_features_denseblock2_denselayer12_layers_norm1_running_mean: \"f32[480]\", b_features_denseblock2_denselayer12_layers_norm1_running_var: \"f32[480]\", b__frozen_param36: \"i8[128, 480, 1, 1]\", b__frozen_param37: \"i8[32, 128, 3, 3]\", b_features_transition2_norm_running_mean: \"f32[512]\", b_features_transition2_norm_running_var: \"f32[512]\", b__frozen_param38: \"i8[256, 512, 1, 1]\", b_features_denseblock3_denselayer1_layers_norm1_running_mean: \"f32[256]\", b_features_denseblock3_denselayer1_layers_norm1_running_var: \"f32[256]\", b__frozen_param39: \"i8[128, 256, 1, 1]\", b__frozen_param40: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer2_layers_norm1_running_mean: \"f32[288]\", b_features_denseblock3_denselayer2_layers_norm1_running_var: \"f32[288]\", b__frozen_param41: \"i8[128, 288, 1, 1]\", b__frozen_param42: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer3_layers_norm1_running_mean: \"f32[320]\", b_features_denseblock3_denselayer3_layers_norm1_running_var: \"f32[320]\", b__frozen_param43: \"i8[128, 320, 1, 1]\", b__frozen_param44: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer4_layers_norm1_running_mean: \"f32[352]\", b_features_denseblock3_denselayer4_layers_norm1_running_var: \"f32[352]\", b__frozen_param45: \"i8[128, 352, 1, 1]\", b__frozen_param46: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer5_layers_norm1_running_mean: \"f32[384]\", b_features_denseblock3_denselayer5_layers_norm1_running_var: \"f32[384]\", b__frozen_param47: \"i8[128, 384, 1, 1]\", b__frozen_param48: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer6_layers_norm1_running_mean: \"f32[416]\", b_features_denseblock3_denselayer6_layers_norm1_running_var: \"f32[416]\", b__frozen_param49: \"i8[128, 416, 1, 1]\", b__frozen_param50: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer7_layers_norm1_running_mean: \"f32[448]\", b_features_denseblock3_denselayer7_layers_norm1_running_var: \"f32[448]\", b__frozen_param51: \"i8[128, 448, 1, 1]\", b__frozen_param52: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer8_layers_norm1_running_mean: \"f32[480]\", b_features_denseblock3_denselayer8_layers_norm1_running_var: \"f32[480]\", b__frozen_param53: \"i8[128, 480, 1, 1]\", b__frozen_param54: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer9_layers_norm1_running_mean: \"f32[512]\", b_features_denseblock3_denselayer9_layers_norm1_running_var: \"f32[512]\", b__frozen_param55: \"i8[128, 512, 1, 1]\", b__frozen_param56: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer10_layers_norm1_running_mean: \"f32[544]\", b_features_denseblock3_denselayer10_layers_norm1_running_var: \"f32[544]\", b__frozen_param57: \"i8[128, 544, 1, 1]\", b__frozen_param58: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer11_layers_norm1_running_mean: \"f32[576]\", b_features_denseblock3_denselayer11_layers_norm1_running_var: \"f32[576]\", b__frozen_param59: \"i8[128, 576, 1, 1]\", b__frozen_param60: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer12_layers_norm1_running_mean: \"f32[608]\", b_features_denseblock3_denselayer12_layers_norm1_running_var: \"f32[608]\", b__frozen_param61: \"i8[128, 608, 1, 1]\", b__frozen_param62: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer13_layers_norm1_running_mean: \"f32[640]\", b_features_denseblock3_denselayer13_layers_norm1_running_var: \"f32[640]\", b__frozen_param63: \"i8[128, 640, 1, 1]\", b__frozen_param64: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer14_layers_norm1_running_mean: \"f32[672]\", b_features_denseblock3_denselayer14_layers_norm1_running_var: \"f32[672]\", b__frozen_param65: \"i8[128, 672, 1, 1]\", b__frozen_param66: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer15_layers_norm1_running_mean: \"f32[704]\", b_features_denseblock3_denselayer15_layers_norm1_running_var: \"f32[704]\", b__frozen_param67: \"i8[128, 704, 1, 1]\", b__frozen_param68: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer16_layers_norm1_running_mean: \"f32[736]\", b_features_denseblock3_denselayer16_layers_norm1_running_var: \"f32[736]\", b__frozen_param69: \"i8[128, 736, 1, 1]\", b__frozen_param70: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer17_layers_norm1_running_mean: \"f32[768]\", b_features_denseblock3_denselayer17_layers_norm1_running_var: \"f32[768]\", b__frozen_param71: \"i8[128, 768, 1, 1]\", b__frozen_param72: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer18_layers_norm1_running_mean: \"f32[800]\", b_features_denseblock3_denselayer18_layers_norm1_running_var: \"f32[800]\", b__frozen_param73: \"i8[128, 800, 1, 1]\", b__frozen_param74: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer19_layers_norm1_running_mean: \"f32[832]\", b_features_denseblock3_denselayer19_layers_norm1_running_var: \"f32[832]\", b__frozen_param75: \"i8[128, 832, 1, 1]\", b__frozen_param76: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer20_layers_norm1_running_mean: \"f32[864]\", b_features_denseblock3_denselayer20_layers_norm1_running_var: \"f32[864]\", b__frozen_param77: \"i8[128, 864, 1, 1]\", b__frozen_param78: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer21_layers_norm1_running_mean: \"f32[896]\", b_features_denseblock3_denselayer21_layers_norm1_running_var: \"f32[896]\", b__frozen_param79: \"i8[128, 896, 1, 1]\", b__frozen_param80: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer22_layers_norm1_running_mean: \"f32[928]\", b_features_denseblock3_denselayer22_layers_norm1_running_var: \"f32[928]\", b__frozen_param81: \"i8[128, 928, 1, 1]\", b__frozen_param82: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer23_layers_norm1_running_mean: \"f32[960]\", b_features_denseblock3_denselayer23_layers_norm1_running_var: \"f32[960]\", b__frozen_param83: \"i8[128, 960, 1, 1]\", b__frozen_param84: \"i8[32, 128, 3, 3]\", b_features_denseblock3_denselayer24_layers_norm1_running_mean: \"f32[992]\", b_features_denseblock3_denselayer24_layers_norm1_running_var: \"f32[992]\", b__frozen_param85: \"i8[128, 992, 1, 1]\", b__frozen_param86: \"i8[32, 128, 3, 3]\", b_features_transition3_norm_running_mean: \"f32[1024]\", b_features_transition3_norm_running_var: \"f32[1024]\", b__frozen_param87: \"i8[512, 1024, 1, 1]\", b_features_denseblock4_denselayer1_layers_norm1_running_mean: \"f32[512]\", b_features_denseblock4_denselayer1_layers_norm1_running_var: \"f32[512]\", b__frozen_param88: \"i8[128, 512, 1, 1]\", b__frozen_param89: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer2_layers_norm1_running_mean: \"f32[544]\", b_features_denseblock4_denselayer2_layers_norm1_running_var: \"f32[544]\", b__frozen_param90: \"i8[128, 544, 1, 1]\", b__frozen_param91: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer3_layers_norm1_running_mean: \"f32[576]\", b_features_denseblock4_denselayer3_layers_norm1_running_var: \"f32[576]\", b__frozen_param92: \"i8[128, 576, 1, 1]\", b__frozen_param93: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer4_layers_norm1_running_mean: \"f32[608]\", b_features_denseblock4_denselayer4_layers_norm1_running_var: \"f32[608]\", b__frozen_param94: \"i8[128, 608, 1, 1]\", b__frozen_param95: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer5_layers_norm1_running_mean: \"f32[640]\", b_features_denseblock4_denselayer5_layers_norm1_running_var: \"f32[640]\", b__frozen_param96: \"i8[128, 640, 1, 1]\", b__frozen_param97: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer6_layers_norm1_running_mean: \"f32[672]\", b_features_denseblock4_denselayer6_layers_norm1_running_var: \"f32[672]\", b__frozen_param98: \"i8[128, 672, 1, 1]\", b__frozen_param99: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer7_layers_norm1_running_mean: \"f32[704]\", b_features_denseblock4_denselayer7_layers_norm1_running_var: \"f32[704]\", b__frozen_param100: \"i8[128, 704, 1, 1]\", b__frozen_param101: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer8_layers_norm1_running_mean: \"f32[736]\", b_features_denseblock4_denselayer8_layers_norm1_running_var: \"f32[736]\", b__frozen_param102: \"i8[128, 736, 1, 1]\", b__frozen_param103: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer9_layers_norm1_running_mean: \"f32[768]\", b_features_denseblock4_denselayer9_layers_norm1_running_var: \"f32[768]\", b__frozen_param104: \"i8[128, 768, 1, 1]\", b__frozen_param105: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer10_layers_norm1_running_mean: \"f32[800]\", b_features_denseblock4_denselayer10_layers_norm1_running_var: \"f32[800]\", b__frozen_param106: \"i8[128, 800, 1, 1]\", b__frozen_param107: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer11_layers_norm1_running_mean: \"f32[832]\", b_features_denseblock4_denselayer11_layers_norm1_running_var: \"f32[832]\", b__frozen_param108: \"i8[128, 832, 1, 1]\", b__frozen_param109: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer12_layers_norm1_running_mean: \"f32[864]\", b_features_denseblock4_denselayer12_layers_norm1_running_var: \"f32[864]\", b__frozen_param110: \"i8[128, 864, 1, 1]\", b__frozen_param111: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer13_layers_norm1_running_mean: \"f32[896]\", b_features_denseblock4_denselayer13_layers_norm1_running_var: \"f32[896]\", b__frozen_param112: \"i8[128, 896, 1, 1]\", b__frozen_param113: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer14_layers_norm1_running_mean: \"f32[928]\", b_features_denseblock4_denselayer14_layers_norm1_running_var: \"f32[928]\", b__frozen_param114: \"i8[128, 928, 1, 1]\", b__frozen_param115: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer15_layers_norm1_running_mean: \"f32[960]\", b_features_denseblock4_denselayer15_layers_norm1_running_var: \"f32[960]\", b__frozen_param116: \"i8[128, 960, 1, 1]\", b__frozen_param117: \"i8[32, 128, 3, 3]\", b_features_denseblock4_denselayer16_layers_norm1_running_mean: \"f32[992]\", b_features_denseblock4_denselayer16_layers_norm1_running_var: \"f32[992]\", b__frozen_param118: \"i8[128, 992, 1, 1]\", b__frozen_param119: \"i8[32, 128, 3, 3]\", b_features_norm5_running_mean: \"f32[1024]\", b_features_norm5_running_var: \"f32[1024]\", b__frozen_param120: \"i8[3, 1024]\", x: \"f32[1, 3, 256, 256]\"):\n",
      "             # File: <eval_with_key>.954:7 in forward, code: quantize_per_tensor_default = torch.ops.quantized_decomposed.quantize_per_tensor.default(arg0_1, 0.0309614110738039, 0, -128, 127, torch.int8);  arg0_1 = None\n",
      "            quantize_per_tensor: \"i8[1, 3, 256, 256]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(x, 0.0309614110738039, 0, -128, 127, torch.int8);  x = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            dequantize_per_tensor: \"f32[1, 3, 256, 256]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor, 0.0309614110738039, 0, -128, 127, torch.int8);  quantize_per_tensor = None\n",
      "            dequantize_per_tensor_1: \"f32[64, 3, 7, 7]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param0, 0.01635424979031086, 0, -127, 127, torch.int8);  b__frozen_param0 = None\n",
      "            conv2d: \"f32[1, 64, 128, 128]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor, dequantize_per_tensor_1, p_features_conv0_weight_bias, [2, 2], [3, 3]);  dequantize_per_tensor = dequantize_per_tensor_1 = p_features_conv0_weight_bias = None\n",
      "            relu: \"f32[1, 64, 128, 128]\" = torch.ops.aten.relu.default(conv2d);  conv2d = None\n",
      "            quantize_per_tensor_1: \"i8[1, 64, 128, 128]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu, 0.15412181615829468, -13, -128, 127, torch.int8);  relu = None\n",
      "            dequantize_per_tensor_2: \"f32[1, 64, 128, 128]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_1, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_1 = None\n",
      "            max_pool2d: \"f32[1, 64, 64, 64]\" = torch.ops.aten.max_pool2d.default(dequantize_per_tensor_2, [3, 3], [2, 2], [1, 1]);  dequantize_per_tensor_2 = None\n",
      "            quantize_per_tensor_2: \"i8[1, 64, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(max_pool2d, 0.15412181615829468, -13, -128, 127, torch.int8);  max_pool2d = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:18 in forward, code: dequantize_per_tensor_default_3 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_3: \"f32[1, 64, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_2, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:19 in forward, code: dequantize_per_tensor_default_369 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_3, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_3 = None\n",
      "            dequantize_per_tensor_4: \"f32[1, 64, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_2, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_2 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_3, p_features_denseblock1_denselayer1_layers_norm1_weight, p_features_denseblock1_denselayer1_layers_norm1_bias, b_features_denseblock1_denselayer1_layers_norm1_running_mean, b_features_denseblock1_denselayer1_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_3 = p_features_denseblock1_denselayer1_layers_norm1_weight = p_features_denseblock1_denselayer1_layers_norm1_bias = b_features_denseblock1_denselayer1_layers_norm1_running_mean = b_features_denseblock1_denselayer1_layers_norm1_running_var = None\n",
      "            getitem: \"f32[1, 64, 64, 64]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
      "            relu_1: \"f32[1, 64, 64, 64]\" = torch.ops.aten.relu.default(getitem);  getitem = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:27 in forward, code: quantize_per_tensor_default_4 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__1, 0.14546501636505127, -128, -128, 127, torch.int8);  relu__1 = None\n",
      "            quantize_per_tensor_3: \"i8[1, 64, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_1, 0.14546501636505127, -128, -128, 127, torch.int8);  relu_1 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_5: \"f32[1, 64, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_3, 0.14546501636505127, -128, -128, 127, torch.int8);  quantize_per_tensor_3 = None\n",
      "            dequantize_per_tensor_6: \"f32[128, 64, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param1, 0.011223173700273037, 0, -127, 127, torch.int8);  b__frozen_param1 = None\n",
      "            conv2d_1: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_5, dequantize_per_tensor_6, p_features_denseblock1_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_5 = dequantize_per_tensor_6 = p_features_denseblock1_denselayer1_layers_conv1_weight_bias = None\n",
      "            relu_2: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_1);  conv2d_1 = None\n",
      "            quantize_per_tensor_4: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_2, 0.04576343670487404, -128, -128, 127, torch.int8);  relu_2 = None\n",
      "            dequantize_per_tensor_7: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_4, 0.04576343670487404, -128, -128, 127, torch.int8);  quantize_per_tensor_4 = None\n",
      "            dequantize_per_tensor_8: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param2, 0.003611508058384061, 0, -127, 127, torch.int8);  b__frozen_param2 = None\n",
      "            conv2d_2: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_7, dequantize_per_tensor_8, None, [1, 1], [1, 1]);  dequantize_per_tensor_7 = dequantize_per_tensor_8 = None\n",
      "            quantize_per_tensor_5: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_2, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_2 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:40 in forward, code: dequantize_per_tensor_default_8 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_8, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_8 = None\n",
      "            dequantize_per_tensor_9: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_5, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_5 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat: \"f32[1, 96, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_4, dequantize_per_tensor_9], 1);  dequantize_per_tensor_4 = dequantize_per_tensor_9 = None\n",
      "            quantize_per_tensor_6: \"i8[1, 96, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat, 0.15412181615829468, -13, -128, 127, torch.int8);  cat = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:43 in forward, code: dequantize_per_tensor_default_9 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_10: \"f32[1, 96, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_6, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:44 in forward, code: dequantize_per_tensor_default_370 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_9, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_9 = None\n",
      "            dequantize_per_tensor_11: \"f32[1, 96, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_6, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_6 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_10, p_features_denseblock1_denselayer2_layers_norm1_weight, p_features_denseblock1_denselayer2_layers_norm1_bias, b_features_denseblock1_denselayer2_layers_norm1_running_mean, b_features_denseblock1_denselayer2_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_10 = p_features_denseblock1_denselayer2_layers_norm1_weight = p_features_denseblock1_denselayer2_layers_norm1_bias = b_features_denseblock1_denselayer2_layers_norm1_running_mean = b_features_denseblock1_denselayer2_layers_norm1_running_var = None\n",
      "            getitem_3: \"f32[1, 96, 64, 64]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
      "            relu_3: \"f32[1, 96, 64, 64]\" = torch.ops.aten.relu.default(getitem_3);  getitem_3 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:52 in forward, code: quantize_per_tensor_default_10 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__3, 0.3290613889694214, -128, -128, 127, torch.int8);  relu__3 = None\n",
      "            quantize_per_tensor_7: \"i8[1, 96, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_3, 0.3290613889694214, -128, -128, 127, torch.int8);  relu_3 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_12: \"f32[1, 96, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_7, 0.3290613889694214, -128, -128, 127, torch.int8);  quantize_per_tensor_7 = None\n",
      "            dequantize_per_tensor_13: \"f32[128, 96, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param3, 0.007783120032399893, 0, -127, 127, torch.int8);  b__frozen_param3 = None\n",
      "            conv2d_3: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_12, dequantize_per_tensor_13, p_features_denseblock1_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_12 = dequantize_per_tensor_13 = p_features_denseblock1_denselayer2_layers_conv1_weight_bias = None\n",
      "            relu_4: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_3);  conv2d_3 = None\n",
      "            quantize_per_tensor_8: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_4, 0.11768194288015366, -128, -128, 127, torch.int8);  relu_4 = None\n",
      "            dequantize_per_tensor_14: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_8, 0.11768194288015366, -128, -128, 127, torch.int8);  quantize_per_tensor_8 = None\n",
      "            dequantize_per_tensor_15: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param4, 0.0034869362134486437, 0, -127, 127, torch.int8);  b__frozen_param4 = None\n",
      "            conv2d_4: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_14, dequantize_per_tensor_15, None, [1, 1], [1, 1]);  dequantize_per_tensor_14 = dequantize_per_tensor_15 = None\n",
      "            quantize_per_tensor_9: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_4, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_4 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:65 in forward, code: dequantize_per_tensor_default_14 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_14, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_14 = None\n",
      "            dequantize_per_tensor_16: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_9, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_9 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_1: \"f32[1, 128, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_11, dequantize_per_tensor_16], 1);  dequantize_per_tensor_11 = dequantize_per_tensor_16 = None\n",
      "            quantize_per_tensor_10: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_1, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_1 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:68 in forward, code: dequantize_per_tensor_default_15 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_17: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_10, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:69 in forward, code: dequantize_per_tensor_default_371 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_15, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_15 = None\n",
      "            dequantize_per_tensor_18: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_10, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_10 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_17, p_features_denseblock1_denselayer3_layers_norm1_weight, p_features_denseblock1_denselayer3_layers_norm1_bias, b_features_denseblock1_denselayer3_layers_norm1_running_mean, b_features_denseblock1_denselayer3_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_17 = p_features_denseblock1_denselayer3_layers_norm1_weight = p_features_denseblock1_denselayer3_layers_norm1_bias = b_features_denseblock1_denselayer3_layers_norm1_running_mean = b_features_denseblock1_denselayer3_layers_norm1_running_var = None\n",
      "            getitem_6: \"f32[1, 128, 64, 64]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
      "            relu_5: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(getitem_6);  getitem_6 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:77 in forward, code: quantize_per_tensor_default_16 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__5, 0.10120505094528198, -128, -128, 127, torch.int8);  relu__5 = None\n",
      "            quantize_per_tensor_11: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_5, 0.10120505094528198, -128, -128, 127, torch.int8);  relu_5 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_19: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_11, 0.10120505094528198, -128, -128, 127, torch.int8);  quantize_per_tensor_11 = None\n",
      "            dequantize_per_tensor_20: \"f32[128, 128, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param5, 0.007038871757686138, 0, -127, 127, torch.int8);  b__frozen_param5 = None\n",
      "            conv2d_5: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_19, dequantize_per_tensor_20, p_features_denseblock1_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_19 = dequantize_per_tensor_20 = p_features_denseblock1_denselayer3_layers_conv1_weight_bias = None\n",
      "            relu_6: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_5);  conv2d_5 = None\n",
      "            quantize_per_tensor_12: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_6, 0.027735194191336632, -128, -128, 127, torch.int8);  relu_6 = None\n",
      "            dequantize_per_tensor_21: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_12, 0.027735194191336632, -128, -128, 127, torch.int8);  quantize_per_tensor_12 = None\n",
      "            dequantize_per_tensor_22: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param6, 0.002163182944059372, 0, -127, 127, torch.int8);  b__frozen_param6 = None\n",
      "            conv2d_6: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_21, dequantize_per_tensor_22, None, [1, 1], [1, 1]);  dequantize_per_tensor_21 = dequantize_per_tensor_22 = None\n",
      "            quantize_per_tensor_13: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_6, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_6 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:90 in forward, code: dequantize_per_tensor_default_20 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_20, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_20 = None\n",
      "            dequantize_per_tensor_23: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_13, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_13 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_2: \"f32[1, 160, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_18, dequantize_per_tensor_23], 1);  dequantize_per_tensor_18 = dequantize_per_tensor_23 = None\n",
      "            quantize_per_tensor_14: \"i8[1, 160, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_2, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_2 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:93 in forward, code: dequantize_per_tensor_default_21 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_24: \"f32[1, 160, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_14, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:94 in forward, code: dequantize_per_tensor_default_372 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_21, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_21 = None\n",
      "            dequantize_per_tensor_25: \"f32[1, 160, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_14, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_14 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_24, p_features_denseblock1_denselayer4_layers_norm1_weight, p_features_denseblock1_denselayer4_layers_norm1_bias, b_features_denseblock1_denselayer4_layers_norm1_running_mean, b_features_denseblock1_denselayer4_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_24 = p_features_denseblock1_denselayer4_layers_norm1_weight = p_features_denseblock1_denselayer4_layers_norm1_bias = b_features_denseblock1_denselayer4_layers_norm1_running_mean = b_features_denseblock1_denselayer4_layers_norm1_running_var = None\n",
      "            getitem_9: \"f32[1, 160, 64, 64]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
      "            relu_7: \"f32[1, 160, 64, 64]\" = torch.ops.aten.relu.default(getitem_9);  getitem_9 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:102 in forward, code: quantize_per_tensor_default_22 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__7, 0.03223251551389694, -128, -128, 127, torch.int8);  relu__7 = None\n",
      "            quantize_per_tensor_15: \"i8[1, 160, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_7, 0.03223251551389694, -128, -128, 127, torch.int8);  relu_7 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_26: \"f32[1, 160, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_15, 0.03223251551389694, -128, -128, 127, torch.int8);  quantize_per_tensor_15 = None\n",
      "            dequantize_per_tensor_27: \"f32[128, 160, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param7, 0.006927610840648413, 0, -127, 127, torch.int8);  b__frozen_param7 = None\n",
      "            conv2d_7: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_26, dequantize_per_tensor_27, p_features_denseblock1_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_26 = dequantize_per_tensor_27 = p_features_denseblock1_denselayer4_layers_conv1_weight_bias = None\n",
      "            relu_8: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_7);  conv2d_7 = None\n",
      "            quantize_per_tensor_16: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_8, 0.0137783233076334, -128, -128, 127, torch.int8);  relu_8 = None\n",
      "            dequantize_per_tensor_28: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_16, 0.0137783233076334, -128, -128, 127, torch.int8);  quantize_per_tensor_16 = None\n",
      "            dequantize_per_tensor_29: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param8, 0.0016751647926867008, 0, -127, 127, torch.int8);  b__frozen_param8 = None\n",
      "            conv2d_8: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_28, dequantize_per_tensor_29, None, [1, 1], [1, 1]);  dequantize_per_tensor_28 = dequantize_per_tensor_29 = None\n",
      "            quantize_per_tensor_17: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_8, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_8 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:115 in forward, code: dequantize_per_tensor_default_26 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_26, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_26 = None\n",
      "            dequantize_per_tensor_30: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_17, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_17 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_3: \"f32[1, 192, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_25, dequantize_per_tensor_30], 1);  dequantize_per_tensor_25 = dequantize_per_tensor_30 = None\n",
      "            quantize_per_tensor_18: \"i8[1, 192, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_3, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_3 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:118 in forward, code: dequantize_per_tensor_default_27 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_31: \"f32[1, 192, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_18, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:119 in forward, code: dequantize_per_tensor_default_373 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_27, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_27 = None\n",
      "            dequantize_per_tensor_32: \"f32[1, 192, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_18, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_18 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_31, p_features_denseblock1_denselayer5_layers_norm1_weight, p_features_denseblock1_denselayer5_layers_norm1_bias, b_features_denseblock1_denselayer5_layers_norm1_running_mean, b_features_denseblock1_denselayer5_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_31 = p_features_denseblock1_denselayer5_layers_norm1_weight = p_features_denseblock1_denselayer5_layers_norm1_bias = b_features_denseblock1_denselayer5_layers_norm1_running_mean = b_features_denseblock1_denselayer5_layers_norm1_running_var = None\n",
      "            getitem_12: \"f32[1, 192, 64, 64]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
      "            relu_9: \"f32[1, 192, 64, 64]\" = torch.ops.aten.relu.default(getitem_12);  getitem_12 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:127 in forward, code: quantize_per_tensor_default_28 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__9, 0.05981072410941124, -128, -128, 127, torch.int8);  relu__9 = None\n",
      "            quantize_per_tensor_19: \"i8[1, 192, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_9, 0.05981072410941124, -128, -128, 127, torch.int8);  relu_9 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_33: \"f32[1, 192, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_19, 0.05981072410941124, -128, -128, 127, torch.int8);  quantize_per_tensor_19 = None\n",
      "            dequantize_per_tensor_34: \"f32[128, 192, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param9, 0.010060940869152546, 0, -127, 127, torch.int8);  b__frozen_param9 = None\n",
      "            conv2d_9: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_33, dequantize_per_tensor_34, p_features_denseblock1_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_33 = dequantize_per_tensor_34 = p_features_denseblock1_denselayer5_layers_conv1_weight_bias = None\n",
      "            relu_10: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_9);  conv2d_9 = None\n",
      "            quantize_per_tensor_20: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_10, 0.01713251695036888, -128, -128, 127, torch.int8);  relu_10 = None\n",
      "            dequantize_per_tensor_35: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_20, 0.01713251695036888, -128, -128, 127, torch.int8);  quantize_per_tensor_20 = None\n",
      "            dequantize_per_tensor_36: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param10, 0.0028601507656276226, 0, -127, 127, torch.int8);  b__frozen_param10 = None\n",
      "            conv2d_10: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_35, dequantize_per_tensor_36, None, [1, 1], [1, 1]);  dequantize_per_tensor_35 = dequantize_per_tensor_36 = None\n",
      "            quantize_per_tensor_21: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_10, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_10 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:140 in forward, code: dequantize_per_tensor_default_32 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_32, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_32 = None\n",
      "            dequantize_per_tensor_37: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_21, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_21 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_4: \"f32[1, 224, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_32, dequantize_per_tensor_37], 1);  dequantize_per_tensor_32 = dequantize_per_tensor_37 = None\n",
      "            quantize_per_tensor_22: \"i8[1, 224, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_4, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_4 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:143 in forward, code: dequantize_per_tensor_default_33 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_38: \"f32[1, 224, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_22, 0.15412181615829468, -13, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:144 in forward, code: dequantize_per_tensor_default_374 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_33, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_33 = None\n",
      "            dequantize_per_tensor_39: \"f32[1, 224, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_22, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_22 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_38, p_features_denseblock1_denselayer6_layers_norm1_weight, p_features_denseblock1_denselayer6_layers_norm1_bias, b_features_denseblock1_denselayer6_layers_norm1_running_mean, b_features_denseblock1_denselayer6_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_38 = p_features_denseblock1_denselayer6_layers_norm1_weight = p_features_denseblock1_denselayer6_layers_norm1_bias = b_features_denseblock1_denselayer6_layers_norm1_running_mean = b_features_denseblock1_denselayer6_layers_norm1_running_var = None\n",
      "            getitem_15: \"f32[1, 224, 64, 64]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
      "            relu_11: \"f32[1, 224, 64, 64]\" = torch.ops.aten.relu.default(getitem_15);  getitem_15 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:152 in forward, code: quantize_per_tensor_default_34 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__11, 0.02181347645819187, -128, -128, 127, torch.int8);  relu__11 = None\n",
      "            quantize_per_tensor_23: \"i8[1, 224, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_11, 0.02181347645819187, -128, -128, 127, torch.int8);  relu_11 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_40: \"f32[1, 224, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_23, 0.02181347645819187, -128, -128, 127, torch.int8);  quantize_per_tensor_23 = None\n",
      "            dequantize_per_tensor_41: \"f32[128, 224, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param11, 0.014067327603697777, 0, -127, 127, torch.int8);  b__frozen_param11 = None\n",
      "            conv2d_11: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_40, dequantize_per_tensor_41, p_features_denseblock1_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_40 = dequantize_per_tensor_41 = p_features_denseblock1_denselayer6_layers_conv1_weight_bias = None\n",
      "            relu_12: \"f32[1, 128, 64, 64]\" = torch.ops.aten.relu.default(conv2d_11);  conv2d_11 = None\n",
      "            quantize_per_tensor_24: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_12, 0.012534106150269508, -128, -128, 127, torch.int8);  relu_12 = None\n",
      "            dequantize_per_tensor_42: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_24, 0.012534106150269508, -128, -128, 127, torch.int8);  quantize_per_tensor_24 = None\n",
      "            dequantize_per_tensor_43: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param12, 0.0021891833748668432, 0, -127, 127, torch.int8);  b__frozen_param12 = None\n",
      "            conv2d_12: \"f32[1, 32, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_42, dequantize_per_tensor_43, None, [1, 1], [1, 1]);  dequantize_per_tensor_42 = dequantize_per_tensor_43 = None\n",
      "            quantize_per_tensor_25: \"i8[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_12, 0.15412181615829468, -13, -128, 127, torch.int8);  conv2d_12 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:165 in forward, code: dequantize_per_tensor_default_38 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_38, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_38 = None\n",
      "            dequantize_per_tensor_44: \"f32[1, 32, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_25, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_25 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_5: \"f32[1, 256, 64, 64]\" = torch.ops.aten.cat.default([dequantize_per_tensor_39, dequantize_per_tensor_44], 1);  dequantize_per_tensor_39 = dequantize_per_tensor_44 = None\n",
      "            quantize_per_tensor_26: \"i8[1, 256, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_5, 0.15412181615829468, -13, -128, 127, torch.int8);  cat_5 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:168 in forward, code: dequantize_per_tensor_default_39 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_39, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_default_39 = None\n",
      "            dequantize_per_tensor_45: \"f32[1, 256, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_26, 0.15412181615829468, -13, -128, 127, torch.int8);  quantize_per_tensor_26 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_45, p_features_transition1_norm_weight, p_features_transition1_norm_bias, b_features_transition1_norm_running_mean, b_features_transition1_norm_running_var, 0.1, 1e-05);  dequantize_per_tensor_45 = p_features_transition1_norm_weight = p_features_transition1_norm_bias = b_features_transition1_norm_running_mean = b_features_transition1_norm_running_var = None\n",
      "            getitem_18: \"f32[1, 256, 64, 64]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
      "            relu_13: \"f32[1, 256, 64, 64]\" = torch.ops.aten.relu.default(getitem_18);  getitem_18 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:176 in forward, code: quantize_per_tensor_default_40 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__13, 0.11582395434379578, -128, -128, 127, torch.int8);  relu__13 = None\n",
      "            quantize_per_tensor_27: \"i8[1, 256, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_13, 0.11582395434379578, -128, -128, 127, torch.int8);  relu_13 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            dequantize_per_tensor_46: \"f32[1, 256, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_27, 0.11582395434379578, -128, -128, 127, torch.int8);  quantize_per_tensor_27 = None\n",
      "            dequantize_per_tensor_47: \"f32[128, 256, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param13, 0.007403446361422539, 0, -127, 127, torch.int8);  b__frozen_param13 = None\n",
      "            conv2d_13: \"f32[1, 128, 64, 64]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_46, dequantize_per_tensor_47);  dequantize_per_tensor_46 = dequantize_per_tensor_47 = None\n",
      "            quantize_per_tensor_28: \"i8[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_13, 0.09962928295135498, 14, -128, 127, torch.int8);  conv2d_13 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:182 in forward, code: dequantize_per_tensor_default_42 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_42, 0.09962928295135498, 14, -128, 127, torch.int8);  quantize_per_tensor_default_42 = None\n",
      "            dequantize_per_tensor_48: \"f32[1, 128, 64, 64]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_28, 0.09962928295135498, 14, -128, 127, torch.int8);  quantize_per_tensor_28 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            avg_pool2d: \"f32[1, 128, 32, 32]\" = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_48, [2, 2], [2, 2]);  dequantize_per_tensor_48 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:184 in forward, code: quantize_per_tensor_default_43 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            quantize_per_tensor_29: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:185 in forward, code: dequantize_per_tensor_default_43 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_43, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_43 = None\n",
      "            dequantize_per_tensor_49: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_29, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_29 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d, p_features_denseblock2_denselayer1_layers_norm1_weight, p_features_denseblock2_denselayer1_layers_norm1_bias, b_features_denseblock2_denselayer1_layers_norm1_running_mean, b_features_denseblock2_denselayer1_layers_norm1_running_var, 0.1, 1e-05);  avg_pool2d = p_features_denseblock2_denselayer1_layers_norm1_weight = p_features_denseblock2_denselayer1_layers_norm1_bias = b_features_denseblock2_denselayer1_layers_norm1_running_mean = b_features_denseblock2_denselayer1_layers_norm1_running_var = None\n",
      "            getitem_21: \"f32[1, 128, 32, 32]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
      "            relu_14: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(getitem_21);  getitem_21 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:193 in forward, code: quantize_per_tensor_default_44 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__14, 0.028628453612327576, -128, -128, 127, torch.int8);  relu__14 = None\n",
      "            quantize_per_tensor_30: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_14, 0.028628453612327576, -128, -128, 127, torch.int8);  relu_14 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_50: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_30, 0.028628453612327576, -128, -128, 127, torch.int8);  quantize_per_tensor_30 = None\n",
      "            dequantize_per_tensor_51: \"f32[128, 128, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param14, 0.007619316689670086, 0, -127, 127, torch.int8);  b__frozen_param14 = None\n",
      "            conv2d_14: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_50, dequantize_per_tensor_51, p_features_denseblock2_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_50 = dequantize_per_tensor_51 = p_features_denseblock2_denselayer1_layers_conv1_weight_bias = None\n",
      "            relu_15: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_14);  conv2d_14 = None\n",
      "            quantize_per_tensor_31: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_15, 0.015536557883024216, -128, -128, 127, torch.int8);  relu_15 = None\n",
      "            dequantize_per_tensor_52: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_31, 0.015536557883024216, -128, -128, 127, torch.int8);  quantize_per_tensor_31 = None\n",
      "            dequantize_per_tensor_53: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param15, 0.0031634012702852488, 0, -127, 127, torch.int8);  b__frozen_param15 = None\n",
      "            conv2d_15: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_52, dequantize_per_tensor_53, None, [1, 1], [1, 1]);  dequantize_per_tensor_52 = dequantize_per_tensor_53 = None\n",
      "            quantize_per_tensor_32: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_15, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_15 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:206 in forward, code: dequantize_per_tensor_default_48 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_48, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_48 = None\n",
      "            dequantize_per_tensor_54: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_32, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_32 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_6: \"f32[1, 160, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_49, dequantize_per_tensor_54], 1);  dequantize_per_tensor_49 = dequantize_per_tensor_54 = None\n",
      "            quantize_per_tensor_33: \"i8[1, 160, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_6, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_6 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:209 in forward, code: dequantize_per_tensor_default_49 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_55: \"f32[1, 160, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_33, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:210 in forward, code: dequantize_per_tensor_default_375 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_49, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_49 = None\n",
      "            dequantize_per_tensor_56: \"f32[1, 160, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_33, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_33 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_55, p_features_denseblock2_denselayer2_layers_norm1_weight, p_features_denseblock2_denselayer2_layers_norm1_bias, b_features_denseblock2_denselayer2_layers_norm1_running_mean, b_features_denseblock2_denselayer2_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_55 = p_features_denseblock2_denselayer2_layers_norm1_weight = p_features_denseblock2_denselayer2_layers_norm1_bias = b_features_denseblock2_denselayer2_layers_norm1_running_mean = b_features_denseblock2_denselayer2_layers_norm1_running_var = None\n",
      "            getitem_24: \"f32[1, 160, 32, 32]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
      "            relu_16: \"f32[1, 160, 32, 32]\" = torch.ops.aten.relu.default(getitem_24);  getitem_24 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:218 in forward, code: quantize_per_tensor_default_50 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__16, 0.03705156221985817, -128, -128, 127, torch.int8);  relu__16 = None\n",
      "            quantize_per_tensor_34: \"i8[1, 160, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_16, 0.03705156221985817, -128, -128, 127, torch.int8);  relu_16 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_57: \"f32[1, 160, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_34, 0.03705156221985817, -128, -128, 127, torch.int8);  quantize_per_tensor_34 = None\n",
      "            dequantize_per_tensor_58: \"f32[128, 160, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param16, 0.007260892074555159, 0, -127, 127, torch.int8);  b__frozen_param16 = None\n",
      "            conv2d_16: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_57, dequantize_per_tensor_58, p_features_denseblock2_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_57 = dequantize_per_tensor_58 = p_features_denseblock2_denselayer2_layers_conv1_weight_bias = None\n",
      "            relu_17: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_16);  conv2d_16 = None\n",
      "            quantize_per_tensor_35: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_17, 0.01951760984957218, -128, -128, 127, torch.int8);  relu_17 = None\n",
      "            dequantize_per_tensor_59: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_35, 0.01951760984957218, -128, -128, 127, torch.int8);  quantize_per_tensor_35 = None\n",
      "            dequantize_per_tensor_60: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param17, 0.0017099434044212103, 0, -127, 127, torch.int8);  b__frozen_param17 = None\n",
      "            conv2d_17: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_59, dequantize_per_tensor_60, None, [1, 1], [1, 1]);  dequantize_per_tensor_59 = dequantize_per_tensor_60 = None\n",
      "            quantize_per_tensor_36: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_17, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_17 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:231 in forward, code: dequantize_per_tensor_default_54 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_54, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_54 = None\n",
      "            dequantize_per_tensor_61: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_36, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_36 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_7: \"f32[1, 192, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_56, dequantize_per_tensor_61], 1);  dequantize_per_tensor_56 = dequantize_per_tensor_61 = None\n",
      "            quantize_per_tensor_37: \"i8[1, 192, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_7, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_7 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:234 in forward, code: dequantize_per_tensor_default_55 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_62: \"f32[1, 192, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_37, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:235 in forward, code: dequantize_per_tensor_default_376 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_55, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_55 = None\n",
      "            dequantize_per_tensor_63: \"f32[1, 192, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_37, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_37 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_62, p_features_denseblock2_denselayer3_layers_norm1_weight, p_features_denseblock2_denselayer3_layers_norm1_bias, b_features_denseblock2_denselayer3_layers_norm1_running_mean, b_features_denseblock2_denselayer3_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_62 = p_features_denseblock2_denselayer3_layers_norm1_weight = p_features_denseblock2_denselayer3_layers_norm1_bias = b_features_denseblock2_denselayer3_layers_norm1_running_mean = b_features_denseblock2_denselayer3_layers_norm1_running_var = None\n",
      "            getitem_27: \"f32[1, 192, 32, 32]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
      "            relu_18: \"f32[1, 192, 32, 32]\" = torch.ops.aten.relu.default(getitem_27);  getitem_27 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:243 in forward, code: quantize_per_tensor_default_56 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__18, 0.018638765439391136, -128, -128, 127, torch.int8);  relu__18 = None\n",
      "            quantize_per_tensor_38: \"i8[1, 192, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_18, 0.018638765439391136, -128, -128, 127, torch.int8);  relu_18 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_64: \"f32[1, 192, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_38, 0.018638765439391136, -128, -128, 127, torch.int8);  quantize_per_tensor_38 = None\n",
      "            dequantize_per_tensor_65: \"f32[128, 192, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param18, 0.007643700111657381, 0, -127, 127, torch.int8);  b__frozen_param18 = None\n",
      "            conv2d_18: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_64, dequantize_per_tensor_65, p_features_denseblock2_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_64 = dequantize_per_tensor_65 = p_features_denseblock2_denselayer3_layers_conv1_weight_bias = None\n",
      "            relu_19: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_18);  conv2d_18 = None\n",
      "            quantize_per_tensor_39: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_19, 0.009119376540184021, -128, -128, 127, torch.int8);  relu_19 = None\n",
      "            dequantize_per_tensor_66: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_39, 0.009119376540184021, -128, -128, 127, torch.int8);  quantize_per_tensor_39 = None\n",
      "            dequantize_per_tensor_67: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param19, 0.0019441406475380063, 0, -127, 127, torch.int8);  b__frozen_param19 = None\n",
      "            conv2d_19: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_66, dequantize_per_tensor_67, None, [1, 1], [1, 1]);  dequantize_per_tensor_66 = dequantize_per_tensor_67 = None\n",
      "            quantize_per_tensor_40: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_19, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_19 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:256 in forward, code: dequantize_per_tensor_default_60 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_60, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_60 = None\n",
      "            dequantize_per_tensor_68: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_40, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_40 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_8: \"f32[1, 224, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_63, dequantize_per_tensor_68], 1);  dequantize_per_tensor_63 = dequantize_per_tensor_68 = None\n",
      "            quantize_per_tensor_41: \"i8[1, 224, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_8, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_8 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:259 in forward, code: dequantize_per_tensor_default_61 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_69: \"f32[1, 224, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_41, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:260 in forward, code: dequantize_per_tensor_default_377 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_61, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_61 = None\n",
      "            dequantize_per_tensor_70: \"f32[1, 224, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_41, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_41 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_69, p_features_denseblock2_denselayer4_layers_norm1_weight, p_features_denseblock2_denselayer4_layers_norm1_bias, b_features_denseblock2_denselayer4_layers_norm1_running_mean, b_features_denseblock2_denselayer4_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_69 = p_features_denseblock2_denselayer4_layers_norm1_weight = p_features_denseblock2_denselayer4_layers_norm1_bias = b_features_denseblock2_denselayer4_layers_norm1_running_mean = b_features_denseblock2_denselayer4_layers_norm1_running_var = None\n",
      "            getitem_30: \"f32[1, 224, 32, 32]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
      "            relu_20: \"f32[1, 224, 32, 32]\" = torch.ops.aten.relu.default(getitem_30);  getitem_30 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:268 in forward, code: quantize_per_tensor_default_62 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__20, 0.029592720791697502, -128, -128, 127, torch.int8);  relu__20 = None\n",
      "            quantize_per_tensor_42: \"i8[1, 224, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_20, 0.029592720791697502, -128, -128, 127, torch.int8);  relu_20 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_71: \"f32[1, 224, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_42, 0.029592720791697502, -128, -128, 127, torch.int8);  quantize_per_tensor_42 = None\n",
      "            dequantize_per_tensor_72: \"f32[128, 224, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param20, 0.011065496131777763, 0, -127, 127, torch.int8);  b__frozen_param20 = None\n",
      "            conv2d_20: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_71, dequantize_per_tensor_72, p_features_denseblock2_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_71 = dequantize_per_tensor_72 = p_features_denseblock2_denselayer4_layers_conv1_weight_bias = None\n",
      "            relu_21: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_20);  conv2d_20 = None\n",
      "            quantize_per_tensor_43: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_21, 0.023821014910936356, -128, -128, 127, torch.int8);  relu_21 = None\n",
      "            dequantize_per_tensor_73: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_43, 0.023821014910936356, -128, -128, 127, torch.int8);  quantize_per_tensor_43 = None\n",
      "            dequantize_per_tensor_74: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param21, 0.00323011027649045, 0, -127, 127, torch.int8);  b__frozen_param21 = None\n",
      "            conv2d_21: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_73, dequantize_per_tensor_74, None, [1, 1], [1, 1]);  dequantize_per_tensor_73 = dequantize_per_tensor_74 = None\n",
      "            quantize_per_tensor_44: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_21, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_21 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:281 in forward, code: dequantize_per_tensor_default_66 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_66, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_66 = None\n",
      "            dequantize_per_tensor_75: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_44, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_44 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_9: \"f32[1, 256, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_70, dequantize_per_tensor_75], 1);  dequantize_per_tensor_70 = dequantize_per_tensor_75 = None\n",
      "            quantize_per_tensor_45: \"i8[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_9, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_9 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:284 in forward, code: dequantize_per_tensor_default_67 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_76: \"f32[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_45, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:285 in forward, code: dequantize_per_tensor_default_378 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_67, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_67 = None\n",
      "            dequantize_per_tensor_77: \"f32[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_45, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_45 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_76, p_features_denseblock2_denselayer5_layers_norm1_weight, p_features_denseblock2_denselayer5_layers_norm1_bias, b_features_denseblock2_denselayer5_layers_norm1_running_mean, b_features_denseblock2_denselayer5_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_76 = p_features_denseblock2_denselayer5_layers_norm1_weight = p_features_denseblock2_denselayer5_layers_norm1_bias = b_features_denseblock2_denselayer5_layers_norm1_running_mean = b_features_denseblock2_denselayer5_layers_norm1_running_var = None\n",
      "            getitem_33: \"f32[1, 256, 32, 32]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
      "            relu_22: \"f32[1, 256, 32, 32]\" = torch.ops.aten.relu.default(getitem_33);  getitem_33 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:293 in forward, code: quantize_per_tensor_default_68 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__22, 0.013898526318371296, -128, -128, 127, torch.int8);  relu__22 = None\n",
      "            quantize_per_tensor_46: \"i8[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_22, 0.013898526318371296, -128, -128, 127, torch.int8);  relu_22 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_78: \"f32[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_46, 0.013898526318371296, -128, -128, 127, torch.int8);  quantize_per_tensor_46 = None\n",
      "            dequantize_per_tensor_79: \"f32[128, 256, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param22, 0.0064514512196183205, 0, -127, 127, torch.int8);  b__frozen_param22 = None\n",
      "            conv2d_22: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_78, dequantize_per_tensor_79, p_features_denseblock2_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_78 = dequantize_per_tensor_79 = p_features_denseblock2_denselayer5_layers_conv1_weight_bias = None\n",
      "            relu_23: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_22);  conv2d_22 = None\n",
      "            quantize_per_tensor_47: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_23, 0.0094265416264534, -128, -128, 127, torch.int8);  relu_23 = None\n",
      "            dequantize_per_tensor_80: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_47, 0.0094265416264534, -128, -128, 127, torch.int8);  quantize_per_tensor_47 = None\n",
      "            dequantize_per_tensor_81: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param23, 0.0015792256454005837, 0, -127, 127, torch.int8);  b__frozen_param23 = None\n",
      "            conv2d_23: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_80, dequantize_per_tensor_81, None, [1, 1], [1, 1]);  dequantize_per_tensor_80 = dequantize_per_tensor_81 = None\n",
      "            quantize_per_tensor_48: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_23, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_23 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:306 in forward, code: dequantize_per_tensor_default_72 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_72, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_72 = None\n",
      "            dequantize_per_tensor_82: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_48, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_48 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_10: \"f32[1, 288, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_77, dequantize_per_tensor_82], 1);  dequantize_per_tensor_77 = dequantize_per_tensor_82 = None\n",
      "            quantize_per_tensor_49: \"i8[1, 288, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_10, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_10 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:309 in forward, code: dequantize_per_tensor_default_73 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_83: \"f32[1, 288, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_49, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:310 in forward, code: dequantize_per_tensor_default_379 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_73, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_73 = None\n",
      "            dequantize_per_tensor_84: \"f32[1, 288, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_49, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_49 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_83, p_features_denseblock2_denselayer6_layers_norm1_weight, p_features_denseblock2_denselayer6_layers_norm1_bias, b_features_denseblock2_denselayer6_layers_norm1_running_mean, b_features_denseblock2_denselayer6_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_83 = p_features_denseblock2_denselayer6_layers_norm1_weight = p_features_denseblock2_denselayer6_layers_norm1_bias = b_features_denseblock2_denselayer6_layers_norm1_running_mean = b_features_denseblock2_denselayer6_layers_norm1_running_var = None\n",
      "            getitem_36: \"f32[1, 288, 32, 32]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
      "            relu_24: \"f32[1, 288, 32, 32]\" = torch.ops.aten.relu.default(getitem_36);  getitem_36 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:318 in forward, code: quantize_per_tensor_default_74 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__24, 0.025128398090600967, -128, -128, 127, torch.int8);  relu__24 = None\n",
      "            quantize_per_tensor_50: \"i8[1, 288, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_24, 0.025128398090600967, -128, -128, 127, torch.int8);  relu_24 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_85: \"f32[1, 288, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_50, 0.025128398090600967, -128, -128, 127, torch.int8);  quantize_per_tensor_50 = None\n",
      "            dequantize_per_tensor_86: \"f32[128, 288, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param24, 0.007715207524597645, 0, -127, 127, torch.int8);  b__frozen_param24 = None\n",
      "            conv2d_24: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_85, dequantize_per_tensor_86, p_features_denseblock2_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_85 = dequantize_per_tensor_86 = p_features_denseblock2_denselayer6_layers_conv1_weight_bias = None\n",
      "            relu_25: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_24);  conv2d_24 = None\n",
      "            quantize_per_tensor_51: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_25, 0.01569560542702675, -128, -128, 127, torch.int8);  relu_25 = None\n",
      "            dequantize_per_tensor_87: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_51, 0.01569560542702675, -128, -128, 127, torch.int8);  quantize_per_tensor_51 = None\n",
      "            dequantize_per_tensor_88: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param25, 0.003498468780890107, 0, -127, 127, torch.int8);  b__frozen_param25 = None\n",
      "            conv2d_25: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_87, dequantize_per_tensor_88, None, [1, 1], [1, 1]);  dequantize_per_tensor_87 = dequantize_per_tensor_88 = None\n",
      "            quantize_per_tensor_52: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_25, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_25 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:331 in forward, code: dequantize_per_tensor_default_78 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_78, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_78 = None\n",
      "            dequantize_per_tensor_89: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_52, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_52 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_11: \"f32[1, 320, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_84, dequantize_per_tensor_89], 1);  dequantize_per_tensor_84 = dequantize_per_tensor_89 = None\n",
      "            quantize_per_tensor_53: \"i8[1, 320, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_11, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_11 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:334 in forward, code: dequantize_per_tensor_default_79 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_90: \"f32[1, 320, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_53, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:335 in forward, code: dequantize_per_tensor_default_380 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_79, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_79 = None\n",
      "            dequantize_per_tensor_91: \"f32[1, 320, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_53, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_53 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_90, p_features_denseblock2_denselayer7_layers_norm1_weight, p_features_denseblock2_denselayer7_layers_norm1_bias, b_features_denseblock2_denselayer7_layers_norm1_running_mean, b_features_denseblock2_denselayer7_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_90 = p_features_denseblock2_denselayer7_layers_norm1_weight = p_features_denseblock2_denselayer7_layers_norm1_bias = b_features_denseblock2_denselayer7_layers_norm1_running_mean = b_features_denseblock2_denselayer7_layers_norm1_running_var = None\n",
      "            getitem_39: \"f32[1, 320, 32, 32]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
      "            relu_26: \"f32[1, 320, 32, 32]\" = torch.ops.aten.relu.default(getitem_39);  getitem_39 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:343 in forward, code: quantize_per_tensor_default_80 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__26, 0.021912051364779472, -128, -128, 127, torch.int8);  relu__26 = None\n",
      "            quantize_per_tensor_54: \"i8[1, 320, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_26, 0.021912051364779472, -128, -128, 127, torch.int8);  relu_26 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_92: \"f32[1, 320, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_54, 0.021912051364779472, -128, -128, 127, torch.int8);  quantize_per_tensor_54 = None\n",
      "            dequantize_per_tensor_93: \"f32[128, 320, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param26, 0.008215930312871933, 0, -127, 127, torch.int8);  b__frozen_param26 = None\n",
      "            conv2d_26: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_92, dequantize_per_tensor_93, p_features_denseblock2_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_92 = dequantize_per_tensor_93 = p_features_denseblock2_denselayer7_layers_conv1_weight_bias = None\n",
      "            relu_27: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_26);  conv2d_26 = None\n",
      "            quantize_per_tensor_55: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_27, 0.016761358827352524, -128, -128, 127, torch.int8);  relu_27 = None\n",
      "            dequantize_per_tensor_94: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_55, 0.016761358827352524, -128, -128, 127, torch.int8);  quantize_per_tensor_55 = None\n",
      "            dequantize_per_tensor_95: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param27, 0.0024026758037507534, 0, -127, 127, torch.int8);  b__frozen_param27 = None\n",
      "            conv2d_27: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_94, dequantize_per_tensor_95, None, [1, 1], [1, 1]);  dequantize_per_tensor_94 = dequantize_per_tensor_95 = None\n",
      "            quantize_per_tensor_56: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_27, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_27 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:356 in forward, code: dequantize_per_tensor_default_84 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_84, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_84 = None\n",
      "            dequantize_per_tensor_96: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_56, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_56 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_12: \"f32[1, 352, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_91, dequantize_per_tensor_96], 1);  dequantize_per_tensor_91 = dequantize_per_tensor_96 = None\n",
      "            quantize_per_tensor_57: \"i8[1, 352, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_12, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_12 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:359 in forward, code: dequantize_per_tensor_default_85 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_97: \"f32[1, 352, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_57, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:360 in forward, code: dequantize_per_tensor_default_381 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_85, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_85 = None\n",
      "            dequantize_per_tensor_98: \"f32[1, 352, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_57, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_57 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_97, p_features_denseblock2_denselayer8_layers_norm1_weight, p_features_denseblock2_denselayer8_layers_norm1_bias, b_features_denseblock2_denselayer8_layers_norm1_running_mean, b_features_denseblock2_denselayer8_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_97 = p_features_denseblock2_denselayer8_layers_norm1_weight = p_features_denseblock2_denselayer8_layers_norm1_bias = b_features_denseblock2_denselayer8_layers_norm1_running_mean = b_features_denseblock2_denselayer8_layers_norm1_running_var = None\n",
      "            getitem_42: \"f32[1, 352, 32, 32]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
      "            relu_28: \"f32[1, 352, 32, 32]\" = torch.ops.aten.relu.default(getitem_42);  getitem_42 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:368 in forward, code: quantize_per_tensor_default_86 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__28, 0.026374759152531624, -128, -128, 127, torch.int8);  relu__28 = None\n",
      "            quantize_per_tensor_58: \"i8[1, 352, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_28, 0.026374759152531624, -128, -128, 127, torch.int8);  relu_28 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_99: \"f32[1, 352, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_58, 0.026374759152531624, -128, -128, 127, torch.int8);  quantize_per_tensor_58 = None\n",
      "            dequantize_per_tensor_100: \"f32[128, 352, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param28, 0.007590748369693756, 0, -127, 127, torch.int8);  b__frozen_param28 = None\n",
      "            conv2d_28: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_99, dequantize_per_tensor_100, p_features_denseblock2_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_99 = dequantize_per_tensor_100 = p_features_denseblock2_denselayer8_layers_conv1_weight_bias = None\n",
      "            relu_29: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_28);  conv2d_28 = None\n",
      "            quantize_per_tensor_59: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_29, 0.01001269556581974, -128, -128, 127, torch.int8);  relu_29 = None\n",
      "            dequantize_per_tensor_101: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_59, 0.01001269556581974, -128, -128, 127, torch.int8);  quantize_per_tensor_59 = None\n",
      "            dequantize_per_tensor_102: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param29, 0.0018703668611124158, 0, -127, 127, torch.int8);  b__frozen_param29 = None\n",
      "            conv2d_29: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_101, dequantize_per_tensor_102, None, [1, 1], [1, 1]);  dequantize_per_tensor_101 = dequantize_per_tensor_102 = None\n",
      "            quantize_per_tensor_60: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_29, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_29 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:381 in forward, code: dequantize_per_tensor_default_90 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_90, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_90 = None\n",
      "            dequantize_per_tensor_103: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_60, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_60 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_13: \"f32[1, 384, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_98, dequantize_per_tensor_103], 1);  dequantize_per_tensor_98 = dequantize_per_tensor_103 = None\n",
      "            quantize_per_tensor_61: \"i8[1, 384, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_13, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_13 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:384 in forward, code: dequantize_per_tensor_default_91 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_104: \"f32[1, 384, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_61, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:385 in forward, code: dequantize_per_tensor_default_382 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_91, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_91 = None\n",
      "            dequantize_per_tensor_105: \"f32[1, 384, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_61, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_61 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_104, p_features_denseblock2_denselayer9_layers_norm1_weight, p_features_denseblock2_denselayer9_layers_norm1_bias, b_features_denseblock2_denselayer9_layers_norm1_running_mean, b_features_denseblock2_denselayer9_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_104 = p_features_denseblock2_denselayer9_layers_norm1_weight = p_features_denseblock2_denselayer9_layers_norm1_bias = b_features_denseblock2_denselayer9_layers_norm1_running_mean = b_features_denseblock2_denselayer9_layers_norm1_running_var = None\n",
      "            getitem_45: \"f32[1, 384, 32, 32]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
      "            relu_30: \"f32[1, 384, 32, 32]\" = torch.ops.aten.relu.default(getitem_45);  getitem_45 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:393 in forward, code: quantize_per_tensor_default_92 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__30, 0.026048051193356514, -128, -128, 127, torch.int8);  relu__30 = None\n",
      "            quantize_per_tensor_62: \"i8[1, 384, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_30, 0.026048051193356514, -128, -128, 127, torch.int8);  relu_30 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_106: \"f32[1, 384, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_62, 0.026048051193356514, -128, -128, 127, torch.int8);  quantize_per_tensor_62 = None\n",
      "            dequantize_per_tensor_107: \"f32[128, 384, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param30, 0.010624253191053867, 0, -127, 127, torch.int8);  b__frozen_param30 = None\n",
      "            conv2d_30: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_106, dequantize_per_tensor_107, p_features_denseblock2_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_106 = dequantize_per_tensor_107 = p_features_denseblock2_denselayer9_layers_conv1_weight_bias = None\n",
      "            relu_31: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_30);  conv2d_30 = None\n",
      "            quantize_per_tensor_63: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_31, 0.014488347806036472, -128, -128, 127, torch.int8);  relu_31 = None\n",
      "            dequantize_per_tensor_108: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_63, 0.014488347806036472, -128, -128, 127, torch.int8);  quantize_per_tensor_63 = None\n",
      "            dequantize_per_tensor_109: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param31, 0.0022182774264365435, 0, -127, 127, torch.int8);  b__frozen_param31 = None\n",
      "            conv2d_31: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_108, dequantize_per_tensor_109, None, [1, 1], [1, 1]);  dequantize_per_tensor_108 = dequantize_per_tensor_109 = None\n",
      "            quantize_per_tensor_64: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_31, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_31 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:406 in forward, code: dequantize_per_tensor_default_96 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_96, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_96 = None\n",
      "            dequantize_per_tensor_110: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_64, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_64 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_14: \"f32[1, 416, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_105, dequantize_per_tensor_110], 1);  dequantize_per_tensor_105 = dequantize_per_tensor_110 = None\n",
      "            quantize_per_tensor_65: \"i8[1, 416, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_14, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_14 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:409 in forward, code: dequantize_per_tensor_default_97 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_111: \"f32[1, 416, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_65, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:410 in forward, code: dequantize_per_tensor_default_383 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_97, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_97 = None\n",
      "            dequantize_per_tensor_112: \"f32[1, 416, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_65, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_65 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_111, p_features_denseblock2_denselayer10_layers_norm1_weight, p_features_denseblock2_denselayer10_layers_norm1_bias, b_features_denseblock2_denselayer10_layers_norm1_running_mean, b_features_denseblock2_denselayer10_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_111 = p_features_denseblock2_denselayer10_layers_norm1_weight = p_features_denseblock2_denselayer10_layers_norm1_bias = b_features_denseblock2_denselayer10_layers_norm1_running_mean = b_features_denseblock2_denselayer10_layers_norm1_running_var = None\n",
      "            getitem_48: \"f32[1, 416, 32, 32]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
      "            relu_32: \"f32[1, 416, 32, 32]\" = torch.ops.aten.relu.default(getitem_48);  getitem_48 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:418 in forward, code: quantize_per_tensor_default_98 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__32, 0.03876306489109993, -128, -128, 127, torch.int8);  relu__32 = None\n",
      "            quantize_per_tensor_66: \"i8[1, 416, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_32, 0.03876306489109993, -128, -128, 127, torch.int8);  relu_32 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_113: \"f32[1, 416, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_66, 0.03876306489109993, -128, -128, 127, torch.int8);  quantize_per_tensor_66 = None\n",
      "            dequantize_per_tensor_114: \"f32[128, 416, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param32, 0.012093828991055489, 0, -127, 127, torch.int8);  b__frozen_param32 = None\n",
      "            conv2d_32: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_113, dequantize_per_tensor_114, p_features_denseblock2_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_113 = dequantize_per_tensor_114 = p_features_denseblock2_denselayer10_layers_conv1_weight_bias = None\n",
      "            relu_33: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_32);  conv2d_32 = None\n",
      "            quantize_per_tensor_67: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_33, 0.02278151921927929, -128, -128, 127, torch.int8);  relu_33 = None\n",
      "            dequantize_per_tensor_115: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_67, 0.02278151921927929, -128, -128, 127, torch.int8);  quantize_per_tensor_67 = None\n",
      "            dequantize_per_tensor_116: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param33, 0.0017407116247341037, 0, -127, 127, torch.int8);  b__frozen_param33 = None\n",
      "            conv2d_33: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_115, dequantize_per_tensor_116, None, [1, 1], [1, 1]);  dequantize_per_tensor_115 = dequantize_per_tensor_116 = None\n",
      "            quantize_per_tensor_68: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_33, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_33 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:431 in forward, code: dequantize_per_tensor_default_102 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_102, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_102 = None\n",
      "            dequantize_per_tensor_117: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_68, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_68 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_15: \"f32[1, 448, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_112, dequantize_per_tensor_117], 1);  dequantize_per_tensor_112 = dequantize_per_tensor_117 = None\n",
      "            quantize_per_tensor_69: \"i8[1, 448, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_15, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_15 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:434 in forward, code: dequantize_per_tensor_default_103 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_118: \"f32[1, 448, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_69, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:435 in forward, code: dequantize_per_tensor_default_384 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_103, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_103 = None\n",
      "            dequantize_per_tensor_119: \"f32[1, 448, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_69, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_69 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_118, p_features_denseblock2_denselayer11_layers_norm1_weight, p_features_denseblock2_denselayer11_layers_norm1_bias, b_features_denseblock2_denselayer11_layers_norm1_running_mean, b_features_denseblock2_denselayer11_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_118 = p_features_denseblock2_denselayer11_layers_norm1_weight = p_features_denseblock2_denselayer11_layers_norm1_bias = b_features_denseblock2_denselayer11_layers_norm1_running_mean = b_features_denseblock2_denselayer11_layers_norm1_running_var = None\n",
      "            getitem_51: \"f32[1, 448, 32, 32]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
      "            relu_34: \"f32[1, 448, 32, 32]\" = torch.ops.aten.relu.default(getitem_51);  getitem_51 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:443 in forward, code: quantize_per_tensor_default_104 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__34, 0.037703581154346466, -128, -128, 127, torch.int8);  relu__34 = None\n",
      "            quantize_per_tensor_70: \"i8[1, 448, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_34, 0.037703581154346466, -128, -128, 127, torch.int8);  relu_34 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_120: \"f32[1, 448, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_70, 0.037703581154346466, -128, -128, 127, torch.int8);  quantize_per_tensor_70 = None\n",
      "            dequantize_per_tensor_121: \"f32[128, 448, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param34, 0.009763662703335285, 0, -127, 127, torch.int8);  b__frozen_param34 = None\n",
      "            conv2d_34: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_120, dequantize_per_tensor_121, p_features_denseblock2_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_120 = dequantize_per_tensor_121 = p_features_denseblock2_denselayer11_layers_conv1_weight_bias = None\n",
      "            relu_35: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_34);  conv2d_34 = None\n",
      "            quantize_per_tensor_71: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_35, 0.019625337794423103, -128, -128, 127, torch.int8);  relu_35 = None\n",
      "            dequantize_per_tensor_122: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_71, 0.019625337794423103, -128, -128, 127, torch.int8);  quantize_per_tensor_71 = None\n",
      "            dequantize_per_tensor_123: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param35, 0.0017583960434421897, 0, -127, 127, torch.int8);  b__frozen_param35 = None\n",
      "            conv2d_35: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_122, dequantize_per_tensor_123, None, [1, 1], [1, 1]);  dequantize_per_tensor_122 = dequantize_per_tensor_123 = None\n",
      "            quantize_per_tensor_72: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_35, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_35 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:456 in forward, code: dequantize_per_tensor_default_108 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_108, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_108 = None\n",
      "            dequantize_per_tensor_124: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_72, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_72 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_16: \"f32[1, 480, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_119, dequantize_per_tensor_124], 1);  dequantize_per_tensor_119 = dequantize_per_tensor_124 = None\n",
      "            quantize_per_tensor_73: \"i8[1, 480, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_16, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_16 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:459 in forward, code: dequantize_per_tensor_default_109 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_109, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_125: \"f32[1, 480, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_73, 0.07687164098024368, 10, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:460 in forward, code: dequantize_per_tensor_default_385 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_109, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_109 = None\n",
      "            dequantize_per_tensor_126: \"f32[1, 480, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_73, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_73 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_125, p_features_denseblock2_denselayer12_layers_norm1_weight, p_features_denseblock2_denselayer12_layers_norm1_bias, b_features_denseblock2_denselayer12_layers_norm1_running_mean, b_features_denseblock2_denselayer12_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_125 = p_features_denseblock2_denselayer12_layers_norm1_weight = p_features_denseblock2_denselayer12_layers_norm1_bias = b_features_denseblock2_denselayer12_layers_norm1_running_mean = b_features_denseblock2_denselayer12_layers_norm1_running_var = None\n",
      "            getitem_54: \"f32[1, 480, 32, 32]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
      "            relu_36: \"f32[1, 480, 32, 32]\" = torch.ops.aten.relu.default(getitem_54);  getitem_54 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:468 in forward, code: quantize_per_tensor_default_110 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__36, 0.04547126591205597, -128, -128, 127, torch.int8);  relu__36 = None\n",
      "            quantize_per_tensor_74: \"i8[1, 480, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_36, 0.04547126591205597, -128, -128, 127, torch.int8);  relu_36 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_127: \"f32[1, 480, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_74, 0.04547126591205597, -128, -128, 127, torch.int8);  quantize_per_tensor_74 = None\n",
      "            dequantize_per_tensor_128: \"f32[128, 480, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param36, 0.009439360350370407, 0, -127, 127, torch.int8);  b__frozen_param36 = None\n",
      "            conv2d_36: \"f32[1, 128, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_127, dequantize_per_tensor_128, p_features_denseblock2_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_127 = dequantize_per_tensor_128 = p_features_denseblock2_denselayer12_layers_conv1_weight_bias = None\n",
      "            relu_37: \"f32[1, 128, 32, 32]\" = torch.ops.aten.relu.default(conv2d_36);  conv2d_36 = None\n",
      "            quantize_per_tensor_75: \"i8[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_37, 0.012600935995578766, -128, -128, 127, torch.int8);  relu_37 = None\n",
      "            dequantize_per_tensor_129: \"f32[1, 128, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_75, 0.012600935995578766, -128, -128, 127, torch.int8);  quantize_per_tensor_75 = None\n",
      "            dequantize_per_tensor_130: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param37, 0.00235523353330791, 0, -127, 127, torch.int8);  b__frozen_param37 = None\n",
      "            conv2d_37: \"f32[1, 32, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_129, dequantize_per_tensor_130, None, [1, 1], [1, 1]);  dequantize_per_tensor_129 = dequantize_per_tensor_130 = None\n",
      "            quantize_per_tensor_76: \"i8[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_37, 0.07687164098024368, 10, -128, 127, torch.int8);  conv2d_37 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:481 in forward, code: dequantize_per_tensor_default_114 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_114, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_114 = None\n",
      "            dequantize_per_tensor_131: \"f32[1, 32, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_76, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_76 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_17: \"f32[1, 512, 32, 32]\" = torch.ops.aten.cat.default([dequantize_per_tensor_126, dequantize_per_tensor_131], 1);  dequantize_per_tensor_126 = dequantize_per_tensor_131 = None\n",
      "            quantize_per_tensor_77: \"i8[1, 512, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_17, 0.07687164098024368, 10, -128, 127, torch.int8);  cat_17 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:484 in forward, code: dequantize_per_tensor_default_115 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_115, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_default_115 = None\n",
      "            dequantize_per_tensor_132: \"f32[1, 512, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_77, 0.07687164098024368, 10, -128, 127, torch.int8);  quantize_per_tensor_77 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_132, p_features_transition2_norm_weight, p_features_transition2_norm_bias, b_features_transition2_norm_running_mean, b_features_transition2_norm_running_var, 0.1, 1e-05);  dequantize_per_tensor_132 = p_features_transition2_norm_weight = p_features_transition2_norm_bias = b_features_transition2_norm_running_mean = b_features_transition2_norm_running_var = None\n",
      "            getitem_57: \"f32[1, 512, 32, 32]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
      "            relu_38: \"f32[1, 512, 32, 32]\" = torch.ops.aten.relu.default(getitem_57);  getitem_57 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:492 in forward, code: quantize_per_tensor_default_116 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__38, 0.04991768300533295, -128, -128, 127, torch.int8);  relu__38 = None\n",
      "            quantize_per_tensor_78: \"i8[1, 512, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_38, 0.04991768300533295, -128, -128, 127, torch.int8);  relu_38 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            dequantize_per_tensor_133: \"f32[1, 512, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_78, 0.04991768300533295, -128, -128, 127, torch.int8);  quantize_per_tensor_78 = None\n",
      "            dequantize_per_tensor_134: \"f32[256, 512, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param38, 0.005248184781521559, 0, -127, 127, torch.int8);  b__frozen_param38 = None\n",
      "            conv2d_38: \"f32[1, 256, 32, 32]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_133, dequantize_per_tensor_134);  dequantize_per_tensor_133 = dequantize_per_tensor_134 = None\n",
      "            quantize_per_tensor_79: \"i8[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_38, 0.08149266242980957, 8, -128, 127, torch.int8);  conv2d_38 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:498 in forward, code: dequantize_per_tensor_default_118 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_118, 0.08149266242980957, 8, -128, 127, torch.int8);  quantize_per_tensor_default_118 = None\n",
      "            dequantize_per_tensor_135: \"f32[1, 256, 32, 32]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_79, 0.08149266242980957, 8, -128, 127, torch.int8);  quantize_per_tensor_79 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            avg_pool2d_1: \"f32[1, 256, 16, 16]\" = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_135, [2, 2], [2, 2]);  dequantize_per_tensor_135 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:500 in forward, code: quantize_per_tensor_default_119 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_1, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            quantize_per_tensor_80: \"i8[1, 256, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_1, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:501 in forward, code: dequantize_per_tensor_default_119 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_119, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_119 = None\n",
      "            dequantize_per_tensor_136: \"f32[1, 256, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_80, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_80 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_1, p_features_denseblock3_denselayer1_layers_norm1_weight, p_features_denseblock3_denselayer1_layers_norm1_bias, b_features_denseblock3_denselayer1_layers_norm1_running_mean, b_features_denseblock3_denselayer1_layers_norm1_running_var, 0.1, 1e-05);  avg_pool2d_1 = p_features_denseblock3_denselayer1_layers_norm1_weight = p_features_denseblock3_denselayer1_layers_norm1_bias = b_features_denseblock3_denselayer1_layers_norm1_running_mean = b_features_denseblock3_denselayer1_layers_norm1_running_var = None\n",
      "            getitem_60: \"f32[1, 256, 16, 16]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
      "            relu_39: \"f32[1, 256, 16, 16]\" = torch.ops.aten.relu.default(getitem_60);  getitem_60 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:509 in forward, code: quantize_per_tensor_default_120 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__39, 0.019499758258461952, -128, -128, 127, torch.int8);  relu__39 = None\n",
      "            quantize_per_tensor_81: \"i8[1, 256, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_39, 0.019499758258461952, -128, -128, 127, torch.int8);  relu_39 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_137: \"f32[1, 256, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_81, 0.019499758258461952, -128, -128, 127, torch.int8);  quantize_per_tensor_81 = None\n",
      "            dequantize_per_tensor_138: \"f32[128, 256, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param39, 0.006735334172844887, 0, -127, 127, torch.int8);  b__frozen_param39 = None\n",
      "            conv2d_39: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_137, dequantize_per_tensor_138, p_features_denseblock3_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_137 = dequantize_per_tensor_138 = p_features_denseblock3_denselayer1_layers_conv1_weight_bias = None\n",
      "            relu_40: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_39);  conv2d_39 = None\n",
      "            quantize_per_tensor_82: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_40, 0.018092796206474304, -128, -128, 127, torch.int8);  relu_40 = None\n",
      "            dequantize_per_tensor_139: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_82, 0.018092796206474304, -128, -128, 127, torch.int8);  quantize_per_tensor_82 = None\n",
      "            dequantize_per_tensor_140: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param40, 0.0019048936665058136, 0, -127, 127, torch.int8);  b__frozen_param40 = None\n",
      "            conv2d_40: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_139, dequantize_per_tensor_140, None, [1, 1], [1, 1]);  dequantize_per_tensor_139 = dequantize_per_tensor_140 = None\n",
      "            quantize_per_tensor_83: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_40, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_40 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:522 in forward, code: dequantize_per_tensor_default_124 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_124, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_124 = None\n",
      "            dequantize_per_tensor_141: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_83, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_83 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_18: \"f32[1, 288, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_136, dequantize_per_tensor_141], 1);  dequantize_per_tensor_136 = dequantize_per_tensor_141 = None\n",
      "            quantize_per_tensor_84: \"i8[1, 288, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_18, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_18 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:525 in forward, code: dequantize_per_tensor_default_125 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_142: \"f32[1, 288, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_84, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:526 in forward, code: dequantize_per_tensor_default_386 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_125, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_125 = None\n",
      "            dequantize_per_tensor_143: \"f32[1, 288, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_84, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_84 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_142, p_features_denseblock3_denselayer2_layers_norm1_weight, p_features_denseblock3_denselayer2_layers_norm1_bias, b_features_denseblock3_denselayer2_layers_norm1_running_mean, b_features_denseblock3_denselayer2_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_142 = p_features_denseblock3_denselayer2_layers_norm1_weight = p_features_denseblock3_denselayer2_layers_norm1_bias = b_features_denseblock3_denselayer2_layers_norm1_running_mean = b_features_denseblock3_denselayer2_layers_norm1_running_var = None\n",
      "            getitem_63: \"f32[1, 288, 16, 16]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
      "            relu_41: \"f32[1, 288, 16, 16]\" = torch.ops.aten.relu.default(getitem_63);  getitem_63 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:534 in forward, code: quantize_per_tensor_default_126 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__41, 0.024419553577899933, -128, -128, 127, torch.int8);  relu__41 = None\n",
      "            quantize_per_tensor_85: \"i8[1, 288, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_41, 0.024419553577899933, -128, -128, 127, torch.int8);  relu_41 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_144: \"f32[1, 288, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_85, 0.024419553577899933, -128, -128, 127, torch.int8);  quantize_per_tensor_85 = None\n",
      "            dequantize_per_tensor_145: \"f32[128, 288, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param41, 0.007588740438222885, 0, -127, 127, torch.int8);  b__frozen_param41 = None\n",
      "            conv2d_41: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_144, dequantize_per_tensor_145, p_features_denseblock3_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_144 = dequantize_per_tensor_145 = p_features_denseblock3_denselayer2_layers_conv1_weight_bias = None\n",
      "            relu_42: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_41);  conv2d_41 = None\n",
      "            quantize_per_tensor_86: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_42, 0.022614017128944397, -128, -128, 127, torch.int8);  relu_42 = None\n",
      "            dequantize_per_tensor_146: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_86, 0.022614017128944397, -128, -128, 127, torch.int8);  quantize_per_tensor_86 = None\n",
      "            dequantize_per_tensor_147: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param42, 0.0023393514566123486, 0, -127, 127, torch.int8);  b__frozen_param42 = None\n",
      "            conv2d_42: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_146, dequantize_per_tensor_147, None, [1, 1], [1, 1]);  dequantize_per_tensor_146 = dequantize_per_tensor_147 = None\n",
      "            quantize_per_tensor_87: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_42, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_42 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:547 in forward, code: dequantize_per_tensor_default_130 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_130, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_130 = None\n",
      "            dequantize_per_tensor_148: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_87, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_87 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_19: \"f32[1, 320, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_143, dequantize_per_tensor_148], 1);  dequantize_per_tensor_143 = dequantize_per_tensor_148 = None\n",
      "            quantize_per_tensor_88: \"i8[1, 320, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_19, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_19 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:550 in forward, code: dequantize_per_tensor_default_131 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_149: \"f32[1, 320, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_88, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:551 in forward, code: dequantize_per_tensor_default_387 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_131, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_131 = None\n",
      "            dequantize_per_tensor_150: \"f32[1, 320, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_88, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_88 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_149, p_features_denseblock3_denselayer3_layers_norm1_weight, p_features_denseblock3_denselayer3_layers_norm1_bias, b_features_denseblock3_denselayer3_layers_norm1_running_mean, b_features_denseblock3_denselayer3_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_149 = p_features_denseblock3_denselayer3_layers_norm1_weight = p_features_denseblock3_denselayer3_layers_norm1_bias = b_features_denseblock3_denselayer3_layers_norm1_running_mean = b_features_denseblock3_denselayer3_layers_norm1_running_var = None\n",
      "            getitem_66: \"f32[1, 320, 16, 16]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
      "            relu_43: \"f32[1, 320, 16, 16]\" = torch.ops.aten.relu.default(getitem_66);  getitem_66 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:559 in forward, code: quantize_per_tensor_default_132 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__43, 0.023411856964230537, -128, -128, 127, torch.int8);  relu__43 = None\n",
      "            quantize_per_tensor_89: \"i8[1, 320, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_43, 0.023411856964230537, -128, -128, 127, torch.int8);  relu_43 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_151: \"f32[1, 320, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_89, 0.023411856964230537, -128, -128, 127, torch.int8);  quantize_per_tensor_89 = None\n",
      "            dequantize_per_tensor_152: \"f32[128, 320, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param43, 0.008429267443716526, 0, -127, 127, torch.int8);  b__frozen_param43 = None\n",
      "            conv2d_43: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_151, dequantize_per_tensor_152, p_features_denseblock3_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_151 = dequantize_per_tensor_152 = p_features_denseblock3_denselayer3_layers_conv1_weight_bias = None\n",
      "            relu_44: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_43);  conv2d_43 = None\n",
      "            quantize_per_tensor_90: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_44, 0.01815163902938366, -128, -128, 127, torch.int8);  relu_44 = None\n",
      "            dequantize_per_tensor_153: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_90, 0.01815163902938366, -128, -128, 127, torch.int8);  quantize_per_tensor_90 = None\n",
      "            dequantize_per_tensor_154: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param44, 0.0022762438748031855, 0, -127, 127, torch.int8);  b__frozen_param44 = None\n",
      "            conv2d_44: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_153, dequantize_per_tensor_154, None, [1, 1], [1, 1]);  dequantize_per_tensor_153 = dequantize_per_tensor_154 = None\n",
      "            quantize_per_tensor_91: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_44, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_44 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:572 in forward, code: dequantize_per_tensor_default_136 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_136, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_136 = None\n",
      "            dequantize_per_tensor_155: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_91, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_91 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_20: \"f32[1, 352, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_150, dequantize_per_tensor_155], 1);  dequantize_per_tensor_150 = dequantize_per_tensor_155 = None\n",
      "            quantize_per_tensor_92: \"i8[1, 352, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_20, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_20 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:575 in forward, code: dequantize_per_tensor_default_137 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_156: \"f32[1, 352, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_92, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:576 in forward, code: dequantize_per_tensor_default_388 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_137, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_137 = None\n",
      "            dequantize_per_tensor_157: \"f32[1, 352, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_92, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_92 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_156, p_features_denseblock3_denselayer4_layers_norm1_weight, p_features_denseblock3_denselayer4_layers_norm1_bias, b_features_denseblock3_denselayer4_layers_norm1_running_mean, b_features_denseblock3_denselayer4_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_156 = p_features_denseblock3_denselayer4_layers_norm1_weight = p_features_denseblock3_denselayer4_layers_norm1_bias = b_features_denseblock3_denselayer4_layers_norm1_running_mean = b_features_denseblock3_denselayer4_layers_norm1_running_var = None\n",
      "            getitem_69: \"f32[1, 352, 16, 16]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
      "            relu_45: \"f32[1, 352, 16, 16]\" = torch.ops.aten.relu.default(getitem_69);  getitem_69 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:584 in forward, code: quantize_per_tensor_default_138 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__45, 0.013636472634971142, -128, -128, 127, torch.int8);  relu__45 = None\n",
      "            quantize_per_tensor_93: \"i8[1, 352, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_45, 0.013636472634971142, -128, -128, 127, torch.int8);  relu_45 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_158: \"f32[1, 352, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_93, 0.013636472634971142, -128, -128, 127, torch.int8);  quantize_per_tensor_93 = None\n",
      "            dequantize_per_tensor_159: \"f32[128, 352, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param45, 0.008664802648127079, 0, -127, 127, torch.int8);  b__frozen_param45 = None\n",
      "            conv2d_45: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_158, dequantize_per_tensor_159, p_features_denseblock3_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_158 = dequantize_per_tensor_159 = p_features_denseblock3_denselayer4_layers_conv1_weight_bias = None\n",
      "            relu_46: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_45);  conv2d_45 = None\n",
      "            quantize_per_tensor_94: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_46, 0.0397607758641243, -128, -128, 127, torch.int8);  relu_46 = None\n",
      "            dequantize_per_tensor_160: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_94, 0.0397607758641243, -128, -128, 127, torch.int8);  quantize_per_tensor_94 = None\n",
      "            dequantize_per_tensor_161: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param46, 0.0032824354711920023, 0, -127, 127, torch.int8);  b__frozen_param46 = None\n",
      "            conv2d_46: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_160, dequantize_per_tensor_161, None, [1, 1], [1, 1]);  dequantize_per_tensor_160 = dequantize_per_tensor_161 = None\n",
      "            quantize_per_tensor_95: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_46, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_46 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:597 in forward, code: dequantize_per_tensor_default_142 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_142, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_142 = None\n",
      "            dequantize_per_tensor_162: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_95, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_95 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_21: \"f32[1, 384, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_157, dequantize_per_tensor_162], 1);  dequantize_per_tensor_157 = dequantize_per_tensor_162 = None\n",
      "            quantize_per_tensor_96: \"i8[1, 384, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_21, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_21 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:600 in forward, code: dequantize_per_tensor_default_143 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_163: \"f32[1, 384, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_96, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:601 in forward, code: dequantize_per_tensor_default_389 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_143, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_143 = None\n",
      "            dequantize_per_tensor_164: \"f32[1, 384, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_96, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_96 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_163, p_features_denseblock3_denselayer5_layers_norm1_weight, p_features_denseblock3_denselayer5_layers_norm1_bias, b_features_denseblock3_denselayer5_layers_norm1_running_mean, b_features_denseblock3_denselayer5_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_163 = p_features_denseblock3_denselayer5_layers_norm1_weight = p_features_denseblock3_denselayer5_layers_norm1_bias = b_features_denseblock3_denselayer5_layers_norm1_running_mean = b_features_denseblock3_denselayer5_layers_norm1_running_var = None\n",
      "            getitem_72: \"f32[1, 384, 16, 16]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
      "            relu_47: \"f32[1, 384, 16, 16]\" = torch.ops.aten.relu.default(getitem_72);  getitem_72 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:609 in forward, code: quantize_per_tensor_default_144 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__47, 0.020244944840669632, -128, -128, 127, torch.int8);  relu__47 = None\n",
      "            quantize_per_tensor_97: \"i8[1, 384, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_47, 0.020244944840669632, -128, -128, 127, torch.int8);  relu_47 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_165: \"f32[1, 384, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_97, 0.020244944840669632, -128, -128, 127, torch.int8);  quantize_per_tensor_97 = None\n",
      "            dequantize_per_tensor_166: \"f32[128, 384, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param47, 0.011617506854236126, 0, -127, 127, torch.int8);  b__frozen_param47 = None\n",
      "            conv2d_47: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_165, dequantize_per_tensor_166, p_features_denseblock3_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_165 = dequantize_per_tensor_166 = p_features_denseblock3_denselayer5_layers_conv1_weight_bias = None\n",
      "            relu_48: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_47);  conv2d_47 = None\n",
      "            quantize_per_tensor_98: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_48, 0.04136771708726883, -128, -128, 127, torch.int8);  relu_48 = None\n",
      "            dequantize_per_tensor_167: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_98, 0.04136771708726883, -128, -128, 127, torch.int8);  quantize_per_tensor_98 = None\n",
      "            dequantize_per_tensor_168: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param48, 0.002854603109881282, 0, -127, 127, torch.int8);  b__frozen_param48 = None\n",
      "            conv2d_48: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_167, dequantize_per_tensor_168, None, [1, 1], [1, 1]);  dequantize_per_tensor_167 = dequantize_per_tensor_168 = None\n",
      "            quantize_per_tensor_99: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_48, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_48 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:622 in forward, code: dequantize_per_tensor_default_148 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_148, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_148 = None\n",
      "            dequantize_per_tensor_169: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_99, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_99 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_22: \"f32[1, 416, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_164, dequantize_per_tensor_169], 1);  dequantize_per_tensor_164 = dequantize_per_tensor_169 = None\n",
      "            quantize_per_tensor_100: \"i8[1, 416, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_22, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_22 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:625 in forward, code: dequantize_per_tensor_default_149 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_170: \"f32[1, 416, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_100, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:626 in forward, code: dequantize_per_tensor_default_390 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_149, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_149 = None\n",
      "            dequantize_per_tensor_171: \"f32[1, 416, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_100, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_100 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_170, p_features_denseblock3_denselayer6_layers_norm1_weight, p_features_denseblock3_denselayer6_layers_norm1_bias, b_features_denseblock3_denselayer6_layers_norm1_running_mean, b_features_denseblock3_denselayer6_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_170 = p_features_denseblock3_denselayer6_layers_norm1_weight = p_features_denseblock3_denselayer6_layers_norm1_bias = b_features_denseblock3_denselayer6_layers_norm1_running_mean = b_features_denseblock3_denselayer6_layers_norm1_running_var = None\n",
      "            getitem_75: \"f32[1, 416, 16, 16]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
      "            relu_49: \"f32[1, 416, 16, 16]\" = torch.ops.aten.relu.default(getitem_75);  getitem_75 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:634 in forward, code: quantize_per_tensor_default_150 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__49, 0.015321011655032635, -128, -128, 127, torch.int8);  relu__49 = None\n",
      "            quantize_per_tensor_101: \"i8[1, 416, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_49, 0.015321011655032635, -128, -128, 127, torch.int8);  relu_49 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_172: \"f32[1, 416, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_101, 0.015321011655032635, -128, -128, 127, torch.int8);  quantize_per_tensor_101 = None\n",
      "            dequantize_per_tensor_173: \"f32[128, 416, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param49, 0.007336599286645651, 0, -127, 127, torch.int8);  b__frozen_param49 = None\n",
      "            conv2d_49: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_172, dequantize_per_tensor_173, p_features_denseblock3_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_172 = dequantize_per_tensor_173 = p_features_denseblock3_denselayer6_layers_conv1_weight_bias = None\n",
      "            relu_50: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_49);  conv2d_49 = None\n",
      "            quantize_per_tensor_102: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_50, 0.019793372601270676, -128, -128, 127, torch.int8);  relu_50 = None\n",
      "            dequantize_per_tensor_174: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_102, 0.019793372601270676, -128, -128, 127, torch.int8);  quantize_per_tensor_102 = None\n",
      "            dequantize_per_tensor_175: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param50, 0.0018314721528440714, 0, -127, 127, torch.int8);  b__frozen_param50 = None\n",
      "            conv2d_50: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_174, dequantize_per_tensor_175, None, [1, 1], [1, 1]);  dequantize_per_tensor_174 = dequantize_per_tensor_175 = None\n",
      "            quantize_per_tensor_103: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_50, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_50 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:647 in forward, code: dequantize_per_tensor_default_154 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_154, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_154 = None\n",
      "            dequantize_per_tensor_176: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_103, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_103 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_23: \"f32[1, 448, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_171, dequantize_per_tensor_176], 1);  dequantize_per_tensor_171 = dequantize_per_tensor_176 = None\n",
      "            quantize_per_tensor_104: \"i8[1, 448, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_23, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_23 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:650 in forward, code: dequantize_per_tensor_default_155 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_155, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_177: \"f32[1, 448, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_104, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:651 in forward, code: dequantize_per_tensor_default_391 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_155, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_155 = None\n",
      "            dequantize_per_tensor_178: \"f32[1, 448, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_104, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_104 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_177, p_features_denseblock3_denselayer7_layers_norm1_weight, p_features_denseblock3_denselayer7_layers_norm1_bias, b_features_denseblock3_denselayer7_layers_norm1_running_mean, b_features_denseblock3_denselayer7_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_177 = p_features_denseblock3_denselayer7_layers_norm1_weight = p_features_denseblock3_denselayer7_layers_norm1_bias = b_features_denseblock3_denselayer7_layers_norm1_running_mean = b_features_denseblock3_denselayer7_layers_norm1_running_var = None\n",
      "            getitem_78: \"f32[1, 448, 16, 16]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
      "            relu_51: \"f32[1, 448, 16, 16]\" = torch.ops.aten.relu.default(getitem_78);  getitem_78 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:659 in forward, code: quantize_per_tensor_default_156 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__51, 0.013829131610691547, -128, -128, 127, torch.int8);  relu__51 = None\n",
      "            quantize_per_tensor_105: \"i8[1, 448, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_51, 0.013829131610691547, -128, -128, 127, torch.int8);  relu_51 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_179: \"f32[1, 448, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_105, 0.013829131610691547, -128, -128, 127, torch.int8);  quantize_per_tensor_105 = None\n",
      "            dequantize_per_tensor_180: \"f32[128, 448, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param51, 0.008493652567267418, 0, -127, 127, torch.int8);  b__frozen_param51 = None\n",
      "            conv2d_51: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_179, dequantize_per_tensor_180, p_features_denseblock3_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_179 = dequantize_per_tensor_180 = p_features_denseblock3_denselayer7_layers_conv1_weight_bias = None\n",
      "            relu_52: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_51);  conv2d_51 = None\n",
      "            quantize_per_tensor_106: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_52, 0.015886062756180763, -128, -128, 127, torch.int8);  relu_52 = None\n",
      "            dequantize_per_tensor_181: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_106, 0.015886062756180763, -128, -128, 127, torch.int8);  quantize_per_tensor_106 = None\n",
      "            dequantize_per_tensor_182: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param52, 0.0016737671103328466, 0, -127, 127, torch.int8);  b__frozen_param52 = None\n",
      "            conv2d_52: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_181, dequantize_per_tensor_182, None, [1, 1], [1, 1]);  dequantize_per_tensor_181 = dequantize_per_tensor_182 = None\n",
      "            quantize_per_tensor_107: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_52, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_52 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:672 in forward, code: dequantize_per_tensor_default_160 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_160, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_160 = None\n",
      "            dequantize_per_tensor_183: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_107, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_107 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_24: \"f32[1, 480, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_178, dequantize_per_tensor_183], 1);  dequantize_per_tensor_178 = dequantize_per_tensor_183 = None\n",
      "            quantize_per_tensor_108: \"i8[1, 480, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_24, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_24 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:675 in forward, code: dequantize_per_tensor_default_161 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_161, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_184: \"f32[1, 480, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_108, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:676 in forward, code: dequantize_per_tensor_default_392 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_161, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_161 = None\n",
      "            dequantize_per_tensor_185: \"f32[1, 480, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_108, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_108 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_184, p_features_denseblock3_denselayer8_layers_norm1_weight, p_features_denseblock3_denselayer8_layers_norm1_bias, b_features_denseblock3_denselayer8_layers_norm1_running_mean, b_features_denseblock3_denselayer8_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_184 = p_features_denseblock3_denselayer8_layers_norm1_weight = p_features_denseblock3_denselayer8_layers_norm1_bias = b_features_denseblock3_denselayer8_layers_norm1_running_mean = b_features_denseblock3_denselayer8_layers_norm1_running_var = None\n",
      "            getitem_81: \"f32[1, 480, 16, 16]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
      "            relu_53: \"f32[1, 480, 16, 16]\" = torch.ops.aten.relu.default(getitem_81);  getitem_81 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:684 in forward, code: quantize_per_tensor_default_162 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__53, 0.018496839329600334, -128, -128, 127, torch.int8);  relu__53 = None\n",
      "            quantize_per_tensor_109: \"i8[1, 480, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_53, 0.018496839329600334, -128, -128, 127, torch.int8);  relu_53 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_186: \"f32[1, 480, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_109, 0.018496839329600334, -128, -128, 127, torch.int8);  quantize_per_tensor_109 = None\n",
      "            dequantize_per_tensor_187: \"f32[128, 480, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param53, 0.00611856346949935, 0, -127, 127, torch.int8);  b__frozen_param53 = None\n",
      "            conv2d_53: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_186, dequantize_per_tensor_187, p_features_denseblock3_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_186 = dequantize_per_tensor_187 = p_features_denseblock3_denselayer8_layers_conv1_weight_bias = None\n",
      "            relu_54: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_53);  conv2d_53 = None\n",
      "            quantize_per_tensor_110: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_54, 0.03790067881345749, -128, -128, 127, torch.int8);  relu_54 = None\n",
      "            dequantize_per_tensor_188: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_110, 0.03790067881345749, -128, -128, 127, torch.int8);  quantize_per_tensor_110 = None\n",
      "            dequantize_per_tensor_189: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param54, 0.002246270654723048, 0, -127, 127, torch.int8);  b__frozen_param54 = None\n",
      "            conv2d_54: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_188, dequantize_per_tensor_189, None, [1, 1], [1, 1]);  dequantize_per_tensor_188 = dequantize_per_tensor_189 = None\n",
      "            quantize_per_tensor_111: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_54, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_54 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:697 in forward, code: dequantize_per_tensor_default_166 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_166, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_166 = None\n",
      "            dequantize_per_tensor_190: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_111, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_111 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_25: \"f32[1, 512, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_185, dequantize_per_tensor_190], 1);  dequantize_per_tensor_185 = dequantize_per_tensor_190 = None\n",
      "            quantize_per_tensor_112: \"i8[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_25, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_25 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:700 in forward, code: dequantize_per_tensor_default_167 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_167, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_191: \"f32[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_112, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:701 in forward, code: dequantize_per_tensor_default_393 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_167, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_167 = None\n",
      "            dequantize_per_tensor_192: \"f32[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_112, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_112 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_191, p_features_denseblock3_denselayer9_layers_norm1_weight, p_features_denseblock3_denselayer9_layers_norm1_bias, b_features_denseblock3_denselayer9_layers_norm1_running_mean, b_features_denseblock3_denselayer9_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_191 = p_features_denseblock3_denselayer9_layers_norm1_weight = p_features_denseblock3_denselayer9_layers_norm1_bias = b_features_denseblock3_denselayer9_layers_norm1_running_mean = b_features_denseblock3_denselayer9_layers_norm1_running_var = None\n",
      "            getitem_84: \"f32[1, 512, 16, 16]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
      "            relu_55: \"f32[1, 512, 16, 16]\" = torch.ops.aten.relu.default(getitem_84);  getitem_84 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:709 in forward, code: quantize_per_tensor_default_168 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__55, 0.03274882957339287, -128, -128, 127, torch.int8);  relu__55 = None\n",
      "            quantize_per_tensor_113: \"i8[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_55, 0.03274882957339287, -128, -128, 127, torch.int8);  relu_55 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_193: \"f32[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_113, 0.03274882957339287, -128, -128, 127, torch.int8);  quantize_per_tensor_113 = None\n",
      "            dequantize_per_tensor_194: \"f32[128, 512, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param55, 0.00956618133932352, 0, -127, 127, torch.int8);  b__frozen_param55 = None\n",
      "            conv2d_55: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_193, dequantize_per_tensor_194, p_features_denseblock3_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_193 = dequantize_per_tensor_194 = p_features_denseblock3_denselayer9_layers_conv1_weight_bias = None\n",
      "            relu_56: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_55);  conv2d_55 = None\n",
      "            quantize_per_tensor_114: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_56, 0.044811878353357315, -128, -128, 127, torch.int8);  relu_56 = None\n",
      "            dequantize_per_tensor_195: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_114, 0.044811878353357315, -128, -128, 127, torch.int8);  quantize_per_tensor_114 = None\n",
      "            dequantize_per_tensor_196: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param56, 0.003327038837596774, 0, -127, 127, torch.int8);  b__frozen_param56 = None\n",
      "            conv2d_56: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_195, dequantize_per_tensor_196, None, [1, 1], [1, 1]);  dequantize_per_tensor_195 = dequantize_per_tensor_196 = None\n",
      "            quantize_per_tensor_115: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_56, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_56 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:722 in forward, code: dequantize_per_tensor_default_172 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_172, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_172 = None\n",
      "            dequantize_per_tensor_197: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_115, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_115 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_26: \"f32[1, 544, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_192, dequantize_per_tensor_197], 1);  dequantize_per_tensor_192 = dequantize_per_tensor_197 = None\n",
      "            quantize_per_tensor_116: \"i8[1, 544, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_26, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_26 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:725 in forward, code: dequantize_per_tensor_default_173 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_173, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_198: \"f32[1, 544, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_116, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:726 in forward, code: dequantize_per_tensor_default_394 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_173, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_173 = None\n",
      "            dequantize_per_tensor_199: \"f32[1, 544, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_116, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_116 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_198, p_features_denseblock3_denselayer10_layers_norm1_weight, p_features_denseblock3_denselayer10_layers_norm1_bias, b_features_denseblock3_denselayer10_layers_norm1_running_mean, b_features_denseblock3_denselayer10_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_198 = p_features_denseblock3_denselayer10_layers_norm1_weight = p_features_denseblock3_denselayer10_layers_norm1_bias = b_features_denseblock3_denselayer10_layers_norm1_running_mean = b_features_denseblock3_denselayer10_layers_norm1_running_var = None\n",
      "            getitem_87: \"f32[1, 544, 16, 16]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
      "            relu_57: \"f32[1, 544, 16, 16]\" = torch.ops.aten.relu.default(getitem_87);  getitem_87 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:734 in forward, code: quantize_per_tensor_default_174 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__57, 0.022092843428254128, -128, -128, 127, torch.int8);  relu__57 = None\n",
      "            quantize_per_tensor_117: \"i8[1, 544, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_57, 0.022092843428254128, -128, -128, 127, torch.int8);  relu_57 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_200: \"f32[1, 544, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_117, 0.022092843428254128, -128, -128, 127, torch.int8);  quantize_per_tensor_117 = None\n",
      "            dequantize_per_tensor_201: \"f32[128, 544, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param57, 0.009288808330893517, 0, -127, 127, torch.int8);  b__frozen_param57 = None\n",
      "            conv2d_57: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_200, dequantize_per_tensor_201, p_features_denseblock3_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_200 = dequantize_per_tensor_201 = p_features_denseblock3_denselayer10_layers_conv1_weight_bias = None\n",
      "            relu_58: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_57);  conv2d_57 = None\n",
      "            quantize_per_tensor_118: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_58, 0.03146630525588989, -128, -128, 127, torch.int8);  relu_58 = None\n",
      "            dequantize_per_tensor_202: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_118, 0.03146630525588989, -128, -128, 127, torch.int8);  quantize_per_tensor_118 = None\n",
      "            dequantize_per_tensor_203: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param58, 0.0017977693350985646, 0, -127, 127, torch.int8);  b__frozen_param58 = None\n",
      "            conv2d_58: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_202, dequantize_per_tensor_203, None, [1, 1], [1, 1]);  dequantize_per_tensor_202 = dequantize_per_tensor_203 = None\n",
      "            quantize_per_tensor_119: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_58, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_58 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:747 in forward, code: dequantize_per_tensor_default_178 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_178, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_178 = None\n",
      "            dequantize_per_tensor_204: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_119, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_119 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_27: \"f32[1, 576, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_199, dequantize_per_tensor_204], 1);  dequantize_per_tensor_199 = dequantize_per_tensor_204 = None\n",
      "            quantize_per_tensor_120: \"i8[1, 576, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_27, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_27 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:750 in forward, code: dequantize_per_tensor_default_179 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_179, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_205: \"f32[1, 576, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_120, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:751 in forward, code: dequantize_per_tensor_default_395 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_179, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_179 = None\n",
      "            dequantize_per_tensor_206: \"f32[1, 576, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_120, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_120 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_205, p_features_denseblock3_denselayer11_layers_norm1_weight, p_features_denseblock3_denselayer11_layers_norm1_bias, b_features_denseblock3_denselayer11_layers_norm1_running_mean, b_features_denseblock3_denselayer11_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_205 = p_features_denseblock3_denselayer11_layers_norm1_weight = p_features_denseblock3_denselayer11_layers_norm1_bias = b_features_denseblock3_denselayer11_layers_norm1_running_mean = b_features_denseblock3_denselayer11_layers_norm1_running_var = None\n",
      "            getitem_90: \"f32[1, 576, 16, 16]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
      "            relu_59: \"f32[1, 576, 16, 16]\" = torch.ops.aten.relu.default(getitem_90);  getitem_90 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:759 in forward, code: quantize_per_tensor_default_180 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__59, 0.019942691549658775, -128, -128, 127, torch.int8);  relu__59 = None\n",
      "            quantize_per_tensor_121: \"i8[1, 576, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_59, 0.019942691549658775, -128, -128, 127, torch.int8);  relu_59 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_207: \"f32[1, 576, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_121, 0.019942691549658775, -128, -128, 127, torch.int8);  quantize_per_tensor_121 = None\n",
      "            dequantize_per_tensor_208: \"f32[128, 576, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param59, 0.007619891781359911, 0, -127, 127, torch.int8);  b__frozen_param59 = None\n",
      "            conv2d_59: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_207, dequantize_per_tensor_208, p_features_denseblock3_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_207 = dequantize_per_tensor_208 = p_features_denseblock3_denselayer11_layers_conv1_weight_bias = None\n",
      "            relu_60: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_59);  conv2d_59 = None\n",
      "            quantize_per_tensor_122: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_60, 0.028196442872285843, -128, -128, 127, torch.int8);  relu_60 = None\n",
      "            dequantize_per_tensor_209: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_122, 0.028196442872285843, -128, -128, 127, torch.int8);  quantize_per_tensor_122 = None\n",
      "            dequantize_per_tensor_210: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param60, 0.001737820217385888, 0, -127, 127, torch.int8);  b__frozen_param60 = None\n",
      "            conv2d_60: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_209, dequantize_per_tensor_210, None, [1, 1], [1, 1]);  dequantize_per_tensor_209 = dequantize_per_tensor_210 = None\n",
      "            quantize_per_tensor_123: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_60, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_60 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:772 in forward, code: dequantize_per_tensor_default_184 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_184, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_184 = None\n",
      "            dequantize_per_tensor_211: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_123, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_123 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_28: \"f32[1, 608, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_206, dequantize_per_tensor_211], 1);  dequantize_per_tensor_206 = dequantize_per_tensor_211 = None\n",
      "            quantize_per_tensor_124: \"i8[1, 608, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_28, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_28 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:775 in forward, code: dequantize_per_tensor_default_185 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_185, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_212: \"f32[1, 608, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_124, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:776 in forward, code: dequantize_per_tensor_default_396 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_185, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_185 = None\n",
      "            dequantize_per_tensor_213: \"f32[1, 608, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_124, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_124 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_212, p_features_denseblock3_denselayer12_layers_norm1_weight, p_features_denseblock3_denselayer12_layers_norm1_bias, b_features_denseblock3_denselayer12_layers_norm1_running_mean, b_features_denseblock3_denselayer12_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_212 = p_features_denseblock3_denselayer12_layers_norm1_weight = p_features_denseblock3_denselayer12_layers_norm1_bias = b_features_denseblock3_denselayer12_layers_norm1_running_mean = b_features_denseblock3_denselayer12_layers_norm1_running_var = None\n",
      "            getitem_93: \"f32[1, 608, 16, 16]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
      "            relu_61: \"f32[1, 608, 16, 16]\" = torch.ops.aten.relu.default(getitem_93);  getitem_93 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:784 in forward, code: quantize_per_tensor_default_186 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__61, 0.026162266731262207, -128, -128, 127, torch.int8);  relu__61 = None\n",
      "            quantize_per_tensor_125: \"i8[1, 608, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_61, 0.026162266731262207, -128, -128, 127, torch.int8);  relu_61 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_214: \"f32[1, 608, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_125, 0.026162266731262207, -128, -128, 127, torch.int8);  quantize_per_tensor_125 = None\n",
      "            dequantize_per_tensor_215: \"f32[128, 608, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param61, 0.008822259493172169, 0, -127, 127, torch.int8);  b__frozen_param61 = None\n",
      "            conv2d_61: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_214, dequantize_per_tensor_215, p_features_denseblock3_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_214 = dequantize_per_tensor_215 = p_features_denseblock3_denselayer12_layers_conv1_weight_bias = None\n",
      "            relu_62: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_61);  conv2d_61 = None\n",
      "            quantize_per_tensor_126: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_62, 0.023787932470440865, -128, -128, 127, torch.int8);  relu_62 = None\n",
      "            dequantize_per_tensor_216: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_126, 0.023787932470440865, -128, -128, 127, torch.int8);  quantize_per_tensor_126 = None\n",
      "            dequantize_per_tensor_217: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param62, 0.0027496202383190393, 0, -127, 127, torch.int8);  b__frozen_param62 = None\n",
      "            conv2d_62: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_216, dequantize_per_tensor_217, None, [1, 1], [1, 1]);  dequantize_per_tensor_216 = dequantize_per_tensor_217 = None\n",
      "            quantize_per_tensor_127: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_62, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_62 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:797 in forward, code: dequantize_per_tensor_default_190 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_190, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_190 = None\n",
      "            dequantize_per_tensor_218: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_127, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_127 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_29: \"f32[1, 640, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_213, dequantize_per_tensor_218], 1);  dequantize_per_tensor_213 = dequantize_per_tensor_218 = None\n",
      "            quantize_per_tensor_128: \"i8[1, 640, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_29, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_29 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:800 in forward, code: dequantize_per_tensor_default_191 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_191, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_219: \"f32[1, 640, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_128, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:801 in forward, code: dequantize_per_tensor_default_397 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_191, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_191 = None\n",
      "            dequantize_per_tensor_220: \"f32[1, 640, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_128, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_128 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_219, p_features_denseblock3_denselayer13_layers_norm1_weight, p_features_denseblock3_denselayer13_layers_norm1_bias, b_features_denseblock3_denselayer13_layers_norm1_running_mean, b_features_denseblock3_denselayer13_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_219 = p_features_denseblock3_denselayer13_layers_norm1_weight = p_features_denseblock3_denselayer13_layers_norm1_bias = b_features_denseblock3_denselayer13_layers_norm1_running_mean = b_features_denseblock3_denselayer13_layers_norm1_running_var = None\n",
      "            getitem_96: \"f32[1, 640, 16, 16]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
      "            relu_63: \"f32[1, 640, 16, 16]\" = torch.ops.aten.relu.default(getitem_96);  getitem_96 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:809 in forward, code: quantize_per_tensor_default_192 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__63, 0.017810774967074394, -128, -128, 127, torch.int8);  relu__63 = None\n",
      "            quantize_per_tensor_129: \"i8[1, 640, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_63, 0.017810774967074394, -128, -128, 127, torch.int8);  relu_63 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_221: \"f32[1, 640, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_129, 0.017810774967074394, -128, -128, 127, torch.int8);  quantize_per_tensor_129 = None\n",
      "            dequantize_per_tensor_222: \"f32[128, 640, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param63, 0.006329011637717485, 0, -127, 127, torch.int8);  b__frozen_param63 = None\n",
      "            conv2d_63: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_221, dequantize_per_tensor_222, p_features_denseblock3_denselayer13_layers_conv1_weight_bias);  dequantize_per_tensor_221 = dequantize_per_tensor_222 = p_features_denseblock3_denselayer13_layers_conv1_weight_bias = None\n",
      "            relu_64: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_63);  conv2d_63 = None\n",
      "            quantize_per_tensor_130: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_64, 0.015317624434828758, -128, -128, 127, torch.int8);  relu_64 = None\n",
      "            dequantize_per_tensor_223: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_130, 0.015317624434828758, -128, -128, 127, torch.int8);  quantize_per_tensor_130 = None\n",
      "            dequantize_per_tensor_224: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param64, 0.0022162192035466433, 0, -127, 127, torch.int8);  b__frozen_param64 = None\n",
      "            conv2d_64: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_223, dequantize_per_tensor_224, None, [1, 1], [1, 1]);  dequantize_per_tensor_223 = dequantize_per_tensor_224 = None\n",
      "            quantize_per_tensor_131: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_64, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_64 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:822 in forward, code: dequantize_per_tensor_default_196 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_196, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_196 = None\n",
      "            dequantize_per_tensor_225: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_131, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_131 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_30: \"f32[1, 672, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_220, dequantize_per_tensor_225], 1);  dequantize_per_tensor_220 = dequantize_per_tensor_225 = None\n",
      "            quantize_per_tensor_132: \"i8[1, 672, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_30, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_30 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:825 in forward, code: dequantize_per_tensor_default_197 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_197, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_226: \"f32[1, 672, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_132, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:826 in forward, code: dequantize_per_tensor_default_398 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_197, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_197 = None\n",
      "            dequantize_per_tensor_227: \"f32[1, 672, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_132, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_132 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_226, p_features_denseblock3_denselayer14_layers_norm1_weight, p_features_denseblock3_denselayer14_layers_norm1_bias, b_features_denseblock3_denselayer14_layers_norm1_running_mean, b_features_denseblock3_denselayer14_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_226 = p_features_denseblock3_denselayer14_layers_norm1_weight = p_features_denseblock3_denselayer14_layers_norm1_bias = b_features_denseblock3_denselayer14_layers_norm1_running_mean = b_features_denseblock3_denselayer14_layers_norm1_running_var = None\n",
      "            getitem_99: \"f32[1, 672, 16, 16]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
      "            relu_65: \"f32[1, 672, 16, 16]\" = torch.ops.aten.relu.default(getitem_99);  getitem_99 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:834 in forward, code: quantize_per_tensor_default_198 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__65, 0.019032306969165802, -128, -128, 127, torch.int8);  relu__65 = None\n",
      "            quantize_per_tensor_133: \"i8[1, 672, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_65, 0.019032306969165802, -128, -128, 127, torch.int8);  relu_65 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_228: \"f32[1, 672, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_133, 0.019032306969165802, -128, -128, 127, torch.int8);  quantize_per_tensor_133 = None\n",
      "            dequantize_per_tensor_229: \"f32[128, 672, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param65, 0.007711241953074932, 0, -127, 127, torch.int8);  b__frozen_param65 = None\n",
      "            conv2d_65: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_228, dequantize_per_tensor_229, p_features_denseblock3_denselayer14_layers_conv1_weight_bias);  dequantize_per_tensor_228 = dequantize_per_tensor_229 = p_features_denseblock3_denselayer14_layers_conv1_weight_bias = None\n",
      "            relu_66: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_65);  conv2d_65 = None\n",
      "            quantize_per_tensor_134: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_66, 0.015506373718380928, -128, -128, 127, torch.int8);  relu_66 = None\n",
      "            dequantize_per_tensor_230: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_134, 0.015506373718380928, -128, -128, 127, torch.int8);  quantize_per_tensor_134 = None\n",
      "            dequantize_per_tensor_231: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param66, 0.0019943343941122293, 0, -127, 127, torch.int8);  b__frozen_param66 = None\n",
      "            conv2d_66: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_230, dequantize_per_tensor_231, None, [1, 1], [1, 1]);  dequantize_per_tensor_230 = dequantize_per_tensor_231 = None\n",
      "            quantize_per_tensor_135: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_66, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_66 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:847 in forward, code: dequantize_per_tensor_default_202 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_202, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_202 = None\n",
      "            dequantize_per_tensor_232: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_135, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_135 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_31: \"f32[1, 704, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_227, dequantize_per_tensor_232], 1);  dequantize_per_tensor_227 = dequantize_per_tensor_232 = None\n",
      "            quantize_per_tensor_136: \"i8[1, 704, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_31, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_31 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:850 in forward, code: dequantize_per_tensor_default_203 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_203, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_233: \"f32[1, 704, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_136, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:851 in forward, code: dequantize_per_tensor_default_399 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_203, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_203 = None\n",
      "            dequantize_per_tensor_234: \"f32[1, 704, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_136, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_136 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_233, p_features_denseblock3_denselayer15_layers_norm1_weight, p_features_denseblock3_denselayer15_layers_norm1_bias, b_features_denseblock3_denselayer15_layers_norm1_running_mean, b_features_denseblock3_denselayer15_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_233 = p_features_denseblock3_denselayer15_layers_norm1_weight = p_features_denseblock3_denselayer15_layers_norm1_bias = b_features_denseblock3_denselayer15_layers_norm1_running_mean = b_features_denseblock3_denselayer15_layers_norm1_running_var = None\n",
      "            getitem_102: \"f32[1, 704, 16, 16]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
      "            relu_67: \"f32[1, 704, 16, 16]\" = torch.ops.aten.relu.default(getitem_102);  getitem_102 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:859 in forward, code: quantize_per_tensor_default_204 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__67, 0.018883991986513138, -128, -128, 127, torch.int8);  relu__67 = None\n",
      "            quantize_per_tensor_137: \"i8[1, 704, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_67, 0.018883991986513138, -128, -128, 127, torch.int8);  relu_67 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_235: \"f32[1, 704, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_137, 0.018883991986513138, -128, -128, 127, torch.int8);  quantize_per_tensor_137 = None\n",
      "            dequantize_per_tensor_236: \"f32[128, 704, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param67, 0.0059023452922701836, 0, -127, 127, torch.int8);  b__frozen_param67 = None\n",
      "            conv2d_67: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_235, dequantize_per_tensor_236, p_features_denseblock3_denselayer15_layers_conv1_weight_bias);  dequantize_per_tensor_235 = dequantize_per_tensor_236 = p_features_denseblock3_denselayer15_layers_conv1_weight_bias = None\n",
      "            relu_68: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_67);  conv2d_67 = None\n",
      "            quantize_per_tensor_138: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_68, 0.017909351736307144, -128, -128, 127, torch.int8);  relu_68 = None\n",
      "            dequantize_per_tensor_237: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_138, 0.017909351736307144, -128, -128, 127, torch.int8);  quantize_per_tensor_138 = None\n",
      "            dequantize_per_tensor_238: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param68, 0.002152183325961232, 0, -127, 127, torch.int8);  b__frozen_param68 = None\n",
      "            conv2d_68: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_237, dequantize_per_tensor_238, None, [1, 1], [1, 1]);  dequantize_per_tensor_237 = dequantize_per_tensor_238 = None\n",
      "            quantize_per_tensor_139: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_68, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_68 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:872 in forward, code: dequantize_per_tensor_default_208 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_208, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_208 = None\n",
      "            dequantize_per_tensor_239: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_139, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_139 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_32: \"f32[1, 736, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_234, dequantize_per_tensor_239], 1);  dequantize_per_tensor_234 = dequantize_per_tensor_239 = None\n",
      "            quantize_per_tensor_140: \"i8[1, 736, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_32, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_32 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:875 in forward, code: dequantize_per_tensor_default_209 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_209, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_240: \"f32[1, 736, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_140, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:876 in forward, code: dequantize_per_tensor_default_400 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_209, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_209 = None\n",
      "            dequantize_per_tensor_241: \"f32[1, 736, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_140, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_140 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_240, p_features_denseblock3_denselayer16_layers_norm1_weight, p_features_denseblock3_denselayer16_layers_norm1_bias, b_features_denseblock3_denselayer16_layers_norm1_running_mean, b_features_denseblock3_denselayer16_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_240 = p_features_denseblock3_denselayer16_layers_norm1_weight = p_features_denseblock3_denselayer16_layers_norm1_bias = b_features_denseblock3_denselayer16_layers_norm1_running_mean = b_features_denseblock3_denselayer16_layers_norm1_running_var = None\n",
      "            getitem_105: \"f32[1, 736, 16, 16]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
      "            relu_69: \"f32[1, 736, 16, 16]\" = torch.ops.aten.relu.default(getitem_105);  getitem_105 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:884 in forward, code: quantize_per_tensor_default_210 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__69, 0.020595984533429146, -128, -128, 127, torch.int8);  relu__69 = None\n",
      "            quantize_per_tensor_141: \"i8[1, 736, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_69, 0.020595984533429146, -128, -128, 127, torch.int8);  relu_69 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_242: \"f32[1, 736, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_141, 0.020595984533429146, -128, -128, 127, torch.int8);  quantize_per_tensor_141 = None\n",
      "            dequantize_per_tensor_243: \"f32[128, 736, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param69, 0.007651130668818951, 0, -127, 127, torch.int8);  b__frozen_param69 = None\n",
      "            conv2d_69: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_242, dequantize_per_tensor_243, p_features_denseblock3_denselayer16_layers_conv1_weight_bias);  dequantize_per_tensor_242 = dequantize_per_tensor_243 = p_features_denseblock3_denselayer16_layers_conv1_weight_bias = None\n",
      "            relu_70: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_69);  conv2d_69 = None\n",
      "            quantize_per_tensor_142: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_70, 0.017967142164707184, -128, -128, 127, torch.int8);  relu_70 = None\n",
      "            dequantize_per_tensor_244: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_142, 0.017967142164707184, -128, -128, 127, torch.int8);  quantize_per_tensor_142 = None\n",
      "            dequantize_per_tensor_245: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param70, 0.002101373625919223, 0, -127, 127, torch.int8);  b__frozen_param70 = None\n",
      "            conv2d_70: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_244, dequantize_per_tensor_245, None, [1, 1], [1, 1]);  dequantize_per_tensor_244 = dequantize_per_tensor_245 = None\n",
      "            quantize_per_tensor_143: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_70, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_70 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:897 in forward, code: dequantize_per_tensor_default_214 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_214, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_214 = None\n",
      "            dequantize_per_tensor_246: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_143, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_143 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_33: \"f32[1, 768, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_241, dequantize_per_tensor_246], 1);  dequantize_per_tensor_241 = dequantize_per_tensor_246 = None\n",
      "            quantize_per_tensor_144: \"i8[1, 768, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_33, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_33 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:900 in forward, code: dequantize_per_tensor_default_215 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_215, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_247: \"f32[1, 768, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_144, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:901 in forward, code: dequantize_per_tensor_default_401 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_215, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_215 = None\n",
      "            dequantize_per_tensor_248: \"f32[1, 768, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_144, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_144 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_247, p_features_denseblock3_denselayer17_layers_norm1_weight, p_features_denseblock3_denselayer17_layers_norm1_bias, b_features_denseblock3_denselayer17_layers_norm1_running_mean, b_features_denseblock3_denselayer17_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_247 = p_features_denseblock3_denselayer17_layers_norm1_weight = p_features_denseblock3_denselayer17_layers_norm1_bias = b_features_denseblock3_denselayer17_layers_norm1_running_mean = b_features_denseblock3_denselayer17_layers_norm1_running_var = None\n",
      "            getitem_108: \"f32[1, 768, 16, 16]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
      "            relu_71: \"f32[1, 768, 16, 16]\" = torch.ops.aten.relu.default(getitem_108);  getitem_108 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:909 in forward, code: quantize_per_tensor_default_216 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__71, 0.01922297291457653, -128, -128, 127, torch.int8);  relu__71 = None\n",
      "            quantize_per_tensor_145: \"i8[1, 768, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_71, 0.01922297291457653, -128, -128, 127, torch.int8);  relu_71 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_249: \"f32[1, 768, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_145, 0.01922297291457653, -128, -128, 127, torch.int8);  quantize_per_tensor_145 = None\n",
      "            dequantize_per_tensor_250: \"f32[128, 768, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param71, 0.007255369797348976, 0, -127, 127, torch.int8);  b__frozen_param71 = None\n",
      "            conv2d_71: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_249, dequantize_per_tensor_250, p_features_denseblock3_denselayer17_layers_conv1_weight_bias);  dequantize_per_tensor_249 = dequantize_per_tensor_250 = p_features_denseblock3_denselayer17_layers_conv1_weight_bias = None\n",
      "            relu_72: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_71);  conv2d_71 = None\n",
      "            quantize_per_tensor_146: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_72, 0.022512536495923996, -128, -128, 127, torch.int8);  relu_72 = None\n",
      "            dequantize_per_tensor_251: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_146, 0.022512536495923996, -128, -128, 127, torch.int8);  quantize_per_tensor_146 = None\n",
      "            dequantize_per_tensor_252: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param72, 0.0034767789766192436, 0, -127, 127, torch.int8);  b__frozen_param72 = None\n",
      "            conv2d_72: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_251, dequantize_per_tensor_252, None, [1, 1], [1, 1]);  dequantize_per_tensor_251 = dequantize_per_tensor_252 = None\n",
      "            quantize_per_tensor_147: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_72, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_72 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:922 in forward, code: dequantize_per_tensor_default_220 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_220, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_220 = None\n",
      "            dequantize_per_tensor_253: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_147, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_147 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_34: \"f32[1, 800, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_248, dequantize_per_tensor_253], 1);  dequantize_per_tensor_248 = dequantize_per_tensor_253 = None\n",
      "            quantize_per_tensor_148: \"i8[1, 800, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_34, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_34 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:925 in forward, code: dequantize_per_tensor_default_221 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_221, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_254: \"f32[1, 800, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_148, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:926 in forward, code: dequantize_per_tensor_default_402 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_221, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_221 = None\n",
      "            dequantize_per_tensor_255: \"f32[1, 800, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_148, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_148 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_254, p_features_denseblock3_denselayer18_layers_norm1_weight, p_features_denseblock3_denselayer18_layers_norm1_bias, b_features_denseblock3_denselayer18_layers_norm1_running_mean, b_features_denseblock3_denselayer18_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_254 = p_features_denseblock3_denselayer18_layers_norm1_weight = p_features_denseblock3_denselayer18_layers_norm1_bias = b_features_denseblock3_denselayer18_layers_norm1_running_mean = b_features_denseblock3_denselayer18_layers_norm1_running_var = None\n",
      "            getitem_111: \"f32[1, 800, 16, 16]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
      "            relu_73: \"f32[1, 800, 16, 16]\" = torch.ops.aten.relu.default(getitem_111);  getitem_111 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:934 in forward, code: quantize_per_tensor_default_222 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__73, 0.016622869297862053, -128, -128, 127, torch.int8);  relu__73 = None\n",
      "            quantize_per_tensor_149: \"i8[1, 800, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_73, 0.016622869297862053, -128, -128, 127, torch.int8);  relu_73 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_256: \"f32[1, 800, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_149, 0.016622869297862053, -128, -128, 127, torch.int8);  quantize_per_tensor_149 = None\n",
      "            dequantize_per_tensor_257: \"f32[128, 800, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param73, 0.010191931389272213, 0, -127, 127, torch.int8);  b__frozen_param73 = None\n",
      "            conv2d_73: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_256, dequantize_per_tensor_257, p_features_denseblock3_denselayer18_layers_conv1_weight_bias);  dequantize_per_tensor_256 = dequantize_per_tensor_257 = p_features_denseblock3_denselayer18_layers_conv1_weight_bias = None\n",
      "            relu_74: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_73);  conv2d_73 = None\n",
      "            quantize_per_tensor_150: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_74, 0.027026360854506493, -128, -128, 127, torch.int8);  relu_74 = None\n",
      "            dequantize_per_tensor_258: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_150, 0.027026360854506493, -128, -128, 127, torch.int8);  quantize_per_tensor_150 = None\n",
      "            dequantize_per_tensor_259: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param74, 0.002713581779971719, 0, -127, 127, torch.int8);  b__frozen_param74 = None\n",
      "            conv2d_74: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_258, dequantize_per_tensor_259, None, [1, 1], [1, 1]);  dequantize_per_tensor_258 = dequantize_per_tensor_259 = None\n",
      "            quantize_per_tensor_151: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_74, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_74 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:947 in forward, code: dequantize_per_tensor_default_226 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_226, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_226 = None\n",
      "            dequantize_per_tensor_260: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_151, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_151 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_35: \"f32[1, 832, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_255, dequantize_per_tensor_260], 1);  dequantize_per_tensor_255 = dequantize_per_tensor_260 = None\n",
      "            quantize_per_tensor_152: \"i8[1, 832, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_35, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_35 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:950 in forward, code: dequantize_per_tensor_default_227 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_227, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_261: \"f32[1, 832, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_152, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:951 in forward, code: dequantize_per_tensor_default_403 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_227, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_227 = None\n",
      "            dequantize_per_tensor_262: \"f32[1, 832, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_152, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_152 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_261, p_features_denseblock3_denselayer19_layers_norm1_weight, p_features_denseblock3_denselayer19_layers_norm1_bias, b_features_denseblock3_denselayer19_layers_norm1_running_mean, b_features_denseblock3_denselayer19_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_261 = p_features_denseblock3_denselayer19_layers_norm1_weight = p_features_denseblock3_denselayer19_layers_norm1_bias = b_features_denseblock3_denselayer19_layers_norm1_running_mean = b_features_denseblock3_denselayer19_layers_norm1_running_var = None\n",
      "            getitem_114: \"f32[1, 832, 16, 16]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
      "            relu_75: \"f32[1, 832, 16, 16]\" = torch.ops.aten.relu.default(getitem_114);  getitem_114 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:959 in forward, code: quantize_per_tensor_default_228 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__75, 0.023014681413769722, -128, -128, 127, torch.int8);  relu__75 = None\n",
      "            quantize_per_tensor_153: \"i8[1, 832, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_75, 0.023014681413769722, -128, -128, 127, torch.int8);  relu_75 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_263: \"f32[1, 832, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_153, 0.023014681413769722, -128, -128, 127, torch.int8);  quantize_per_tensor_153 = None\n",
      "            dequantize_per_tensor_264: \"f32[128, 832, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param75, 0.007876643911004066, 0, -127, 127, torch.int8);  b__frozen_param75 = None\n",
      "            conv2d_75: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_263, dequantize_per_tensor_264, p_features_denseblock3_denselayer19_layers_conv1_weight_bias);  dequantize_per_tensor_263 = dequantize_per_tensor_264 = p_features_denseblock3_denselayer19_layers_conv1_weight_bias = None\n",
      "            relu_76: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_75);  conv2d_75 = None\n",
      "            quantize_per_tensor_154: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_76, 0.028720280155539513, -128, -128, 127, torch.int8);  relu_76 = None\n",
      "            dequantize_per_tensor_265: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_154, 0.028720280155539513, -128, -128, 127, torch.int8);  quantize_per_tensor_154 = None\n",
      "            dequantize_per_tensor_266: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param76, 0.001983033725991845, 0, -127, 127, torch.int8);  b__frozen_param76 = None\n",
      "            conv2d_76: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_265, dequantize_per_tensor_266, None, [1, 1], [1, 1]);  dequantize_per_tensor_265 = dequantize_per_tensor_266 = None\n",
      "            quantize_per_tensor_155: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_76, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_76 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:972 in forward, code: dequantize_per_tensor_default_232 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_232, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_232 = None\n",
      "            dequantize_per_tensor_267: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_155, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_155 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_36: \"f32[1, 864, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_262, dequantize_per_tensor_267], 1);  dequantize_per_tensor_262 = dequantize_per_tensor_267 = None\n",
      "            quantize_per_tensor_156: \"i8[1, 864, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_36, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_36 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:975 in forward, code: dequantize_per_tensor_default_233 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_233, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_268: \"f32[1, 864, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_156, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:976 in forward, code: dequantize_per_tensor_default_404 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_233, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_233 = None\n",
      "            dequantize_per_tensor_269: \"f32[1, 864, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_156, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_156 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_268, p_features_denseblock3_denselayer20_layers_norm1_weight, p_features_denseblock3_denselayer20_layers_norm1_bias, b_features_denseblock3_denselayer20_layers_norm1_running_mean, b_features_denseblock3_denselayer20_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_268 = p_features_denseblock3_denselayer20_layers_norm1_weight = p_features_denseblock3_denselayer20_layers_norm1_bias = b_features_denseblock3_denselayer20_layers_norm1_running_mean = b_features_denseblock3_denselayer20_layers_norm1_running_var = None\n",
      "            getitem_117: \"f32[1, 864, 16, 16]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
      "            relu_77: \"f32[1, 864, 16, 16]\" = torch.ops.aten.relu.default(getitem_117);  getitem_117 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:984 in forward, code: quantize_per_tensor_default_234 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__77, 0.02052520401775837, -128, -128, 127, torch.int8);  relu__77 = None\n",
      "            quantize_per_tensor_157: \"i8[1, 864, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_77, 0.02052520401775837, -128, -128, 127, torch.int8);  relu_77 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_270: \"f32[1, 864, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_157, 0.02052520401775837, -128, -128, 127, torch.int8);  quantize_per_tensor_157 = None\n",
      "            dequantize_per_tensor_271: \"f32[128, 864, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param77, 0.005435098893940449, 0, -127, 127, torch.int8);  b__frozen_param77 = None\n",
      "            conv2d_77: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_270, dequantize_per_tensor_271, p_features_denseblock3_denselayer20_layers_conv1_weight_bias);  dequantize_per_tensor_270 = dequantize_per_tensor_271 = p_features_denseblock3_denselayer20_layers_conv1_weight_bias = None\n",
      "            relu_78: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_77);  conv2d_77 = None\n",
      "            quantize_per_tensor_158: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_78, 0.0212941225618124, -128, -128, 127, torch.int8);  relu_78 = None\n",
      "            dequantize_per_tensor_272: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_158, 0.0212941225618124, -128, -128, 127, torch.int8);  quantize_per_tensor_158 = None\n",
      "            dequantize_per_tensor_273: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param78, 0.0013692936627194285, 0, -127, 127, torch.int8);  b__frozen_param78 = None\n",
      "            conv2d_78: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_272, dequantize_per_tensor_273, None, [1, 1], [1, 1]);  dequantize_per_tensor_272 = dequantize_per_tensor_273 = None\n",
      "            quantize_per_tensor_159: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_78, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_78 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:997 in forward, code: dequantize_per_tensor_default_238 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_238, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_238 = None\n",
      "            dequantize_per_tensor_274: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_159, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_159 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_37: \"f32[1, 896, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_269, dequantize_per_tensor_274], 1);  dequantize_per_tensor_269 = dequantize_per_tensor_274 = None\n",
      "            quantize_per_tensor_160: \"i8[1, 896, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_37, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_37 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1000 in forward, code: dequantize_per_tensor_default_239 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_239, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_275: \"f32[1, 896, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_160, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1001 in forward, code: dequantize_per_tensor_default_405 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_239, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_239 = None\n",
      "            dequantize_per_tensor_276: \"f32[1, 896, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_160, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_160 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_275, p_features_denseblock3_denselayer21_layers_norm1_weight, p_features_denseblock3_denselayer21_layers_norm1_bias, b_features_denseblock3_denselayer21_layers_norm1_running_mean, b_features_denseblock3_denselayer21_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_275 = p_features_denseblock3_denselayer21_layers_norm1_weight = p_features_denseblock3_denselayer21_layers_norm1_bias = b_features_denseblock3_denselayer21_layers_norm1_running_mean = b_features_denseblock3_denselayer21_layers_norm1_running_var = None\n",
      "            getitem_120: \"f32[1, 896, 16, 16]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
      "            relu_79: \"f32[1, 896, 16, 16]\" = torch.ops.aten.relu.default(getitem_120);  getitem_120 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1009 in forward, code: quantize_per_tensor_default_240 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__79, 0.023304402828216553, -128, -128, 127, torch.int8);  relu__79 = None\n",
      "            quantize_per_tensor_161: \"i8[1, 896, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_79, 0.023304402828216553, -128, -128, 127, torch.int8);  relu_79 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_277: \"f32[1, 896, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_161, 0.023304402828216553, -128, -128, 127, torch.int8);  quantize_per_tensor_161 = None\n",
      "            dequantize_per_tensor_278: \"f32[128, 896, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param79, 0.007689815480262041, 0, -127, 127, torch.int8);  b__frozen_param79 = None\n",
      "            conv2d_79: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_277, dequantize_per_tensor_278, p_features_denseblock3_denselayer21_layers_conv1_weight_bias);  dequantize_per_tensor_277 = dequantize_per_tensor_278 = p_features_denseblock3_denselayer21_layers_conv1_weight_bias = None\n",
      "            relu_80: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_79);  conv2d_79 = None\n",
      "            quantize_per_tensor_162: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_80, 0.02554982341825962, -128, -128, 127, torch.int8);  relu_80 = None\n",
      "            dequantize_per_tensor_279: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_162, 0.02554982341825962, -128, -128, 127, torch.int8);  quantize_per_tensor_162 = None\n",
      "            dequantize_per_tensor_280: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param80, 0.0014898556983098388, 0, -127, 127, torch.int8);  b__frozen_param80 = None\n",
      "            conv2d_80: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_279, dequantize_per_tensor_280, None, [1, 1], [1, 1]);  dequantize_per_tensor_279 = dequantize_per_tensor_280 = None\n",
      "            quantize_per_tensor_163: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_80, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_80 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1022 in forward, code: dequantize_per_tensor_default_244 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_244, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_244 = None\n",
      "            dequantize_per_tensor_281: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_163, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_163 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_38: \"f32[1, 928, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_276, dequantize_per_tensor_281], 1);  dequantize_per_tensor_276 = dequantize_per_tensor_281 = None\n",
      "            quantize_per_tensor_164: \"i8[1, 928, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_38, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_38 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1025 in forward, code: dequantize_per_tensor_default_245 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_245, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_282: \"f32[1, 928, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_164, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1026 in forward, code: dequantize_per_tensor_default_406 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_245, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_245 = None\n",
      "            dequantize_per_tensor_283: \"f32[1, 928, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_164, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_164 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_282, p_features_denseblock3_denselayer22_layers_norm1_weight, p_features_denseblock3_denselayer22_layers_norm1_bias, b_features_denseblock3_denselayer22_layers_norm1_running_mean, b_features_denseblock3_denselayer22_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_282 = p_features_denseblock3_denselayer22_layers_norm1_weight = p_features_denseblock3_denselayer22_layers_norm1_bias = b_features_denseblock3_denselayer22_layers_norm1_running_mean = b_features_denseblock3_denselayer22_layers_norm1_running_var = None\n",
      "            getitem_123: \"f32[1, 928, 16, 16]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
      "            relu_81: \"f32[1, 928, 16, 16]\" = torch.ops.aten.relu.default(getitem_123);  getitem_123 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1034 in forward, code: quantize_per_tensor_default_246 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__81, 0.013866767287254333, -128, -128, 127, torch.int8);  relu__81 = None\n",
      "            quantize_per_tensor_165: \"i8[1, 928, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_81, 0.013866767287254333, -128, -128, 127, torch.int8);  relu_81 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_284: \"f32[1, 928, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_165, 0.013866767287254333, -128, -128, 127, torch.int8);  quantize_per_tensor_165 = None\n",
      "            dequantize_per_tensor_285: \"f32[128, 928, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param81, 0.010334867052733898, 0, -127, 127, torch.int8);  b__frozen_param81 = None\n",
      "            conv2d_81: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_284, dequantize_per_tensor_285, p_features_denseblock3_denselayer22_layers_conv1_weight_bias);  dequantize_per_tensor_284 = dequantize_per_tensor_285 = p_features_denseblock3_denselayer22_layers_conv1_weight_bias = None\n",
      "            relu_82: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_81);  conv2d_81 = None\n",
      "            quantize_per_tensor_166: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_82, 0.022194935008883476, -128, -128, 127, torch.int8);  relu_82 = None\n",
      "            dequantize_per_tensor_286: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_166, 0.022194935008883476, -128, -128, 127, torch.int8);  quantize_per_tensor_166 = None\n",
      "            dequantize_per_tensor_287: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param82, 0.001793096074834466, 0, -127, 127, torch.int8);  b__frozen_param82 = None\n",
      "            conv2d_82: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_286, dequantize_per_tensor_287, None, [1, 1], [1, 1]);  dequantize_per_tensor_286 = dequantize_per_tensor_287 = None\n",
      "            quantize_per_tensor_167: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_82, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_82 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1047 in forward, code: dequantize_per_tensor_default_250 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_250, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_250 = None\n",
      "            dequantize_per_tensor_288: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_167, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_167 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_39: \"f32[1, 960, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_283, dequantize_per_tensor_288], 1);  dequantize_per_tensor_283 = dequantize_per_tensor_288 = None\n",
      "            quantize_per_tensor_168: \"i8[1, 960, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_39, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_39 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1050 in forward, code: dequantize_per_tensor_default_251 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_251, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_289: \"f32[1, 960, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_168, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1051 in forward, code: dequantize_per_tensor_default_407 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_251, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_251 = None\n",
      "            dequantize_per_tensor_290: \"f32[1, 960, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_168, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_168 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_289, p_features_denseblock3_denselayer23_layers_norm1_weight, p_features_denseblock3_denselayer23_layers_norm1_bias, b_features_denseblock3_denselayer23_layers_norm1_running_mean, b_features_denseblock3_denselayer23_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_289 = p_features_denseblock3_denselayer23_layers_norm1_weight = p_features_denseblock3_denselayer23_layers_norm1_bias = b_features_denseblock3_denselayer23_layers_norm1_running_mean = b_features_denseblock3_denselayer23_layers_norm1_running_var = None\n",
      "            getitem_126: \"f32[1, 960, 16, 16]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
      "            relu_83: \"f32[1, 960, 16, 16]\" = torch.ops.aten.relu.default(getitem_126);  getitem_126 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1059 in forward, code: quantize_per_tensor_default_252 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__83, 0.02189573459327221, -128, -128, 127, torch.int8);  relu__83 = None\n",
      "            quantize_per_tensor_169: \"i8[1, 960, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_83, 0.02189573459327221, -128, -128, 127, torch.int8);  relu_83 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_291: \"f32[1, 960, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_169, 0.02189573459327221, -128, -128, 127, torch.int8);  quantize_per_tensor_169 = None\n",
      "            dequantize_per_tensor_292: \"f32[128, 960, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param83, 0.008317476138472557, 0, -127, 127, torch.int8);  b__frozen_param83 = None\n",
      "            conv2d_83: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_291, dequantize_per_tensor_292, p_features_denseblock3_denselayer23_layers_conv1_weight_bias);  dequantize_per_tensor_291 = dequantize_per_tensor_292 = p_features_denseblock3_denselayer23_layers_conv1_weight_bias = None\n",
      "            relu_84: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_83);  conv2d_83 = None\n",
      "            quantize_per_tensor_170: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_84, 0.01919465884566307, -128, -128, 127, torch.int8);  relu_84 = None\n",
      "            dequantize_per_tensor_293: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_170, 0.01919465884566307, -128, -128, 127, torch.int8);  quantize_per_tensor_170 = None\n",
      "            dequantize_per_tensor_294: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param84, 0.0017358582699671388, 0, -127, 127, torch.int8);  b__frozen_param84 = None\n",
      "            conv2d_84: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_293, dequantize_per_tensor_294, None, [1, 1], [1, 1]);  dequantize_per_tensor_293 = dequantize_per_tensor_294 = None\n",
      "            quantize_per_tensor_171: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_84, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_84 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1072 in forward, code: dequantize_per_tensor_default_256 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_256, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_256 = None\n",
      "            dequantize_per_tensor_295: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_171, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_171 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_40: \"f32[1, 992, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_290, dequantize_per_tensor_295], 1);  dequantize_per_tensor_290 = dequantize_per_tensor_295 = None\n",
      "            quantize_per_tensor_172: \"i8[1, 992, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_40, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_40 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1075 in forward, code: dequantize_per_tensor_default_257 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_257, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_296: \"f32[1, 992, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_172, 0.07365507632493973, 6, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1076 in forward, code: dequantize_per_tensor_default_408 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_257, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_257 = None\n",
      "            dequantize_per_tensor_297: \"f32[1, 992, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_172, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_172 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_296, p_features_denseblock3_denselayer24_layers_norm1_weight, p_features_denseblock3_denselayer24_layers_norm1_bias, b_features_denseblock3_denselayer24_layers_norm1_running_mean, b_features_denseblock3_denselayer24_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_296 = p_features_denseblock3_denselayer24_layers_norm1_weight = p_features_denseblock3_denselayer24_layers_norm1_bias = b_features_denseblock3_denselayer24_layers_norm1_running_mean = b_features_denseblock3_denselayer24_layers_norm1_running_var = None\n",
      "            getitem_129: \"f32[1, 992, 16, 16]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
      "            relu_85: \"f32[1, 992, 16, 16]\" = torch.ops.aten.relu.default(getitem_129);  getitem_129 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1084 in forward, code: quantize_per_tensor_default_258 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__85, 0.022350188344717026, -128, -128, 127, torch.int8);  relu__85 = None\n",
      "            quantize_per_tensor_173: \"i8[1, 992, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_85, 0.022350188344717026, -128, -128, 127, torch.int8);  relu_85 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_298: \"f32[1, 992, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_173, 0.022350188344717026, -128, -128, 127, torch.int8);  quantize_per_tensor_173 = None\n",
      "            dequantize_per_tensor_299: \"f32[128, 992, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param85, 0.0063673402182757854, 0, -127, 127, torch.int8);  b__frozen_param85 = None\n",
      "            conv2d_85: \"f32[1, 128, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_298, dequantize_per_tensor_299, p_features_denseblock3_denselayer24_layers_conv1_weight_bias);  dequantize_per_tensor_298 = dequantize_per_tensor_299 = p_features_denseblock3_denselayer24_layers_conv1_weight_bias = None\n",
      "            relu_86: \"f32[1, 128, 16, 16]\" = torch.ops.aten.relu.default(conv2d_85);  conv2d_85 = None\n",
      "            quantize_per_tensor_174: \"i8[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_86, 0.016037991270422935, -128, -128, 127, torch.int8);  relu_86 = None\n",
      "            dequantize_per_tensor_300: \"f32[1, 128, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_174, 0.016037991270422935, -128, -128, 127, torch.int8);  quantize_per_tensor_174 = None\n",
      "            dequantize_per_tensor_301: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param86, 0.0013281713472679257, 0, -127, 127, torch.int8);  b__frozen_param86 = None\n",
      "            conv2d_86: \"f32[1, 32, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_300, dequantize_per_tensor_301, None, [1, 1], [1, 1]);  dequantize_per_tensor_300 = dequantize_per_tensor_301 = None\n",
      "            quantize_per_tensor_175: \"i8[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_86, 0.07365507632493973, 6, -128, 127, torch.int8);  conv2d_86 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1097 in forward, code: dequantize_per_tensor_default_262 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_262, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_262 = None\n",
      "            dequantize_per_tensor_302: \"f32[1, 32, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_175, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_175 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_41: \"f32[1, 1024, 16, 16]\" = torch.ops.aten.cat.default([dequantize_per_tensor_297, dequantize_per_tensor_302], 1);  dequantize_per_tensor_297 = dequantize_per_tensor_302 = None\n",
      "            quantize_per_tensor_176: \"i8[1, 1024, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_41, 0.07365507632493973, 6, -128, 127, torch.int8);  cat_41 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1100 in forward, code: dequantize_per_tensor_default_263 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_263, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_default_263 = None\n",
      "            dequantize_per_tensor_303: \"f32[1, 1024, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_176, 0.07365507632493973, 6, -128, 127, torch.int8);  quantize_per_tensor_176 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_303, p_features_transition3_norm_weight, p_features_transition3_norm_bias, b_features_transition3_norm_running_mean, b_features_transition3_norm_running_var, 0.1, 1e-05);  dequantize_per_tensor_303 = p_features_transition3_norm_weight = p_features_transition3_norm_bias = b_features_transition3_norm_running_mean = b_features_transition3_norm_running_var = None\n",
      "            getitem_132: \"f32[1, 1024, 16, 16]\" = _native_batch_norm_legit_no_training_44[0];  _native_batch_norm_legit_no_training_44 = None\n",
      "            relu_87: \"f32[1, 1024, 16, 16]\" = torch.ops.aten.relu.default(getitem_132);  getitem_132 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1108 in forward, code: quantize_per_tensor_default_264 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__87, 0.041730694472789764, -128, -128, 127, torch.int8);  relu__87 = None\n",
      "            quantize_per_tensor_177: \"i8[1, 1024, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_87, 0.041730694472789764, -128, -128, 127, torch.int8);  relu_87 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            dequantize_per_tensor_304: \"f32[1, 1024, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_177, 0.041730694472789764, -128, -128, 127, torch.int8);  quantize_per_tensor_177 = None\n",
      "            dequantize_per_tensor_305: \"f32[512, 1024, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param87, 0.005728257820010185, 0, -127, 127, torch.int8);  b__frozen_param87 = None\n",
      "            conv2d_87: \"f32[1, 512, 16, 16]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_304, dequantize_per_tensor_305);  dequantize_per_tensor_304 = dequantize_per_tensor_305 = None\n",
      "            quantize_per_tensor_178: \"i8[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_87, 0.049894753843545914, -6, -128, 127, torch.int8);  conv2d_87 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1114 in forward, code: dequantize_per_tensor_default_266 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_266, 0.049894753843545914, -6, -128, 127, torch.int8);  quantize_per_tensor_default_266 = None\n",
      "            dequantize_per_tensor_306: \"f32[1, 512, 16, 16]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_178, 0.049894753843545914, -6, -128, 127, torch.int8);  quantize_per_tensor_178 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            avg_pool2d_2: \"f32[1, 512, 8, 8]\" = torch.ops.aten.avg_pool2d.default(dequantize_per_tensor_306, [2, 2], [2, 2]);  dequantize_per_tensor_306 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1116 in forward, code: quantize_per_tensor_default_267 = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_2, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            quantize_per_tensor_179: \"i8[1, 512, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(avg_pool2d_2, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1117 in forward, code: dequantize_per_tensor_default_267 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_267, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_267 = None\n",
      "            dequantize_per_tensor_307: \"f32[1, 512, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_179, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_179 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(avg_pool2d_2, p_features_denseblock4_denselayer1_layers_norm1_weight, p_features_denseblock4_denselayer1_layers_norm1_bias, b_features_denseblock4_denselayer1_layers_norm1_running_mean, b_features_denseblock4_denselayer1_layers_norm1_running_var, 0.1, 1e-05);  avg_pool2d_2 = p_features_denseblock4_denselayer1_layers_norm1_weight = p_features_denseblock4_denselayer1_layers_norm1_bias = b_features_denseblock4_denselayer1_layers_norm1_running_mean = b_features_denseblock4_denselayer1_layers_norm1_running_var = None\n",
      "            getitem_135: \"f32[1, 512, 8, 8]\" = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
      "            relu_88: \"f32[1, 512, 8, 8]\" = torch.ops.aten.relu.default(getitem_135);  getitem_135 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1125 in forward, code: quantize_per_tensor_default_268 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__88, 0.024571435526013374, -128, -128, 127, torch.int8);  relu__88 = None\n",
      "            quantize_per_tensor_180: \"i8[1, 512, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_88, 0.024571435526013374, -128, -128, 127, torch.int8);  relu_88 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_308: \"f32[1, 512, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_180, 0.024571435526013374, -128, -128, 127, torch.int8);  quantize_per_tensor_180 = None\n",
      "            dequantize_per_tensor_309: \"f32[128, 512, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param88, 0.006350560113787651, 0, -127, 127, torch.int8);  b__frozen_param88 = None\n",
      "            conv2d_88: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_308, dequantize_per_tensor_309, p_features_denseblock4_denselayer1_layers_conv1_weight_bias);  dequantize_per_tensor_308 = dequantize_per_tensor_309 = p_features_denseblock4_denselayer1_layers_conv1_weight_bias = None\n",
      "            relu_89: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_88);  conv2d_88 = None\n",
      "            quantize_per_tensor_181: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_89, 0.016578614711761475, -128, -128, 127, torch.int8);  relu_89 = None\n",
      "            dequantize_per_tensor_310: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_181, 0.016578614711761475, -128, -128, 127, torch.int8);  quantize_per_tensor_181 = None\n",
      "            dequantize_per_tensor_311: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param89, 0.001437353203073144, 0, -127, 127, torch.int8);  b__frozen_param89 = None\n",
      "            conv2d_89: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_310, dequantize_per_tensor_311, None, [1, 1], [1, 1]);  dequantize_per_tensor_310 = dequantize_per_tensor_311 = None\n",
      "            quantize_per_tensor_182: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_89, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_89 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1138 in forward, code: dequantize_per_tensor_default_272 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_272, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_272 = None\n",
      "            dequantize_per_tensor_312: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_182, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_182 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_42: \"f32[1, 544, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_307, dequantize_per_tensor_312], 1);  dequantize_per_tensor_307 = dequantize_per_tensor_312 = None\n",
      "            quantize_per_tensor_183: \"i8[1, 544, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_42, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_42 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1141 in forward, code: dequantize_per_tensor_default_273 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_273, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_313: \"f32[1, 544, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_183, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1142 in forward, code: dequantize_per_tensor_default_409 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_273, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_273 = None\n",
      "            dequantize_per_tensor_314: \"f32[1, 544, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_183, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_183 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_313, p_features_denseblock4_denselayer2_layers_norm1_weight, p_features_denseblock4_denselayer2_layers_norm1_bias, b_features_denseblock4_denselayer2_layers_norm1_running_mean, b_features_denseblock4_denselayer2_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_313 = p_features_denseblock4_denselayer2_layers_norm1_weight = p_features_denseblock4_denselayer2_layers_norm1_bias = b_features_denseblock4_denselayer2_layers_norm1_running_mean = b_features_denseblock4_denselayer2_layers_norm1_running_var = None\n",
      "            getitem_138: \"f32[1, 544, 8, 8]\" = _native_batch_norm_legit_no_training_46[0];  _native_batch_norm_legit_no_training_46 = None\n",
      "            relu_90: \"f32[1, 544, 8, 8]\" = torch.ops.aten.relu.default(getitem_138);  getitem_138 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1150 in forward, code: quantize_per_tensor_default_274 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__90, 0.028671227395534515, -128, -128, 127, torch.int8);  relu__90 = None\n",
      "            quantize_per_tensor_184: \"i8[1, 544, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_90, 0.028671227395534515, -128, -128, 127, torch.int8);  relu_90 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_315: \"f32[1, 544, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_184, 0.028671227395534515, -128, -128, 127, torch.int8);  quantize_per_tensor_184 = None\n",
      "            dequantize_per_tensor_316: \"f32[128, 544, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param90, 0.006311160512268543, 0, -127, 127, torch.int8);  b__frozen_param90 = None\n",
      "            conv2d_90: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_315, dequantize_per_tensor_316, p_features_denseblock4_denselayer2_layers_conv1_weight_bias);  dequantize_per_tensor_315 = dequantize_per_tensor_316 = p_features_denseblock4_denselayer2_layers_conv1_weight_bias = None\n",
      "            relu_91: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_90);  conv2d_90 = None\n",
      "            quantize_per_tensor_185: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_91, 0.02069302648305893, -128, -128, 127, torch.int8);  relu_91 = None\n",
      "            dequantize_per_tensor_317: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_185, 0.02069302648305893, -128, -128, 127, torch.int8);  quantize_per_tensor_185 = None\n",
      "            dequantize_per_tensor_318: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param91, 0.0016781366430222988, 0, -127, 127, torch.int8);  b__frozen_param91 = None\n",
      "            conv2d_91: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_317, dequantize_per_tensor_318, None, [1, 1], [1, 1]);  dequantize_per_tensor_317 = dequantize_per_tensor_318 = None\n",
      "            quantize_per_tensor_186: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_91, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_91 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1163 in forward, code: dequantize_per_tensor_default_278 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_278, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_278 = None\n",
      "            dequantize_per_tensor_319: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_186, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_186 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_43: \"f32[1, 576, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_314, dequantize_per_tensor_319], 1);  dequantize_per_tensor_314 = dequantize_per_tensor_319 = None\n",
      "            quantize_per_tensor_187: \"i8[1, 576, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_43, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_43 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1166 in forward, code: dequantize_per_tensor_default_279 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_279, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_320: \"f32[1, 576, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_187, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1167 in forward, code: dequantize_per_tensor_default_410 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_279, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_279 = None\n",
      "            dequantize_per_tensor_321: \"f32[1, 576, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_187, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_187 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_320, p_features_denseblock4_denselayer3_layers_norm1_weight, p_features_denseblock4_denselayer3_layers_norm1_bias, b_features_denseblock4_denselayer3_layers_norm1_running_mean, b_features_denseblock4_denselayer3_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_320 = p_features_denseblock4_denselayer3_layers_norm1_weight = p_features_denseblock4_denselayer3_layers_norm1_bias = b_features_denseblock4_denselayer3_layers_norm1_running_mean = b_features_denseblock4_denselayer3_layers_norm1_running_var = None\n",
      "            getitem_141: \"f32[1, 576, 8, 8]\" = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
      "            relu_92: \"f32[1, 576, 8, 8]\" = torch.ops.aten.relu.default(getitem_141);  getitem_141 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1175 in forward, code: quantize_per_tensor_default_280 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__92, 0.025901002809405327, -128, -128, 127, torch.int8);  relu__92 = None\n",
      "            quantize_per_tensor_188: \"i8[1, 576, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_92, 0.025901002809405327, -128, -128, 127, torch.int8);  relu_92 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_322: \"f32[1, 576, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_188, 0.025901002809405327, -128, -128, 127, torch.int8);  quantize_per_tensor_188 = None\n",
      "            dequantize_per_tensor_323: \"f32[128, 576, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param92, 0.00706758676096797, 0, -127, 127, torch.int8);  b__frozen_param92 = None\n",
      "            conv2d_92: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_322, dequantize_per_tensor_323, p_features_denseblock4_denselayer3_layers_conv1_weight_bias);  dequantize_per_tensor_322 = dequantize_per_tensor_323 = p_features_denseblock4_denselayer3_layers_conv1_weight_bias = None\n",
      "            relu_93: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_92);  conv2d_92 = None\n",
      "            quantize_per_tensor_189: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_93, 0.029033469036221504, -128, -128, 127, torch.int8);  relu_93 = None\n",
      "            dequantize_per_tensor_324: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_189, 0.029033469036221504, -128, -128, 127, torch.int8);  quantize_per_tensor_189 = None\n",
      "            dequantize_per_tensor_325: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param93, 0.0025906572118401527, 0, -127, 127, torch.int8);  b__frozen_param93 = None\n",
      "            conv2d_93: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_324, dequantize_per_tensor_325, None, [1, 1], [1, 1]);  dequantize_per_tensor_324 = dequantize_per_tensor_325 = None\n",
      "            quantize_per_tensor_190: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_93, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_93 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1188 in forward, code: dequantize_per_tensor_default_284 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_284, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_284 = None\n",
      "            dequantize_per_tensor_326: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_190, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_190 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_44: \"f32[1, 608, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_321, dequantize_per_tensor_326], 1);  dequantize_per_tensor_321 = dequantize_per_tensor_326 = None\n",
      "            quantize_per_tensor_191: \"i8[1, 608, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_44, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_44 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1191 in forward, code: dequantize_per_tensor_default_285 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_285, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_327: \"f32[1, 608, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_191, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1192 in forward, code: dequantize_per_tensor_default_411 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_285, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_285 = None\n",
      "            dequantize_per_tensor_328: \"f32[1, 608, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_191, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_191 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_327, p_features_denseblock4_denselayer4_layers_norm1_weight, p_features_denseblock4_denselayer4_layers_norm1_bias, b_features_denseblock4_denselayer4_layers_norm1_running_mean, b_features_denseblock4_denselayer4_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_327 = p_features_denseblock4_denselayer4_layers_norm1_weight = p_features_denseblock4_denselayer4_layers_norm1_bias = b_features_denseblock4_denselayer4_layers_norm1_running_mean = b_features_denseblock4_denselayer4_layers_norm1_running_var = None\n",
      "            getitem_144: \"f32[1, 608, 8, 8]\" = _native_batch_norm_legit_no_training_48[0];  _native_batch_norm_legit_no_training_48 = None\n",
      "            relu_94: \"f32[1, 608, 8, 8]\" = torch.ops.aten.relu.default(getitem_144);  getitem_144 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1200 in forward, code: quantize_per_tensor_default_286 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__94, 0.02989189326763153, -128, -128, 127, torch.int8);  relu__94 = None\n",
      "            quantize_per_tensor_192: \"i8[1, 608, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_94, 0.02989189326763153, -128, -128, 127, torch.int8);  relu_94 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_329: \"f32[1, 608, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_192, 0.02989189326763153, -128, -128, 127, torch.int8);  quantize_per_tensor_192 = None\n",
      "            dequantize_per_tensor_330: \"f32[128, 608, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param94, 0.00636905524879694, 0, -127, 127, torch.int8);  b__frozen_param94 = None\n",
      "            conv2d_94: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_329, dequantize_per_tensor_330, p_features_denseblock4_denselayer4_layers_conv1_weight_bias);  dequantize_per_tensor_329 = dequantize_per_tensor_330 = p_features_denseblock4_denselayer4_layers_conv1_weight_bias = None\n",
      "            relu_95: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_94);  conv2d_94 = None\n",
      "            quantize_per_tensor_193: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_95, 0.01768406666815281, -128, -128, 127, torch.int8);  relu_95 = None\n",
      "            dequantize_per_tensor_331: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_193, 0.01768406666815281, -128, -128, 127, torch.int8);  quantize_per_tensor_193 = None\n",
      "            dequantize_per_tensor_332: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param95, 0.002960711717605591, 0, -127, 127, torch.int8);  b__frozen_param95 = None\n",
      "            conv2d_95: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_331, dequantize_per_tensor_332, None, [1, 1], [1, 1]);  dequantize_per_tensor_331 = dequantize_per_tensor_332 = None\n",
      "            quantize_per_tensor_194: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_95, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_95 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1213 in forward, code: dequantize_per_tensor_default_290 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_290, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_290 = None\n",
      "            dequantize_per_tensor_333: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_194, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_194 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_45: \"f32[1, 640, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_328, dequantize_per_tensor_333], 1);  dequantize_per_tensor_328 = dequantize_per_tensor_333 = None\n",
      "            quantize_per_tensor_195: \"i8[1, 640, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_45, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_45 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1216 in forward, code: dequantize_per_tensor_default_291 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_291, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_334: \"f32[1, 640, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_195, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1217 in forward, code: dequantize_per_tensor_default_412 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_291, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_291 = None\n",
      "            dequantize_per_tensor_335: \"f32[1, 640, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_195, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_195 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_334, p_features_denseblock4_denselayer5_layers_norm1_weight, p_features_denseblock4_denselayer5_layers_norm1_bias, b_features_denseblock4_denselayer5_layers_norm1_running_mean, b_features_denseblock4_denselayer5_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_334 = p_features_denseblock4_denselayer5_layers_norm1_weight = p_features_denseblock4_denselayer5_layers_norm1_bias = b_features_denseblock4_denselayer5_layers_norm1_running_mean = b_features_denseblock4_denselayer5_layers_norm1_running_var = None\n",
      "            getitem_147: \"f32[1, 640, 8, 8]\" = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
      "            relu_96: \"f32[1, 640, 8, 8]\" = torch.ops.aten.relu.default(getitem_147);  getitem_147 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1225 in forward, code: quantize_per_tensor_default_292 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__96, 0.02547215297818184, -128, -128, 127, torch.int8);  relu__96 = None\n",
      "            quantize_per_tensor_196: \"i8[1, 640, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_96, 0.02547215297818184, -128, -128, 127, torch.int8);  relu_96 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_336: \"f32[1, 640, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_196, 0.02547215297818184, -128, -128, 127, torch.int8);  quantize_per_tensor_196 = None\n",
      "            dequantize_per_tensor_337: \"f32[128, 640, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param96, 0.004713223781436682, 0, -127, 127, torch.int8);  b__frozen_param96 = None\n",
      "            conv2d_96: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_336, dequantize_per_tensor_337, p_features_denseblock4_denselayer5_layers_conv1_weight_bias);  dequantize_per_tensor_336 = dequantize_per_tensor_337 = p_features_denseblock4_denselayer5_layers_conv1_weight_bias = None\n",
      "            relu_97: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_96);  conv2d_96 = None\n",
      "            quantize_per_tensor_197: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_97, 0.01152466144412756, -128, -128, 127, torch.int8);  relu_97 = None\n",
      "            dequantize_per_tensor_338: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_197, 0.01152466144412756, -128, -128, 127, torch.int8);  quantize_per_tensor_197 = None\n",
      "            dequantize_per_tensor_339: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param97, 0.0012787734158337116, 0, -127, 127, torch.int8);  b__frozen_param97 = None\n",
      "            conv2d_97: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_338, dequantize_per_tensor_339, None, [1, 1], [1, 1]);  dequantize_per_tensor_338 = dequantize_per_tensor_339 = None\n",
      "            quantize_per_tensor_198: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_97, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_97 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1238 in forward, code: dequantize_per_tensor_default_296 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_296, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_296 = None\n",
      "            dequantize_per_tensor_340: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_198, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_198 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_46: \"f32[1, 672, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_335, dequantize_per_tensor_340], 1);  dequantize_per_tensor_335 = dequantize_per_tensor_340 = None\n",
      "            quantize_per_tensor_199: \"i8[1, 672, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_46, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_46 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1241 in forward, code: dequantize_per_tensor_default_297 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_297, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_341: \"f32[1, 672, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_199, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1242 in forward, code: dequantize_per_tensor_default_413 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_297, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_297 = None\n",
      "            dequantize_per_tensor_342: \"f32[1, 672, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_199, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_199 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_341, p_features_denseblock4_denselayer6_layers_norm1_weight, p_features_denseblock4_denselayer6_layers_norm1_bias, b_features_denseblock4_denselayer6_layers_norm1_running_mean, b_features_denseblock4_denselayer6_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_341 = p_features_denseblock4_denselayer6_layers_norm1_weight = p_features_denseblock4_denselayer6_layers_norm1_bias = b_features_denseblock4_denselayer6_layers_norm1_running_mean = b_features_denseblock4_denselayer6_layers_norm1_running_var = None\n",
      "            getitem_150: \"f32[1, 672, 8, 8]\" = _native_batch_norm_legit_no_training_50[0];  _native_batch_norm_legit_no_training_50 = None\n",
      "            relu_98: \"f32[1, 672, 8, 8]\" = torch.ops.aten.relu.default(getitem_150);  getitem_150 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1250 in forward, code: quantize_per_tensor_default_298 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__98, 0.02813451737165451, -128, -128, 127, torch.int8);  relu__98 = None\n",
      "            quantize_per_tensor_200: \"i8[1, 672, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_98, 0.02813451737165451, -128, -128, 127, torch.int8);  relu_98 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_343: \"f32[1, 672, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_200, 0.02813451737165451, -128, -128, 127, torch.int8);  quantize_per_tensor_200 = None\n",
      "            dequantize_per_tensor_344: \"f32[128, 672, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param98, 0.009045382030308247, 0, -127, 127, torch.int8);  b__frozen_param98 = None\n",
      "            conv2d_98: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_343, dequantize_per_tensor_344, p_features_denseblock4_denselayer6_layers_conv1_weight_bias);  dequantize_per_tensor_343 = dequantize_per_tensor_344 = p_features_denseblock4_denselayer6_layers_conv1_weight_bias = None\n",
      "            relu_99: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_98);  conv2d_98 = None\n",
      "            quantize_per_tensor_201: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_99, 0.0340961329638958, -128, -128, 127, torch.int8);  relu_99 = None\n",
      "            dequantize_per_tensor_345: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_201, 0.0340961329638958, -128, -128, 127, torch.int8);  quantize_per_tensor_201 = None\n",
      "            dequantize_per_tensor_346: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param99, 0.0038567937444895506, 0, -127, 127, torch.int8);  b__frozen_param99 = None\n",
      "            conv2d_99: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_345, dequantize_per_tensor_346, None, [1, 1], [1, 1]);  dequantize_per_tensor_345 = dequantize_per_tensor_346 = None\n",
      "            quantize_per_tensor_202: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_99, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_99 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1263 in forward, code: dequantize_per_tensor_default_302 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_302, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_302 = None\n",
      "            dequantize_per_tensor_347: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_202, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_202 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_47: \"f32[1, 704, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_342, dequantize_per_tensor_347], 1);  dequantize_per_tensor_342 = dequantize_per_tensor_347 = None\n",
      "            quantize_per_tensor_203: \"i8[1, 704, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_47, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_47 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1266 in forward, code: dequantize_per_tensor_default_303 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_303, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_348: \"f32[1, 704, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_203, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1267 in forward, code: dequantize_per_tensor_default_414 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_303, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_303 = None\n",
      "            dequantize_per_tensor_349: \"f32[1, 704, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_203, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_203 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_348, p_features_denseblock4_denselayer7_layers_norm1_weight, p_features_denseblock4_denselayer7_layers_norm1_bias, b_features_denseblock4_denselayer7_layers_norm1_running_mean, b_features_denseblock4_denselayer7_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_348 = p_features_denseblock4_denselayer7_layers_norm1_weight = p_features_denseblock4_denselayer7_layers_norm1_bias = b_features_denseblock4_denselayer7_layers_norm1_running_mean = b_features_denseblock4_denselayer7_layers_norm1_running_var = None\n",
      "            getitem_153: \"f32[1, 704, 8, 8]\" = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
      "            relu_100: \"f32[1, 704, 8, 8]\" = torch.ops.aten.relu.default(getitem_153);  getitem_153 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1275 in forward, code: quantize_per_tensor_default_304 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__100, 0.030158739537000656, -128, -128, 127, torch.int8);  relu__100 = None\n",
      "            quantize_per_tensor_204: \"i8[1, 704, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_100, 0.030158739537000656, -128, -128, 127, torch.int8);  relu_100 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_350: \"f32[1, 704, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_204, 0.030158739537000656, -128, -128, 127, torch.int8);  quantize_per_tensor_204 = None\n",
      "            dequantize_per_tensor_351: \"f32[128, 704, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param100, 0.005891221575438976, 0, -127, 127, torch.int8);  b__frozen_param100 = None\n",
      "            conv2d_100: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_350, dequantize_per_tensor_351, p_features_denseblock4_denselayer7_layers_conv1_weight_bias);  dequantize_per_tensor_350 = dequantize_per_tensor_351 = p_features_denseblock4_denselayer7_layers_conv1_weight_bias = None\n",
      "            relu_101: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_100);  conv2d_100 = None\n",
      "            quantize_per_tensor_205: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_101, 0.01584067940711975, -128, -128, 127, torch.int8);  relu_101 = None\n",
      "            dequantize_per_tensor_352: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_205, 0.01584067940711975, -128, -128, 127, torch.int8);  quantize_per_tensor_205 = None\n",
      "            dequantize_per_tensor_353: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param101, 0.0014143078587949276, 0, -127, 127, torch.int8);  b__frozen_param101 = None\n",
      "            conv2d_101: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_352, dequantize_per_tensor_353, None, [1, 1], [1, 1]);  dequantize_per_tensor_352 = dequantize_per_tensor_353 = None\n",
      "            quantize_per_tensor_206: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_101, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_101 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1288 in forward, code: dequantize_per_tensor_default_308 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_308, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_308 = None\n",
      "            dequantize_per_tensor_354: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_206, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_206 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_48: \"f32[1, 736, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_349, dequantize_per_tensor_354], 1);  dequantize_per_tensor_349 = dequantize_per_tensor_354 = None\n",
      "            quantize_per_tensor_207: \"i8[1, 736, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_48, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_48 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1291 in forward, code: dequantize_per_tensor_default_309 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_309, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_355: \"f32[1, 736, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_207, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1292 in forward, code: dequantize_per_tensor_default_415 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_309, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_309 = None\n",
      "            dequantize_per_tensor_356: \"f32[1, 736, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_207, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_207 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_52 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_355, p_features_denseblock4_denselayer8_layers_norm1_weight, p_features_denseblock4_denselayer8_layers_norm1_bias, b_features_denseblock4_denselayer8_layers_norm1_running_mean, b_features_denseblock4_denselayer8_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_355 = p_features_denseblock4_denselayer8_layers_norm1_weight = p_features_denseblock4_denselayer8_layers_norm1_bias = b_features_denseblock4_denselayer8_layers_norm1_running_mean = b_features_denseblock4_denselayer8_layers_norm1_running_var = None\n",
      "            getitem_156: \"f32[1, 736, 8, 8]\" = _native_batch_norm_legit_no_training_52[0];  _native_batch_norm_legit_no_training_52 = None\n",
      "            relu_102: \"f32[1, 736, 8, 8]\" = torch.ops.aten.relu.default(getitem_156);  getitem_156 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1300 in forward, code: quantize_per_tensor_default_310 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__102, 0.03208186477422714, -128, -128, 127, torch.int8);  relu__102 = None\n",
      "            quantize_per_tensor_208: \"i8[1, 736, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_102, 0.03208186477422714, -128, -128, 127, torch.int8);  relu_102 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_357: \"f32[1, 736, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_208, 0.03208186477422714, -128, -128, 127, torch.int8);  quantize_per_tensor_208 = None\n",
      "            dequantize_per_tensor_358: \"f32[128, 736, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param102, 0.005860139150172472, 0, -127, 127, torch.int8);  b__frozen_param102 = None\n",
      "            conv2d_102: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_357, dequantize_per_tensor_358, p_features_denseblock4_denselayer8_layers_conv1_weight_bias);  dequantize_per_tensor_357 = dequantize_per_tensor_358 = p_features_denseblock4_denselayer8_layers_conv1_weight_bias = None\n",
      "            relu_103: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_102);  conv2d_102 = None\n",
      "            quantize_per_tensor_209: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_103, 0.014829743653535843, -128, -128, 127, torch.int8);  relu_103 = None\n",
      "            dequantize_per_tensor_359: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_209, 0.014829743653535843, -128, -128, 127, torch.int8);  quantize_per_tensor_209 = None\n",
      "            dequantize_per_tensor_360: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param103, 0.002665165113285184, 0, -127, 127, torch.int8);  b__frozen_param103 = None\n",
      "            conv2d_103: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_359, dequantize_per_tensor_360, None, [1, 1], [1, 1]);  dequantize_per_tensor_359 = dequantize_per_tensor_360 = None\n",
      "            quantize_per_tensor_210: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_103, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_103 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1313 in forward, code: dequantize_per_tensor_default_314 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_314, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_314 = None\n",
      "            dequantize_per_tensor_361: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_210, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_210 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_49: \"f32[1, 768, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_356, dequantize_per_tensor_361], 1);  dequantize_per_tensor_356 = dequantize_per_tensor_361 = None\n",
      "            quantize_per_tensor_211: \"i8[1, 768, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_49, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_49 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1316 in forward, code: dequantize_per_tensor_default_315 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_315, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_362: \"f32[1, 768, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_211, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1317 in forward, code: dequantize_per_tensor_default_416 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_315, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_315 = None\n",
      "            dequantize_per_tensor_363: \"f32[1, 768, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_211, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_211 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_53 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_362, p_features_denseblock4_denselayer9_layers_norm1_weight, p_features_denseblock4_denselayer9_layers_norm1_bias, b_features_denseblock4_denselayer9_layers_norm1_running_mean, b_features_denseblock4_denselayer9_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_362 = p_features_denseblock4_denselayer9_layers_norm1_weight = p_features_denseblock4_denselayer9_layers_norm1_bias = b_features_denseblock4_denselayer9_layers_norm1_running_mean = b_features_denseblock4_denselayer9_layers_norm1_running_var = None\n",
      "            getitem_159: \"f32[1, 768, 8, 8]\" = _native_batch_norm_legit_no_training_53[0];  _native_batch_norm_legit_no_training_53 = None\n",
      "            relu_104: \"f32[1, 768, 8, 8]\" = torch.ops.aten.relu.default(getitem_159);  getitem_159 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1325 in forward, code: quantize_per_tensor_default_316 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__104, 0.02786254696547985, -128, -128, 127, torch.int8);  relu__104 = None\n",
      "            quantize_per_tensor_212: \"i8[1, 768, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_104, 0.02786254696547985, -128, -128, 127, torch.int8);  relu_104 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_364: \"f32[1, 768, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_212, 0.02786254696547985, -128, -128, 127, torch.int8);  quantize_per_tensor_212 = None\n",
      "            dequantize_per_tensor_365: \"f32[128, 768, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param104, 0.00571509450674057, 0, -127, 127, torch.int8);  b__frozen_param104 = None\n",
      "            conv2d_104: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_364, dequantize_per_tensor_365, p_features_denseblock4_denselayer9_layers_conv1_weight_bias);  dequantize_per_tensor_364 = dequantize_per_tensor_365 = p_features_denseblock4_denselayer9_layers_conv1_weight_bias = None\n",
      "            relu_105: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_104);  conv2d_104 = None\n",
      "            quantize_per_tensor_213: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_105, 0.005122145172208548, -128, -128, 127, torch.int8);  relu_105 = None\n",
      "            dequantize_per_tensor_366: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_213, 0.005122145172208548, -128, -128, 127, torch.int8);  quantize_per_tensor_213 = None\n",
      "            dequantize_per_tensor_367: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param105, 0.0013437048764899373, 0, -127, 127, torch.int8);  b__frozen_param105 = None\n",
      "            conv2d_105: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_366, dequantize_per_tensor_367, None, [1, 1], [1, 1]);  dequantize_per_tensor_366 = dequantize_per_tensor_367 = None\n",
      "            quantize_per_tensor_214: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_105, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_105 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1338 in forward, code: dequantize_per_tensor_default_320 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_320, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_320 = None\n",
      "            dequantize_per_tensor_368: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_214, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_214 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_50: \"f32[1, 800, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_363, dequantize_per_tensor_368], 1);  dequantize_per_tensor_363 = dequantize_per_tensor_368 = None\n",
      "            quantize_per_tensor_215: \"i8[1, 800, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_50, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_50 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1341 in forward, code: dequantize_per_tensor_default_321 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_321, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_369: \"f32[1, 800, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_215, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1342 in forward, code: dequantize_per_tensor_default_417 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_321, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_321 = None\n",
      "            dequantize_per_tensor_370: \"f32[1, 800, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_215, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_215 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_54 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_369, p_features_denseblock4_denselayer10_layers_norm1_weight, p_features_denseblock4_denselayer10_layers_norm1_bias, b_features_denseblock4_denselayer10_layers_norm1_running_mean, b_features_denseblock4_denselayer10_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_369 = p_features_denseblock4_denselayer10_layers_norm1_weight = p_features_denseblock4_denselayer10_layers_norm1_bias = b_features_denseblock4_denselayer10_layers_norm1_running_mean = b_features_denseblock4_denselayer10_layers_norm1_running_var = None\n",
      "            getitem_162: \"f32[1, 800, 8, 8]\" = _native_batch_norm_legit_no_training_54[0];  _native_batch_norm_legit_no_training_54 = None\n",
      "            relu_106: \"f32[1, 800, 8, 8]\" = torch.ops.aten.relu.default(getitem_162);  getitem_162 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1350 in forward, code: quantize_per_tensor_default_322 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__106, 0.026937687769532204, -128, -128, 127, torch.int8);  relu__106 = None\n",
      "            quantize_per_tensor_216: \"i8[1, 800, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_106, 0.026937687769532204, -128, -128, 127, torch.int8);  relu_106 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_371: \"f32[1, 800, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_216, 0.026937687769532204, -128, -128, 127, torch.int8);  quantize_per_tensor_216 = None\n",
      "            dequantize_per_tensor_372: \"f32[128, 800, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param106, 0.004579649772495031, 0, -127, 127, torch.int8);  b__frozen_param106 = None\n",
      "            conv2d_106: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_371, dequantize_per_tensor_372, p_features_denseblock4_denselayer10_layers_conv1_weight_bias);  dequantize_per_tensor_371 = dequantize_per_tensor_372 = p_features_denseblock4_denselayer10_layers_conv1_weight_bias = None\n",
      "            relu_107: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_106);  conv2d_106 = None\n",
      "            quantize_per_tensor_217: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_107, 0.0021511942613869905, -128, -128, 127, torch.int8);  relu_107 = None\n",
      "            dequantize_per_tensor_373: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_217, 0.0021511942613869905, -128, -128, 127, torch.int8);  quantize_per_tensor_217 = None\n",
      "            dequantize_per_tensor_374: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param107, 0.0012768249725922942, 0, -127, 127, torch.int8);  b__frozen_param107 = None\n",
      "            conv2d_107: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_373, dequantize_per_tensor_374, None, [1, 1], [1, 1]);  dequantize_per_tensor_373 = dequantize_per_tensor_374 = None\n",
      "            quantize_per_tensor_218: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_107, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_107 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1363 in forward, code: dequantize_per_tensor_default_326 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_326, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_326 = None\n",
      "            dequantize_per_tensor_375: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_218, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_218 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_51: \"f32[1, 832, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_370, dequantize_per_tensor_375], 1);  dequantize_per_tensor_370 = dequantize_per_tensor_375 = None\n",
      "            quantize_per_tensor_219: \"i8[1, 832, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_51, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_51 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1366 in forward, code: dequantize_per_tensor_default_327 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_327, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_376: \"f32[1, 832, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_219, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1367 in forward, code: dequantize_per_tensor_default_418 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_327, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_327 = None\n",
      "            dequantize_per_tensor_377: \"f32[1, 832, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_219, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_219 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_55 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_376, p_features_denseblock4_denselayer11_layers_norm1_weight, p_features_denseblock4_denselayer11_layers_norm1_bias, b_features_denseblock4_denselayer11_layers_norm1_running_mean, b_features_denseblock4_denselayer11_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_376 = p_features_denseblock4_denselayer11_layers_norm1_weight = p_features_denseblock4_denselayer11_layers_norm1_bias = b_features_denseblock4_denselayer11_layers_norm1_running_mean = b_features_denseblock4_denselayer11_layers_norm1_running_var = None\n",
      "            getitem_165: \"f32[1, 832, 8, 8]\" = _native_batch_norm_legit_no_training_55[0];  _native_batch_norm_legit_no_training_55 = None\n",
      "            relu_108: \"f32[1, 832, 8, 8]\" = torch.ops.aten.relu.default(getitem_165);  getitem_165 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1375 in forward, code: quantize_per_tensor_default_328 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__108, 0.026668384671211243, -128, -128, 127, torch.int8);  relu__108 = None\n",
      "            quantize_per_tensor_220: \"i8[1, 832, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_108, 0.026668384671211243, -128, -128, 127, torch.int8);  relu_108 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_378: \"f32[1, 832, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_220, 0.026668384671211243, -128, -128, 127, torch.int8);  quantize_per_tensor_220 = None\n",
      "            dequantize_per_tensor_379: \"f32[128, 832, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param108, 0.004289968404918909, 0, -127, 127, torch.int8);  b__frozen_param108 = None\n",
      "            conv2d_108: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_378, dequantize_per_tensor_379, p_features_denseblock4_denselayer11_layers_conv1_weight_bias);  dequantize_per_tensor_378 = dequantize_per_tensor_379 = p_features_denseblock4_denselayer11_layers_conv1_weight_bias = None\n",
      "            relu_109: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_108);  conv2d_108 = None\n",
      "            quantize_per_tensor_221: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_109, 0.004541976843029261, -128, -128, 127, torch.int8);  relu_109 = None\n",
      "            dequantize_per_tensor_380: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_221, 0.004541976843029261, -128, -128, 127, torch.int8);  quantize_per_tensor_221 = None\n",
      "            dequantize_per_tensor_381: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param109, 0.001174488803371787, 0, -127, 127, torch.int8);  b__frozen_param109 = None\n",
      "            conv2d_109: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_380, dequantize_per_tensor_381, None, [1, 1], [1, 1]);  dequantize_per_tensor_380 = dequantize_per_tensor_381 = None\n",
      "            quantize_per_tensor_222: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_109, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_109 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1388 in forward, code: dequantize_per_tensor_default_332 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_332, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_332 = None\n",
      "            dequantize_per_tensor_382: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_222, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_222 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_52: \"f32[1, 864, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_377, dequantize_per_tensor_382], 1);  dequantize_per_tensor_377 = dequantize_per_tensor_382 = None\n",
      "            quantize_per_tensor_223: \"i8[1, 864, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_52, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_52 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1391 in forward, code: dequantize_per_tensor_default_333 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_333, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_383: \"f32[1, 864, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_223, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1392 in forward, code: dequantize_per_tensor_default_419 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_333, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_333 = None\n",
      "            dequantize_per_tensor_384: \"f32[1, 864, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_223, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_223 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_56 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_383, p_features_denseblock4_denselayer12_layers_norm1_weight, p_features_denseblock4_denselayer12_layers_norm1_bias, b_features_denseblock4_denselayer12_layers_norm1_running_mean, b_features_denseblock4_denselayer12_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_383 = p_features_denseblock4_denselayer12_layers_norm1_weight = p_features_denseblock4_denselayer12_layers_norm1_bias = b_features_denseblock4_denselayer12_layers_norm1_running_mean = b_features_denseblock4_denselayer12_layers_norm1_running_var = None\n",
      "            getitem_168: \"f32[1, 864, 8, 8]\" = _native_batch_norm_legit_no_training_56[0];  _native_batch_norm_legit_no_training_56 = None\n",
      "            relu_110: \"f32[1, 864, 8, 8]\" = torch.ops.aten.relu.default(getitem_168);  getitem_168 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1400 in forward, code: quantize_per_tensor_default_334 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__110, 0.02633899636566639, -128, -128, 127, torch.int8);  relu__110 = None\n",
      "            quantize_per_tensor_224: \"i8[1, 864, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_110, 0.02633899636566639, -128, -128, 127, torch.int8);  relu_110 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_385: \"f32[1, 864, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_224, 0.02633899636566639, -128, -128, 127, torch.int8);  quantize_per_tensor_224 = None\n",
      "            dequantize_per_tensor_386: \"f32[128, 864, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param110, 0.004873822443187237, 0, -127, 127, torch.int8);  b__frozen_param110 = None\n",
      "            conv2d_110: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_385, dequantize_per_tensor_386, p_features_denseblock4_denselayer12_layers_conv1_weight_bias);  dequantize_per_tensor_385 = dequantize_per_tensor_386 = p_features_denseblock4_denselayer12_layers_conv1_weight_bias = None\n",
      "            relu_111: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_110);  conv2d_110 = None\n",
      "            quantize_per_tensor_225: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_111, 0.00443444075062871, -128, -128, 127, torch.int8);  relu_111 = None\n",
      "            dequantize_per_tensor_387: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_225, 0.00443444075062871, -128, -128, 127, torch.int8);  quantize_per_tensor_225 = None\n",
      "            dequantize_per_tensor_388: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param111, 0.0012900737347081304, 0, -127, 127, torch.int8);  b__frozen_param111 = None\n",
      "            conv2d_111: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_387, dequantize_per_tensor_388, None, [1, 1], [1, 1]);  dequantize_per_tensor_387 = dequantize_per_tensor_388 = None\n",
      "            quantize_per_tensor_226: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_111, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_111 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1413 in forward, code: dequantize_per_tensor_default_338 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_338, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_338 = None\n",
      "            dequantize_per_tensor_389: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_226, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_226 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_53: \"f32[1, 896, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_384, dequantize_per_tensor_389], 1);  dequantize_per_tensor_384 = dequantize_per_tensor_389 = None\n",
      "            quantize_per_tensor_227: \"i8[1, 896, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_53, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_53 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1416 in forward, code: dequantize_per_tensor_default_339 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_339, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_390: \"f32[1, 896, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_227, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1417 in forward, code: dequantize_per_tensor_default_420 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_339, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_339 = None\n",
      "            dequantize_per_tensor_391: \"f32[1, 896, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_227, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_227 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_57 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_390, p_features_denseblock4_denselayer13_layers_norm1_weight, p_features_denseblock4_denselayer13_layers_norm1_bias, b_features_denseblock4_denselayer13_layers_norm1_running_mean, b_features_denseblock4_denselayer13_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_390 = p_features_denseblock4_denselayer13_layers_norm1_weight = p_features_denseblock4_denselayer13_layers_norm1_bias = b_features_denseblock4_denselayer13_layers_norm1_running_mean = b_features_denseblock4_denselayer13_layers_norm1_running_var = None\n",
      "            getitem_171: \"f32[1, 896, 8, 8]\" = _native_batch_norm_legit_no_training_57[0];  _native_batch_norm_legit_no_training_57 = None\n",
      "            relu_112: \"f32[1, 896, 8, 8]\" = torch.ops.aten.relu.default(getitem_171);  getitem_171 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1425 in forward, code: quantize_per_tensor_default_340 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__112, 0.023481573909521103, -128, -128, 127, torch.int8);  relu__112 = None\n",
      "            quantize_per_tensor_228: \"i8[1, 896, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_112, 0.023481573909521103, -128, -128, 127, torch.int8);  relu_112 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_392: \"f32[1, 896, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_228, 0.023481573909521103, -128, -128, 127, torch.int8);  quantize_per_tensor_228 = None\n",
      "            dequantize_per_tensor_393: \"f32[128, 896, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param112, 0.004650074522942305, 0, -127, 127, torch.int8);  b__frozen_param112 = None\n",
      "            conv2d_112: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_392, dequantize_per_tensor_393, p_features_denseblock4_denselayer13_layers_conv1_weight_bias);  dequantize_per_tensor_392 = dequantize_per_tensor_393 = p_features_denseblock4_denselayer13_layers_conv1_weight_bias = None\n",
      "            relu_113: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_112);  conv2d_112 = None\n",
      "            quantize_per_tensor_229: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_113, 0.00782014150172472, -128, -128, 127, torch.int8);  relu_113 = None\n",
      "            dequantize_per_tensor_394: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_229, 0.00782014150172472, -128, -128, 127, torch.int8);  quantize_per_tensor_229 = None\n",
      "            dequantize_per_tensor_395: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param113, 0.0012907893396914005, 0, -127, 127, torch.int8);  b__frozen_param113 = None\n",
      "            conv2d_113: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_394, dequantize_per_tensor_395, None, [1, 1], [1, 1]);  dequantize_per_tensor_394 = dequantize_per_tensor_395 = None\n",
      "            quantize_per_tensor_230: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_113, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_113 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1438 in forward, code: dequantize_per_tensor_default_344 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_344, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_344 = None\n",
      "            dequantize_per_tensor_396: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_230, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_230 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_54: \"f32[1, 928, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_391, dequantize_per_tensor_396], 1);  dequantize_per_tensor_391 = dequantize_per_tensor_396 = None\n",
      "            quantize_per_tensor_231: \"i8[1, 928, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_54, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_54 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1441 in forward, code: dequantize_per_tensor_default_345 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_345, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_397: \"f32[1, 928, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_231, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1442 in forward, code: dequantize_per_tensor_default_421 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_345, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_345 = None\n",
      "            dequantize_per_tensor_398: \"f32[1, 928, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_231, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_231 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_58 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_397, p_features_denseblock4_denselayer14_layers_norm1_weight, p_features_denseblock4_denselayer14_layers_norm1_bias, b_features_denseblock4_denselayer14_layers_norm1_running_mean, b_features_denseblock4_denselayer14_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_397 = p_features_denseblock4_denselayer14_layers_norm1_weight = p_features_denseblock4_denselayer14_layers_norm1_bias = b_features_denseblock4_denselayer14_layers_norm1_running_mean = b_features_denseblock4_denselayer14_layers_norm1_running_var = None\n",
      "            getitem_174: \"f32[1, 928, 8, 8]\" = _native_batch_norm_legit_no_training_58[0];  _native_batch_norm_legit_no_training_58 = None\n",
      "            relu_114: \"f32[1, 928, 8, 8]\" = torch.ops.aten.relu.default(getitem_174);  getitem_174 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1450 in forward, code: quantize_per_tensor_default_346 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__114, 0.023704107850790024, -128, -128, 127, torch.int8);  relu__114 = None\n",
      "            quantize_per_tensor_232: \"i8[1, 928, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_114, 0.023704107850790024, -128, -128, 127, torch.int8);  relu_114 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_399: \"f32[1, 928, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_232, 0.023704107850790024, -128, -128, 127, torch.int8);  quantize_per_tensor_232 = None\n",
      "            dequantize_per_tensor_400: \"f32[128, 928, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param114, 0.004829755984246731, 0, -127, 127, torch.int8);  b__frozen_param114 = None\n",
      "            conv2d_114: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_399, dequantize_per_tensor_400, p_features_denseblock4_denselayer14_layers_conv1_weight_bias);  dequantize_per_tensor_399 = dequantize_per_tensor_400 = p_features_denseblock4_denselayer14_layers_conv1_weight_bias = None\n",
      "            relu_115: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_114);  conv2d_114 = None\n",
      "            quantize_per_tensor_233: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_115, 0.005172167904675007, -128, -128, 127, torch.int8);  relu_115 = None\n",
      "            dequantize_per_tensor_401: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_233, 0.005172167904675007, -128, -128, 127, torch.int8);  quantize_per_tensor_233 = None\n",
      "            dequantize_per_tensor_402: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param115, 0.0012164926156401634, 0, -127, 127, torch.int8);  b__frozen_param115 = None\n",
      "            conv2d_115: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_401, dequantize_per_tensor_402, None, [1, 1], [1, 1]);  dequantize_per_tensor_401 = dequantize_per_tensor_402 = None\n",
      "            quantize_per_tensor_234: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_115, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_115 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1463 in forward, code: dequantize_per_tensor_default_350 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_350, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_350 = None\n",
      "            dequantize_per_tensor_403: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_234, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_234 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_55: \"f32[1, 960, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_398, dequantize_per_tensor_403], 1);  dequantize_per_tensor_398 = dequantize_per_tensor_403 = None\n",
      "            quantize_per_tensor_235: \"i8[1, 960, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_55, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_55 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1466 in forward, code: dequantize_per_tensor_default_351 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_351, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_404: \"f32[1, 960, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_235, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1467 in forward, code: dequantize_per_tensor_default_422 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_351, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_351 = None\n",
      "            dequantize_per_tensor_405: \"f32[1, 960, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_235, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_235 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_59 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_404, p_features_denseblock4_denselayer15_layers_norm1_weight, p_features_denseblock4_denselayer15_layers_norm1_bias, b_features_denseblock4_denselayer15_layers_norm1_running_mean, b_features_denseblock4_denselayer15_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_404 = p_features_denseblock4_denselayer15_layers_norm1_weight = p_features_denseblock4_denselayer15_layers_norm1_bias = b_features_denseblock4_denselayer15_layers_norm1_running_mean = b_features_denseblock4_denselayer15_layers_norm1_running_var = None\n",
      "            getitem_177: \"f32[1, 960, 8, 8]\" = _native_batch_norm_legit_no_training_59[0];  _native_batch_norm_legit_no_training_59 = None\n",
      "            relu_116: \"f32[1, 960, 8, 8]\" = torch.ops.aten.relu.default(getitem_177);  getitem_177 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1475 in forward, code: quantize_per_tensor_default_352 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__116, 0.02477584220468998, -128, -128, 127, torch.int8);  relu__116 = None\n",
      "            quantize_per_tensor_236: \"i8[1, 960, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_116, 0.02477584220468998, -128, -128, 127, torch.int8);  relu_116 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_406: \"f32[1, 960, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_236, 0.02477584220468998, -128, -128, 127, torch.int8);  quantize_per_tensor_236 = None\n",
      "            dequantize_per_tensor_407: \"f32[128, 960, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param116, 0.004786992911249399, 0, -127, 127, torch.int8);  b__frozen_param116 = None\n",
      "            conv2d_116: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_406, dequantize_per_tensor_407, p_features_denseblock4_denselayer15_layers_conv1_weight_bias);  dequantize_per_tensor_406 = dequantize_per_tensor_407 = p_features_denseblock4_denselayer15_layers_conv1_weight_bias = None\n",
      "            relu_117: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_116);  conv2d_116 = None\n",
      "            quantize_per_tensor_237: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_117, 0.009676340967416763, -128, -128, 127, torch.int8);  relu_117 = None\n",
      "            dequantize_per_tensor_408: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_237, 0.009676340967416763, -128, -128, 127, torch.int8);  quantize_per_tensor_237 = None\n",
      "            dequantize_per_tensor_409: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param117, 0.001245377934537828, 0, -127, 127, torch.int8);  b__frozen_param117 = None\n",
      "            conv2d_117: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_408, dequantize_per_tensor_409, None, [1, 1], [1, 1]);  dequantize_per_tensor_408 = dequantize_per_tensor_409 = None\n",
      "            quantize_per_tensor_238: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_117, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_117 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1488 in forward, code: dequantize_per_tensor_default_356 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_356, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_356 = None\n",
      "            dequantize_per_tensor_410: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_238, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_238 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_56: \"f32[1, 992, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_405, dequantize_per_tensor_410], 1);  dequantize_per_tensor_405 = dequantize_per_tensor_410 = None\n",
      "            quantize_per_tensor_239: \"i8[1, 992, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_56, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_56 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1491 in forward, code: dequantize_per_tensor_default_357 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_357, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            dequantize_per_tensor_411: \"f32[1, 992, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_239, 0.06494706869125366, -4, -128, 127, torch.int8)\n",
      "            \n",
      "             # File: <eval_with_key>.954:1492 in forward, code: dequantize_per_tensor_default_423 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_357, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_357 = None\n",
      "            dequantize_per_tensor_412: \"f32[1, 992, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_239, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_239 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            _native_batch_norm_legit_no_training_60 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_411, p_features_denseblock4_denselayer16_layers_norm1_weight, p_features_denseblock4_denselayer16_layers_norm1_bias, b_features_denseblock4_denselayer16_layers_norm1_running_mean, b_features_denseblock4_denselayer16_layers_norm1_running_var, 0.1, 1e-05);  dequantize_per_tensor_411 = p_features_denseblock4_denselayer16_layers_norm1_weight = p_features_denseblock4_denselayer16_layers_norm1_bias = b_features_denseblock4_denselayer16_layers_norm1_running_mean = b_features_denseblock4_denselayer16_layers_norm1_running_var = None\n",
      "            getitem_180: \"f32[1, 992, 8, 8]\" = _native_batch_norm_legit_no_training_60[0];  _native_batch_norm_legit_no_training_60 = None\n",
      "            relu_118: \"f32[1, 992, 8, 8]\" = torch.ops.aten.relu.default(getitem_180);  getitem_180 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1500 in forward, code: quantize_per_tensor_default_358 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__118, 0.02714269794523716, -128, -128, 127, torch.int8);  relu__118 = None\n",
      "            quantize_per_tensor_240: \"i8[1, 992, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_118, 0.02714269794523716, -128, -128, 127, torch.int8);  relu_118 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:87 in forward, code: new_features = self.layers(x)\n",
      "            dequantize_per_tensor_413: \"f32[1, 992, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_240, 0.02714269794523716, -128, -128, 127, torch.int8);  quantize_per_tensor_240 = None\n",
      "            dequantize_per_tensor_414: \"f32[128, 992, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param118, 0.0052767787128686905, 0, -127, 127, torch.int8);  b__frozen_param118 = None\n",
      "            conv2d_118: \"f32[1, 128, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_413, dequantize_per_tensor_414, p_features_denseblock4_denselayer16_layers_conv1_weight_bias);  dequantize_per_tensor_413 = dequantize_per_tensor_414 = p_features_denseblock4_denselayer16_layers_conv1_weight_bias = None\n",
      "            relu_119: \"f32[1, 128, 8, 8]\" = torch.ops.aten.relu.default(conv2d_118);  conv2d_118 = None\n",
      "            quantize_per_tensor_241: \"i8[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_119, 0.016764948144555092, -128, -128, 127, torch.int8);  relu_119 = None\n",
      "            dequantize_per_tensor_415: \"f32[1, 128, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_241, 0.016764948144555092, -128, -128, 127, torch.int8);  quantize_per_tensor_241 = None\n",
      "            dequantize_per_tensor_416: \"f32[32, 128, 3, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param119, 0.0013234312646090984, 0, -127, 127, torch.int8);  b__frozen_param119 = None\n",
      "            conv2d_119: \"f32[1, 32, 8, 8]\" = torch.ops.aten.conv2d.default(dequantize_per_tensor_415, dequantize_per_tensor_416, None, [1, 1], [1, 1]);  dequantize_per_tensor_415 = dequantize_per_tensor_416 = None\n",
      "            quantize_per_tensor_242: \"i8[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(conv2d_119, 0.06494706869125366, -4, -128, 127, torch.int8);  conv2d_119 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1513 in forward, code: dequantize_per_tensor_default_362 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_362, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_362 = None\n",
      "            dequantize_per_tensor_417: \"f32[1, 32, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_242, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_242 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:88 in forward, code: return torch.cat([x, new_features], 1)\n",
      "            cat_57: \"f32[1, 1024, 8, 8]\" = torch.ops.aten.cat.default([dequantize_per_tensor_412, dequantize_per_tensor_417], 1);  dequantize_per_tensor_412 = dequantize_per_tensor_417 = None\n",
      "            quantize_per_tensor_243: \"i8[1, 1024, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(cat_57, 0.06494706869125366, -4, -128, 127, torch.int8);  cat_57 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1516 in forward, code: dequantize_per_tensor_default_363 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_363, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_default_363 = None\n",
      "            dequantize_per_tensor_418: \"f32[1, 1024, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_243, 0.06494706869125366, -4, -128, 127, torch.int8);  quantize_per_tensor_243 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:254 in forward, code: x = self.features(x)\n",
      "            _native_batch_norm_legit_no_training_61 = torch.ops.aten._native_batch_norm_legit_no_training.default(dequantize_per_tensor_418, p_features_norm5_weight, p_features_norm5_bias, b_features_norm5_running_mean, b_features_norm5_running_var, 0.1, 1e-05);  dequantize_per_tensor_418 = p_features_norm5_weight = p_features_norm5_bias = b_features_norm5_running_mean = b_features_norm5_running_var = None\n",
      "            getitem_183: \"f32[1, 1024, 8, 8]\" = _native_batch_norm_legit_no_training_61[0];  _native_batch_norm_legit_no_training_61 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:255 in forward, code: x = self.class_layers(x)\n",
      "            relu_120: \"f32[1, 1024, 8, 8]\" = torch.ops.aten.relu.default(getitem_183);  getitem_183 = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1524 in forward, code: quantize_per_tensor_default_364 = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu__120, 0.5310883522033691, -128, -128, 127, torch.int8);  relu__120 = None\n",
      "            quantize_per_tensor_244: \"i8[1, 1024, 8, 8]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(relu_120, 0.5310883522033691, -128, -128, 127, torch.int8);  relu_120 = None\n",
      "            \n",
      "             # File: /home/kindersc/Documents/model_conversion/executorch_venv/lib/python3.10/site-packages/monai/networks/nets/densenet.py:255 in forward, code: x = self.class_layers(x)\n",
      "            dequantize_per_tensor_419: \"f32[1, 1024, 8, 8]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_244, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_244 = None\n",
      "            adaptive_avg_pool2d: \"f32[1, 1024, 1, 1]\" = torch.ops.aten.adaptive_avg_pool2d.default(dequantize_per_tensor_419, [1, 1]);  dequantize_per_tensor_419 = None\n",
      "            quantize_per_tensor_245: \"i8[1, 1024, 1, 1]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(adaptive_avg_pool2d, 0.5310883522033691, -128, -128, 127, torch.int8);  adaptive_avg_pool2d = None\n",
      "            dequantize_per_tensor_420: \"f32[1, 1024, 1, 1]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_245, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_245 = None\n",
      "            view: \"f32[1, 1024]\" = torch.ops.aten.view.default(dequantize_per_tensor_420, [1, 1024]);  dequantize_per_tensor_420 = None\n",
      "            quantize_per_tensor_246: \"i8[1, 1024]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(view, 0.5310883522033691, -128, -128, 127, torch.int8);  view = None\n",
      "            dequantize_per_tensor_421: \"f32[1, 1024]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_246, 0.5310883522033691, -128, -128, 127, torch.int8);  quantize_per_tensor_246 = None\n",
      "            dequantize_per_tensor_422: \"f32[3, 1024]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(b__frozen_param120, 0.000355078955180943, 0, -127, 127, torch.int8);  b__frozen_param120 = None\n",
      "            linear: \"f32[1, 3]\" = torch.ops.aten.linear.default(dequantize_per_tensor_421, dequantize_per_tensor_422, p_class_layers_out_bias);  dequantize_per_tensor_421 = dequantize_per_tensor_422 = p_class_layers_out_bias = None\n",
      "            quantize_per_tensor_247: \"i8[1, 3]\" = torch.ops.quantized_decomposed.quantize_per_tensor.default(linear, 0.02458547241985798, -128, -128, 127, torch.int8);  linear = None\n",
      "            \n",
      "             # File: <eval_with_key>.954:1537 in forward, code: dequantize_per_tensor_default_368 = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_default_368, 0.02458547241985798, -128, -128, 127, torch.int8);  quantize_per_tensor_default_368 = None\n",
      "            dequantize_per_tensor_423: \"f32[1, 3]\" = torch.ops.quantized_decomposed.dequantize_per_tensor.default(quantize_per_tensor_247, 0.02458547241985798, -128, -128, 127, torch.int8);  quantize_per_tensor_247 = None\n",
      "            return (dequantize_per_tensor_423,)\n",
      "            \n",
      "Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_conv0_weight_bias'), target='features_conv0_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer1_layers_norm1_weight'), target='features_denseblock1_denselayer1_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer1_layers_norm1_bias'), target='features_denseblock1_denselayer1_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer1_layers_conv1_weight_bias'), target='features_denseblock1_denselayer1_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer2_layers_norm1_weight'), target='features_denseblock1_denselayer2_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer2_layers_norm1_bias'), target='features_denseblock1_denselayer2_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer2_layers_conv1_weight_bias'), target='features_denseblock1_denselayer2_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer3_layers_norm1_weight'), target='features_denseblock1_denselayer3_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer3_layers_norm1_bias'), target='features_denseblock1_denselayer3_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer3_layers_conv1_weight_bias'), target='features_denseblock1_denselayer3_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer4_layers_norm1_weight'), target='features_denseblock1_denselayer4_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer4_layers_norm1_bias'), target='features_denseblock1_denselayer4_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer4_layers_conv1_weight_bias'), target='features_denseblock1_denselayer4_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer5_layers_norm1_weight'), target='features_denseblock1_denselayer5_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer5_layers_norm1_bias'), target='features_denseblock1_denselayer5_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer5_layers_conv1_weight_bias'), target='features_denseblock1_denselayer5_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer6_layers_norm1_weight'), target='features_denseblock1_denselayer6_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer6_layers_norm1_bias'), target='features_denseblock1_denselayer6_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock1_denselayer6_layers_conv1_weight_bias'), target='features_denseblock1_denselayer6_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition1_norm_weight'), target='features_transition1_norm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition1_norm_bias'), target='features_transition1_norm_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer1_layers_norm1_weight'), target='features_denseblock2_denselayer1_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer1_layers_norm1_bias'), target='features_denseblock2_denselayer1_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer1_layers_conv1_weight_bias'), target='features_denseblock2_denselayer1_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer2_layers_norm1_weight'), target='features_denseblock2_denselayer2_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer2_layers_norm1_bias'), target='features_denseblock2_denselayer2_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer2_layers_conv1_weight_bias'), target='features_denseblock2_denselayer2_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer3_layers_norm1_weight'), target='features_denseblock2_denselayer3_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer3_layers_norm1_bias'), target='features_denseblock2_denselayer3_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer3_layers_conv1_weight_bias'), target='features_denseblock2_denselayer3_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer4_layers_norm1_weight'), target='features_denseblock2_denselayer4_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer4_layers_norm1_bias'), target='features_denseblock2_denselayer4_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer4_layers_conv1_weight_bias'), target='features_denseblock2_denselayer4_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer5_layers_norm1_weight'), target='features_denseblock2_denselayer5_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer5_layers_norm1_bias'), target='features_denseblock2_denselayer5_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer5_layers_conv1_weight_bias'), target='features_denseblock2_denselayer5_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer6_layers_norm1_weight'), target='features_denseblock2_denselayer6_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer6_layers_norm1_bias'), target='features_denseblock2_denselayer6_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer6_layers_conv1_weight_bias'), target='features_denseblock2_denselayer6_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer7_layers_norm1_weight'), target='features_denseblock2_denselayer7_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer7_layers_norm1_bias'), target='features_denseblock2_denselayer7_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer7_layers_conv1_weight_bias'), target='features_denseblock2_denselayer7_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer8_layers_norm1_weight'), target='features_denseblock2_denselayer8_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer8_layers_norm1_bias'), target='features_denseblock2_denselayer8_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer8_layers_conv1_weight_bias'), target='features_denseblock2_denselayer8_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer9_layers_norm1_weight'), target='features_denseblock2_denselayer9_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer9_layers_norm1_bias'), target='features_denseblock2_denselayer9_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer9_layers_conv1_weight_bias'), target='features_denseblock2_denselayer9_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer10_layers_norm1_weight'), target='features_denseblock2_denselayer10_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer10_layers_norm1_bias'), target='features_denseblock2_denselayer10_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer10_layers_conv1_weight_bias'), target='features_denseblock2_denselayer10_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer11_layers_norm1_weight'), target='features_denseblock2_denselayer11_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer11_layers_norm1_bias'), target='features_denseblock2_denselayer11_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer11_layers_conv1_weight_bias'), target='features_denseblock2_denselayer11_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer12_layers_norm1_weight'), target='features_denseblock2_denselayer12_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer12_layers_norm1_bias'), target='features_denseblock2_denselayer12_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock2_denselayer12_layers_conv1_weight_bias'), target='features_denseblock2_denselayer12_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition2_norm_weight'), target='features_transition2_norm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition2_norm_bias'), target='features_transition2_norm_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer1_layers_norm1_weight'), target='features_denseblock3_denselayer1_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer1_layers_norm1_bias'), target='features_denseblock3_denselayer1_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer1_layers_conv1_weight_bias'), target='features_denseblock3_denselayer1_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer2_layers_norm1_weight'), target='features_denseblock3_denselayer2_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer2_layers_norm1_bias'), target='features_denseblock3_denselayer2_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer2_layers_conv1_weight_bias'), target='features_denseblock3_denselayer2_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer3_layers_norm1_weight'), target='features_denseblock3_denselayer3_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer3_layers_norm1_bias'), target='features_denseblock3_denselayer3_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer3_layers_conv1_weight_bias'), target='features_denseblock3_denselayer3_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer4_layers_norm1_weight'), target='features_denseblock3_denselayer4_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer4_layers_norm1_bias'), target='features_denseblock3_denselayer4_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer4_layers_conv1_weight_bias'), target='features_denseblock3_denselayer4_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer5_layers_norm1_weight'), target='features_denseblock3_denselayer5_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer5_layers_norm1_bias'), target='features_denseblock3_denselayer5_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer5_layers_conv1_weight_bias'), target='features_denseblock3_denselayer5_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer6_layers_norm1_weight'), target='features_denseblock3_denselayer6_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer6_layers_norm1_bias'), target='features_denseblock3_denselayer6_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer6_layers_conv1_weight_bias'), target='features_denseblock3_denselayer6_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer7_layers_norm1_weight'), target='features_denseblock3_denselayer7_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer7_layers_norm1_bias'), target='features_denseblock3_denselayer7_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer7_layers_conv1_weight_bias'), target='features_denseblock3_denselayer7_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer8_layers_norm1_weight'), target='features_denseblock3_denselayer8_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer8_layers_norm1_bias'), target='features_denseblock3_denselayer8_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer8_layers_conv1_weight_bias'), target='features_denseblock3_denselayer8_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer9_layers_norm1_weight'), target='features_denseblock3_denselayer9_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer9_layers_norm1_bias'), target='features_denseblock3_denselayer9_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer9_layers_conv1_weight_bias'), target='features_denseblock3_denselayer9_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer10_layers_norm1_weight'), target='features_denseblock3_denselayer10_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer10_layers_norm1_bias'), target='features_denseblock3_denselayer10_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer10_layers_conv1_weight_bias'), target='features_denseblock3_denselayer10_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer11_layers_norm1_weight'), target='features_denseblock3_denselayer11_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer11_layers_norm1_bias'), target='features_denseblock3_denselayer11_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer11_layers_conv1_weight_bias'), target='features_denseblock3_denselayer11_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer12_layers_norm1_weight'), target='features_denseblock3_denselayer12_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer12_layers_norm1_bias'), target='features_denseblock3_denselayer12_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer12_layers_conv1_weight_bias'), target='features_denseblock3_denselayer12_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer13_layers_norm1_weight'), target='features_denseblock3_denselayer13_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer13_layers_norm1_bias'), target='features_denseblock3_denselayer13_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer13_layers_conv1_weight_bias'), target='features_denseblock3_denselayer13_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer14_layers_norm1_weight'), target='features_denseblock3_denselayer14_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer14_layers_norm1_bias'), target='features_denseblock3_denselayer14_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer14_layers_conv1_weight_bias'), target='features_denseblock3_denselayer14_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer15_layers_norm1_weight'), target='features_denseblock3_denselayer15_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer15_layers_norm1_bias'), target='features_denseblock3_denselayer15_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer15_layers_conv1_weight_bias'), target='features_denseblock3_denselayer15_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer16_layers_norm1_weight'), target='features_denseblock3_denselayer16_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer16_layers_norm1_bias'), target='features_denseblock3_denselayer16_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer16_layers_conv1_weight_bias'), target='features_denseblock3_denselayer16_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer17_layers_norm1_weight'), target='features_denseblock3_denselayer17_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer17_layers_norm1_bias'), target='features_denseblock3_denselayer17_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer17_layers_conv1_weight_bias'), target='features_denseblock3_denselayer17_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer18_layers_norm1_weight'), target='features_denseblock3_denselayer18_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer18_layers_norm1_bias'), target='features_denseblock3_denselayer18_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer18_layers_conv1_weight_bias'), target='features_denseblock3_denselayer18_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer19_layers_norm1_weight'), target='features_denseblock3_denselayer19_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer19_layers_norm1_bias'), target='features_denseblock3_denselayer19_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer19_layers_conv1_weight_bias'), target='features_denseblock3_denselayer19_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer20_layers_norm1_weight'), target='features_denseblock3_denselayer20_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer20_layers_norm1_bias'), target='features_denseblock3_denselayer20_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer20_layers_conv1_weight_bias'), target='features_denseblock3_denselayer20_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer21_layers_norm1_weight'), target='features_denseblock3_denselayer21_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer21_layers_norm1_bias'), target='features_denseblock3_denselayer21_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer21_layers_conv1_weight_bias'), target='features_denseblock3_denselayer21_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer22_layers_norm1_weight'), target='features_denseblock3_denselayer22_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer22_layers_norm1_bias'), target='features_denseblock3_denselayer22_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer22_layers_conv1_weight_bias'), target='features_denseblock3_denselayer22_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer23_layers_norm1_weight'), target='features_denseblock3_denselayer23_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer23_layers_norm1_bias'), target='features_denseblock3_denselayer23_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer23_layers_conv1_weight_bias'), target='features_denseblock3_denselayer23_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer24_layers_norm1_weight'), target='features_denseblock3_denselayer24_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer24_layers_norm1_bias'), target='features_denseblock3_denselayer24_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock3_denselayer24_layers_conv1_weight_bias'), target='features_denseblock3_denselayer24_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition3_norm_weight'), target='features_transition3_norm_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_transition3_norm_bias'), target='features_transition3_norm_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer1_layers_norm1_weight'), target='features_denseblock4_denselayer1_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer1_layers_norm1_bias'), target='features_denseblock4_denselayer1_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer1_layers_conv1_weight_bias'), target='features_denseblock4_denselayer1_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer2_layers_norm1_weight'), target='features_denseblock4_denselayer2_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer2_layers_norm1_bias'), target='features_denseblock4_denselayer2_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer2_layers_conv1_weight_bias'), target='features_denseblock4_denselayer2_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer3_layers_norm1_weight'), target='features_denseblock4_denselayer3_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer3_layers_norm1_bias'), target='features_denseblock4_denselayer3_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer3_layers_conv1_weight_bias'), target='features_denseblock4_denselayer3_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer4_layers_norm1_weight'), target='features_denseblock4_denselayer4_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer4_layers_norm1_bias'), target='features_denseblock4_denselayer4_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer4_layers_conv1_weight_bias'), target='features_denseblock4_denselayer4_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer5_layers_norm1_weight'), target='features_denseblock4_denselayer5_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer5_layers_norm1_bias'), target='features_denseblock4_denselayer5_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer5_layers_conv1_weight_bias'), target='features_denseblock4_denselayer5_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer6_layers_norm1_weight'), target='features_denseblock4_denselayer6_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer6_layers_norm1_bias'), target='features_denseblock4_denselayer6_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer6_layers_conv1_weight_bias'), target='features_denseblock4_denselayer6_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer7_layers_norm1_weight'), target='features_denseblock4_denselayer7_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer7_layers_norm1_bias'), target='features_denseblock4_denselayer7_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer7_layers_conv1_weight_bias'), target='features_denseblock4_denselayer7_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer8_layers_norm1_weight'), target='features_denseblock4_denselayer8_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer8_layers_norm1_bias'), target='features_denseblock4_denselayer8_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer8_layers_conv1_weight_bias'), target='features_denseblock4_denselayer8_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer9_layers_norm1_weight'), target='features_denseblock4_denselayer9_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer9_layers_norm1_bias'), target='features_denseblock4_denselayer9_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer9_layers_conv1_weight_bias'), target='features_denseblock4_denselayer9_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer10_layers_norm1_weight'), target='features_denseblock4_denselayer10_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer10_layers_norm1_bias'), target='features_denseblock4_denselayer10_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer10_layers_conv1_weight_bias'), target='features_denseblock4_denselayer10_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer11_layers_norm1_weight'), target='features_denseblock4_denselayer11_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer11_layers_norm1_bias'), target='features_denseblock4_denselayer11_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer11_layers_conv1_weight_bias'), target='features_denseblock4_denselayer11_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer12_layers_norm1_weight'), target='features_denseblock4_denselayer12_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer12_layers_norm1_bias'), target='features_denseblock4_denselayer12_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer12_layers_conv1_weight_bias'), target='features_denseblock4_denselayer12_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer13_layers_norm1_weight'), target='features_denseblock4_denselayer13_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer13_layers_norm1_bias'), target='features_denseblock4_denselayer13_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer13_layers_conv1_weight_bias'), target='features_denseblock4_denselayer13_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer14_layers_norm1_weight'), target='features_denseblock4_denselayer14_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer14_layers_norm1_bias'), target='features_denseblock4_denselayer14_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer14_layers_conv1_weight_bias'), target='features_denseblock4_denselayer14_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer15_layers_norm1_weight'), target='features_denseblock4_denselayer15_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer15_layers_norm1_bias'), target='features_denseblock4_denselayer15_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer15_layers_conv1_weight_bias'), target='features_denseblock4_denselayer15_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer16_layers_norm1_weight'), target='features_denseblock4_denselayer16_layers_norm1_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer16_layers_norm1_bias'), target='features_denseblock4_denselayer16_layers_norm1_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_denseblock4_denselayer16_layers_conv1_weight_bias'), target='features_denseblock4_denselayer16_layers_conv1_weight_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_norm5_weight'), target='features_norm5_weight', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_features_norm5_bias'), target='features_norm5_bias', persistent=None), InputSpec(kind=<InputKind.PARAMETER: 2>, arg=TensorArgument(name='p_class_layers_out_bias'), target='class_layers_out_bias', persistent=None), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param0'), target='_frozen_param0', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer1_layers_norm1_running_mean'), target='features_denseblock1_denselayer1_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer1_layers_norm1_running_var'), target='features_denseblock1_denselayer1_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param1'), target='_frozen_param1', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param2'), target='_frozen_param2', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer2_layers_norm1_running_mean'), target='features_denseblock1_denselayer2_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer2_layers_norm1_running_var'), target='features_denseblock1_denselayer2_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param3'), target='_frozen_param3', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param4'), target='_frozen_param4', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer3_layers_norm1_running_mean'), target='features_denseblock1_denselayer3_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer3_layers_norm1_running_var'), target='features_denseblock1_denselayer3_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param5'), target='_frozen_param5', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param6'), target='_frozen_param6', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer4_layers_norm1_running_mean'), target='features_denseblock1_denselayer4_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer4_layers_norm1_running_var'), target='features_denseblock1_denselayer4_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param7'), target='_frozen_param7', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param8'), target='_frozen_param8', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer5_layers_norm1_running_mean'), target='features_denseblock1_denselayer5_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer5_layers_norm1_running_var'), target='features_denseblock1_denselayer5_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param9'), target='_frozen_param9', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param10'), target='_frozen_param10', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer6_layers_norm1_running_mean'), target='features_denseblock1_denselayer6_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock1_denselayer6_layers_norm1_running_var'), target='features_denseblock1_denselayer6_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param11'), target='_frozen_param11', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param12'), target='_frozen_param12', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition1_norm_running_mean'), target='features_transition1_norm_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition1_norm_running_var'), target='features_transition1_norm_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param13'), target='_frozen_param13', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer1_layers_norm1_running_mean'), target='features_denseblock2_denselayer1_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer1_layers_norm1_running_var'), target='features_denseblock2_denselayer1_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param14'), target='_frozen_param14', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param15'), target='_frozen_param15', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer2_layers_norm1_running_mean'), target='features_denseblock2_denselayer2_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer2_layers_norm1_running_var'), target='features_denseblock2_denselayer2_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param16'), target='_frozen_param16', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param17'), target='_frozen_param17', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer3_layers_norm1_running_mean'), target='features_denseblock2_denselayer3_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer3_layers_norm1_running_var'), target='features_denseblock2_denselayer3_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param18'), target='_frozen_param18', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param19'), target='_frozen_param19', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer4_layers_norm1_running_mean'), target='features_denseblock2_denselayer4_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer4_layers_norm1_running_var'), target='features_denseblock2_denselayer4_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param20'), target='_frozen_param20', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param21'), target='_frozen_param21', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer5_layers_norm1_running_mean'), target='features_denseblock2_denselayer5_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer5_layers_norm1_running_var'), target='features_denseblock2_denselayer5_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param22'), target='_frozen_param22', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param23'), target='_frozen_param23', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer6_layers_norm1_running_mean'), target='features_denseblock2_denselayer6_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer6_layers_norm1_running_var'), target='features_denseblock2_denselayer6_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param24'), target='_frozen_param24', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param25'), target='_frozen_param25', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer7_layers_norm1_running_mean'), target='features_denseblock2_denselayer7_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer7_layers_norm1_running_var'), target='features_denseblock2_denselayer7_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param26'), target='_frozen_param26', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param27'), target='_frozen_param27', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer8_layers_norm1_running_mean'), target='features_denseblock2_denselayer8_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer8_layers_norm1_running_var'), target='features_denseblock2_denselayer8_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param28'), target='_frozen_param28', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param29'), target='_frozen_param29', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer9_layers_norm1_running_mean'), target='features_denseblock2_denselayer9_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer9_layers_norm1_running_var'), target='features_denseblock2_denselayer9_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param30'), target='_frozen_param30', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param31'), target='_frozen_param31', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer10_layers_norm1_running_mean'), target='features_denseblock2_denselayer10_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer10_layers_norm1_running_var'), target='features_denseblock2_denselayer10_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param32'), target='_frozen_param32', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param33'), target='_frozen_param33', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer11_layers_norm1_running_mean'), target='features_denseblock2_denselayer11_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer11_layers_norm1_running_var'), target='features_denseblock2_denselayer11_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param34'), target='_frozen_param34', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param35'), target='_frozen_param35', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer12_layers_norm1_running_mean'), target='features_denseblock2_denselayer12_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock2_denselayer12_layers_norm1_running_var'), target='features_denseblock2_denselayer12_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param36'), target='_frozen_param36', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param37'), target='_frozen_param37', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition2_norm_running_mean'), target='features_transition2_norm_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition2_norm_running_var'), target='features_transition2_norm_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param38'), target='_frozen_param38', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer1_layers_norm1_running_mean'), target='features_denseblock3_denselayer1_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer1_layers_norm1_running_var'), target='features_denseblock3_denselayer1_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param39'), target='_frozen_param39', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param40'), target='_frozen_param40', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer2_layers_norm1_running_mean'), target='features_denseblock3_denselayer2_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer2_layers_norm1_running_var'), target='features_denseblock3_denselayer2_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param41'), target='_frozen_param41', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param42'), target='_frozen_param42', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer3_layers_norm1_running_mean'), target='features_denseblock3_denselayer3_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer3_layers_norm1_running_var'), target='features_denseblock3_denselayer3_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param43'), target='_frozen_param43', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param44'), target='_frozen_param44', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer4_layers_norm1_running_mean'), target='features_denseblock3_denselayer4_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer4_layers_norm1_running_var'), target='features_denseblock3_denselayer4_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param45'), target='_frozen_param45', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param46'), target='_frozen_param46', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer5_layers_norm1_running_mean'), target='features_denseblock3_denselayer5_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer5_layers_norm1_running_var'), target='features_denseblock3_denselayer5_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param47'), target='_frozen_param47', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param48'), target='_frozen_param48', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer6_layers_norm1_running_mean'), target='features_denseblock3_denselayer6_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer6_layers_norm1_running_var'), target='features_denseblock3_denselayer6_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param49'), target='_frozen_param49', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param50'), target='_frozen_param50', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer7_layers_norm1_running_mean'), target='features_denseblock3_denselayer7_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer7_layers_norm1_running_var'), target='features_denseblock3_denselayer7_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param51'), target='_frozen_param51', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param52'), target='_frozen_param52', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer8_layers_norm1_running_mean'), target='features_denseblock3_denselayer8_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer8_layers_norm1_running_var'), target='features_denseblock3_denselayer8_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param53'), target='_frozen_param53', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param54'), target='_frozen_param54', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer9_layers_norm1_running_mean'), target='features_denseblock3_denselayer9_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer9_layers_norm1_running_var'), target='features_denseblock3_denselayer9_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param55'), target='_frozen_param55', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param56'), target='_frozen_param56', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer10_layers_norm1_running_mean'), target='features_denseblock3_denselayer10_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer10_layers_norm1_running_var'), target='features_denseblock3_denselayer10_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param57'), target='_frozen_param57', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param58'), target='_frozen_param58', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer11_layers_norm1_running_mean'), target='features_denseblock3_denselayer11_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer11_layers_norm1_running_var'), target='features_denseblock3_denselayer11_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param59'), target='_frozen_param59', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param60'), target='_frozen_param60', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer12_layers_norm1_running_mean'), target='features_denseblock3_denselayer12_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer12_layers_norm1_running_var'), target='features_denseblock3_denselayer12_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param61'), target='_frozen_param61', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param62'), target='_frozen_param62', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer13_layers_norm1_running_mean'), target='features_denseblock3_denselayer13_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer13_layers_norm1_running_var'), target='features_denseblock3_denselayer13_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param63'), target='_frozen_param63', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param64'), target='_frozen_param64', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer14_layers_norm1_running_mean'), target='features_denseblock3_denselayer14_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer14_layers_norm1_running_var'), target='features_denseblock3_denselayer14_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param65'), target='_frozen_param65', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param66'), target='_frozen_param66', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer15_layers_norm1_running_mean'), target='features_denseblock3_denselayer15_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer15_layers_norm1_running_var'), target='features_denseblock3_denselayer15_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param67'), target='_frozen_param67', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param68'), target='_frozen_param68', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer16_layers_norm1_running_mean'), target='features_denseblock3_denselayer16_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer16_layers_norm1_running_var'), target='features_denseblock3_denselayer16_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param69'), target='_frozen_param69', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param70'), target='_frozen_param70', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer17_layers_norm1_running_mean'), target='features_denseblock3_denselayer17_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer17_layers_norm1_running_var'), target='features_denseblock3_denselayer17_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param71'), target='_frozen_param71', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param72'), target='_frozen_param72', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer18_layers_norm1_running_mean'), target='features_denseblock3_denselayer18_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer18_layers_norm1_running_var'), target='features_denseblock3_denselayer18_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param73'), target='_frozen_param73', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param74'), target='_frozen_param74', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer19_layers_norm1_running_mean'), target='features_denseblock3_denselayer19_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer19_layers_norm1_running_var'), target='features_denseblock3_denselayer19_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param75'), target='_frozen_param75', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param76'), target='_frozen_param76', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer20_layers_norm1_running_mean'), target='features_denseblock3_denselayer20_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer20_layers_norm1_running_var'), target='features_denseblock3_denselayer20_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param77'), target='_frozen_param77', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param78'), target='_frozen_param78', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer21_layers_norm1_running_mean'), target='features_denseblock3_denselayer21_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer21_layers_norm1_running_var'), target='features_denseblock3_denselayer21_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param79'), target='_frozen_param79', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param80'), target='_frozen_param80', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer22_layers_norm1_running_mean'), target='features_denseblock3_denselayer22_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer22_layers_norm1_running_var'), target='features_denseblock3_denselayer22_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param81'), target='_frozen_param81', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param82'), target='_frozen_param82', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer23_layers_norm1_running_mean'), target='features_denseblock3_denselayer23_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer23_layers_norm1_running_var'), target='features_denseblock3_denselayer23_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param83'), target='_frozen_param83', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param84'), target='_frozen_param84', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer24_layers_norm1_running_mean'), target='features_denseblock3_denselayer24_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock3_denselayer24_layers_norm1_running_var'), target='features_denseblock3_denselayer24_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param85'), target='_frozen_param85', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param86'), target='_frozen_param86', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition3_norm_running_mean'), target='features_transition3_norm_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_transition3_norm_running_var'), target='features_transition3_norm_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param87'), target='_frozen_param87', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer1_layers_norm1_running_mean'), target='features_denseblock4_denselayer1_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer1_layers_norm1_running_var'), target='features_denseblock4_denselayer1_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param88'), target='_frozen_param88', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param89'), target='_frozen_param89', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer2_layers_norm1_running_mean'), target='features_denseblock4_denselayer2_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer2_layers_norm1_running_var'), target='features_denseblock4_denselayer2_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param90'), target='_frozen_param90', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param91'), target='_frozen_param91', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer3_layers_norm1_running_mean'), target='features_denseblock4_denselayer3_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer3_layers_norm1_running_var'), target='features_denseblock4_denselayer3_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param92'), target='_frozen_param92', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param93'), target='_frozen_param93', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer4_layers_norm1_running_mean'), target='features_denseblock4_denselayer4_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer4_layers_norm1_running_var'), target='features_denseblock4_denselayer4_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param94'), target='_frozen_param94', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param95'), target='_frozen_param95', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer5_layers_norm1_running_mean'), target='features_denseblock4_denselayer5_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer5_layers_norm1_running_var'), target='features_denseblock4_denselayer5_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param96'), target='_frozen_param96', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param97'), target='_frozen_param97', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer6_layers_norm1_running_mean'), target='features_denseblock4_denselayer6_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer6_layers_norm1_running_var'), target='features_denseblock4_denselayer6_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param98'), target='_frozen_param98', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param99'), target='_frozen_param99', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer7_layers_norm1_running_mean'), target='features_denseblock4_denselayer7_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer7_layers_norm1_running_var'), target='features_denseblock4_denselayer7_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param100'), target='_frozen_param100', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param101'), target='_frozen_param101', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer8_layers_norm1_running_mean'), target='features_denseblock4_denselayer8_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer8_layers_norm1_running_var'), target='features_denseblock4_denselayer8_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param102'), target='_frozen_param102', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param103'), target='_frozen_param103', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer9_layers_norm1_running_mean'), target='features_denseblock4_denselayer9_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer9_layers_norm1_running_var'), target='features_denseblock4_denselayer9_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param104'), target='_frozen_param104', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param105'), target='_frozen_param105', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer10_layers_norm1_running_mean'), target='features_denseblock4_denselayer10_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer10_layers_norm1_running_var'), target='features_denseblock4_denselayer10_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param106'), target='_frozen_param106', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param107'), target='_frozen_param107', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer11_layers_norm1_running_mean'), target='features_denseblock4_denselayer11_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer11_layers_norm1_running_var'), target='features_denseblock4_denselayer11_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param108'), target='_frozen_param108', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param109'), target='_frozen_param109', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer12_layers_norm1_running_mean'), target='features_denseblock4_denselayer12_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer12_layers_norm1_running_var'), target='features_denseblock4_denselayer12_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param110'), target='_frozen_param110', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param111'), target='_frozen_param111', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer13_layers_norm1_running_mean'), target='features_denseblock4_denselayer13_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer13_layers_norm1_running_var'), target='features_denseblock4_denselayer13_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param112'), target='_frozen_param112', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param113'), target='_frozen_param113', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer14_layers_norm1_running_mean'), target='features_denseblock4_denselayer14_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer14_layers_norm1_running_var'), target='features_denseblock4_denselayer14_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param114'), target='_frozen_param114', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param115'), target='_frozen_param115', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer15_layers_norm1_running_mean'), target='features_denseblock4_denselayer15_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer15_layers_norm1_running_var'), target='features_denseblock4_denselayer15_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param116'), target='_frozen_param116', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param117'), target='_frozen_param117', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer16_layers_norm1_running_mean'), target='features_denseblock4_denselayer16_layers_norm1_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_denseblock4_denselayer16_layers_norm1_running_var'), target='features_denseblock4_denselayer16_layers_norm1_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param118'), target='_frozen_param118', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param119'), target='_frozen_param119', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_norm5_running_mean'), target='features_norm5_running_mean', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b_features_norm5_running_var'), target='features_norm5_running_var', persistent=True), InputSpec(kind=<InputKind.BUFFER: 3>, arg=TensorArgument(name='b__frozen_param120'), target='_frozen_param120', persistent=True), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='dequantize_per_tensor_423'), target=None)])\n",
      "Range constraints: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ATen Dialect Graph\")\n",
    "print(aten_dialect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. torch.export: Defines the program with the ATen operator set.\n",
    "# aten_dialect = export(model, (torch.ones(1, 3, 256, 256),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. to_edge: Make optimizations for Edge devices\n",
    "edge_program = to_edge(aten_dialect, compile_config=EdgeCompileConfig(_check_ir_validity=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_program = edge_program.to_backend(XnnpackPartitioner())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. to_executorch: Convert the graph to an ExecuTorch program\n",
    "executorch_program = edge_program.to_executorch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Save the compiled .pte program\n",
    "with open(\"model_threesix_quantized.pte\", \"wb\") as file:\n",
    "    file.write(executorch_program.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
